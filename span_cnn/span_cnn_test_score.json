{"content": "Will Rengel ever give up? What an idiot.", "tokenize_content": ["will", "ren", "##gel", "ever", "give", "up", "?", "what", "an", "idiot", "."], "span": ["will ren", "rengel", "##gel ever", "ever give", "give up", "up?", "? what", "what an", "an idiot", "idiot."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "im not m1rth so stfu.", "tokenize_content": ["im", "not", "m1", "##rth", "so", "st", "##fu", "."], "span": ["im not", "not m1", "m1rth", "##rth so", "so st", "stfu", "##fu."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0]}
{"content": "you will burn in hell \n\nyou are a nazi piece of shit and your actions are abysmal\nrot in hell\nevil scum", "tokenize_content": ["you", "will", "burn", "in", "hell", "you", "are", "a", "nazi", "piece", "of", "shit", "and", "your", "actions", "are", "ab", "##ys", "##mal", "rot", "in", "hell", "evil", "sc", "##um"], "span": ["you will", "will burn", "burn in", "in hell", "hell you", "you are", "are a", "a nazi", "nazi piece", "piece of", "of shit", "shit and", "and your", "your actions", "actions are", "are ab", "abys", "##ysmal", "##mal rot", "rot in", "in hell", "hell evil", "evil sc", "scum"], "toxic": 1, "score": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "The king of stupid unconstructive edits is you.  Go fuck yourself.", "tokenize_content": ["the", "king", "of", "stupid", "un", "##con", "##st", "##ru", "##ctive", "edit", "##s", "is", "you", ".", "go", "fuck", "yourself", "."], "span": ["the king", "king of", "of stupid", "stupid un", "uncon", "##const", "##stru", "##ructive", "##ctive edit", "edits", "##s is", "is you", "you.", ". go", "go fuck", "fuck yourself", "yourself."], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "300 f*ing years of mixing is MORE than enough to disqualify someone as part of a certain ethnic group.", "tokenize_content": ["300", "f", "*", "ing", "years", "of", "mixing", "is", "more", "than", "enough", "to", "di", "##s", "##qual", "##ify", "someone", "as", "part", "of", "a", "certain", "ethnic", "group", "."], "span": ["300 f", "f *", "* ing", "ing years", "years of", "of mixing", "mixing is", "is more", "more than", "than enough", "enough to", "to di", "dis", "##squal", "##qualify", "##ify someone", "someone as", "as part", "part of", "of a", "a certain", "certain ethnic", "ethnic group", "group."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "NONSENSE?\n\nMY MEDICAL CONDITION IS FUCKING NONSENSE TO YOU? GO FUCK YOURSELF I HOPE YOU DIE RIGHT NOW.", "tokenize_content": ["nonsense", "?", "my", "medical", "condition", "is", "fucking", "nonsense", "to", "you", "?", "go", "fuck", "yourself", "i", "hope", "you", "die", "right", "now", "."], "span": ["nonsense?", "? my", "my medical", "medical condition", "condition is", "is fucking", "fucking nonsense", "nonsense to", "to you", "you?", "? go", "go fuck", "fuck yourself", "yourself i", "i hope", "hope you", "you die", "die right", "right now", "now."], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0]}
{"content": "Shut up, idiot! It is true! Now, go away and die!", "tokenize_content": ["shut", "up", ",", "idiot", "!", "it", "is", "true", "!", "now", ",", "go", "away", "and", "die", "!"], "span": ["shut up", "up,", ", idiot", "idiot!", "! it", "it is", "is true", "true!", "! now", "now,", ", go", "go away", "away and", "and die", "die!"], "toxic": 1, "score": [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "Listen up \n\nIll attack you if i bloody want to!", "tokenize_content": ["listen", "up", "ill", "attack", "you", "if", "i", "bloody", "want", "to", "!"], "span": ["listen up", "up ill", "ill attack", "attack you", "you if", "if i", "i bloody", "bloody want", "want to", "to!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Do you enjoy being a terrorist? \n\n Why? You hate America as much as the democrats?", "tokenize_content": ["do", "you", "enjoy", "being", "a", "terrorist", "?", "why", "?", "you", "hate", "america", "as", "much", "as", "the", "democrats", "?"], "span": ["do you", "you enjoy", "enjoy being", "being a", "a terrorist", "terrorist?", "? why", "why?", "? you", "you hate", "hate america", "america as", "as much", "much as", "as the", "the democrats", "democrats?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]}
{"content": "FUCK YOU Ckatz you are german Cock sucker and FUCKER MOTHER FUCKER", "tokenize_content": ["fuck", "you", "ck", "##atz", "you", "are", "german", "cock", "sucker", "and", "fuck", "##er", "mother", "fuck", "##er"], "span": ["fuck you", "you ck", "ckatz", "##atz you", "you are", "are german", "german cock", "cock sucker", "sucker and", "and fuck", "fucker", "##er mother", "mother fuck", "fucker"], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]}
{"content": "Fucking hell!!! I fucking wanna show these damn people & I'll kill those dufuses like Lil crazy dufus.User:Pic Business", "tokenize_content": ["fucking", "hell", "!", "!", "!", "i", "fucking", "wanna", "show", "these", "damn", "people", "&", "i", "'", "ll", "kill", "those", "du", "##fus", "##es", "like", "lil", "crazy", "du", "##fus", ".", "user", ":", "pic", "business"], "span": ["fucking hell", "hell!", "!!", "!!", "! i", "i fucking", "fucking wanna", "wanna show", "show these", "these damn", "damn people", "people &", "& i", "i '", "' ll", "ll kill", "kill those", "those du", "dufus", "##fuses", "##es like", "like lil", "lil crazy", "crazy du", "dufus", "##fus.", ". user", "user :", ": pic", "pic business"], "toxic": 1, "score": [1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "This has nothing to do with the article, but I f*ucking love Paul Miller's late show. Just had to say that, lulz sorry.", "tokenize_content": ["this", "has", "nothing", "to", "do", "with", "the", "article", ",", "but", "i", "f", "*", "uc", "##king", "love", "paul", "miller", "'", "s", "late", "show", ".", "just", "had", "to", "say", "that", ",", "lu", "##lz", "sorry", "."], "span": ["this has", "has nothing", "nothing to", "to do", "do with", "with the", "the article", "article,", ", but", "but i", "i f", "f *", "* uc", "ucking", "##king love", "love paul", "paul miller", "miller '", "' s", "s late", "late show", "show.", ". just", "just had", "had to", "to say", "say that", "that,", ", lu", "lulz", "##lz sorry", "sorry."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "WHY THE FUCK DID YOU DELETE MY PAGE YOU FUCKING STUCK UP SNOBBISH PAEDOPHILE TWATS!!!!!!!!!!!!!!!!!!!!!!!!!", "tokenize_content": ["why", "the", "fuck", "did", "you", "del", "##ete", "my", "page", "you", "fucking", "stuck", "up", "s", "##nob", "##bis", "##h", "pa", "##edo", "##phile", "t", "##wat", "##s", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!"], "span": ["why the", "the fuck", "fuck did", "did you", "you del", "delete", "##ete my", "my page", "page you", "you fucking", "fucking stuck", "stuck up", "up s", "snob", "##nobbis", "##bish", "##h pa", "paedo", "##edophile", "##phile t", "twat", "##wats", "##s!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!"], "toxic": 1, "score": [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "DUMB ASS THIS IS MY PAGE! LEAVE IT THE FUCK ALONE!", "tokenize_content": ["dumb", "ass", "this", "is", "my", "page", "!", "leave", "it", "the", "fuck", "alone", "!"], "span": ["dumb ass", "ass this", "this is", "is my", "my page", "page!", "! leave", "leave it", "it the", "the fuck", "fuck alone", "alone!"], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "how many people does this tit think i am? And whats with asking another editor who wants me banned to help out  this is fucking bullshit", "tokenize_content": ["how", "many", "people", "does", "this", "ti", "##t", "think", "i", "am", "?", "and", "what", "##s", "with", "asking", "another", "editor", "who", "wants", "me", "banned", "to", "help", "out", "this", "is", "fucking", "bullshit"], "span": ["how many", "many people", "people does", "does this", "this ti", "tit", "##t think", "think i", "i am", "am?", "? and", "and what", "whats", "##s with", "with asking", "asking another", "another editor", "editor who", "who wants", "wants me", "me banned", "banned to", "to help", "help out", "out this", "this is", "is fucking", "fucking bullshit"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "Hello\nYou may quite possibly be the stupidest person in existence.  Congratulations.  And well done on editing personal messages to you which you think might be offensive, whilst pushing lies on to others.", "tokenize_content": ["hello", "you", "may", "quite", "possibly", "be", "the", "stupid", "##est", "person", "in", "existence", ".", "congratulations", ".", "and", "well", "done", "on", "editing", "personal", "messages", "to", "you", "which", "you", "think", "might", "be", "offensive", ",", "whilst", "pushing", "lies", "on", "to", "others", "."], "span": ["hello you", "you may", "may quite", "quite possibly", "possibly be", "be the", "the stupid", "stupidest", "##est person", "person in", "in existence", "existence.", ". congratulations", "congratulations.", ". and", "and well", "well done", "done on", "on editing", "editing personal", "personal messages", "messages to", "to you", "you which", "which you", "you think", "think might", "might be", "be offensive", "offensive,", ", whilst", "whilst pushing", "pushing lies", "lies on", "on to", "to others", "others."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "hahah christ you're a little bitch 65.10.52.220", "tokenize_content": ["ha", "##ha", "##h", "christ", "you", "'", "re", "a", "little", "bitch", "65", ".", "10", ".", "52", ".", "220"], "span": ["haha", "##hah", "##h christ", "christ you", "you '", "' re", "re a", "a little", "little bitch", "bitch 65", "65.", ". 10", "10.", ". 52", "52.", ". 220"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "Newsflash!!  Schuminweb is GAY!!", "tokenize_content": ["news", "##fl", "##ash", "!", "!", "sc", "##hum", "##in", "##we", "##b", "is", "gay", "!", "!"], "span": ["newsfl", "##flash", "##ash!", "!!", "! sc", "schum", "##humin", "##inwe", "##web", "##b is", "is gay", "gay!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}
{"content": "Ekgograf and his son of bitch of gang of dumb, n*zi , and are the greatest batard that ever walk on earth !!!!!", "tokenize_content": ["ek", "##go", "##gra", "##f", "and", "his", "son", "of", "bitch", "of", "gang", "of", "dumb", ",", "n", "*", "z", "##i", ",", "and", "are", "the", "greatest", "bat", "##ard", "that", "ever", "walk", "on", "earth", "!", "!", "!", "!", "!"], "span": ["ekgo", "##gogra", "##graf", "##f and", "and his", "his son", "son of", "of bitch", "bitch of", "of gang", "gang of", "of dumb", "dumb,", ", n", "n *", "* z", "zi", "##i,", ", and", "and are", "are the", "the greatest", "greatest bat", "batard", "##ard that", "that ever", "ever walk", "walk on", "on earth", "earth!", "!!", "!!", "!!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "You're an ass. That was not a clip of the real game.\n-Jutras", "tokenize_content": ["you", "'", "re", "an", "ass", ".", "that", "was", "not", "a", "clip", "of", "the", "real", "game", ".", "-", "ju", "##tra", "##s"], "span": ["you '", "' re", "re an", "an ass", "ass.", ". that", "that was", "was not", "not a", "a clip", "clip of", "of the", "the real", "real game", "game.", ". -", "- ju", "jutra", "##tras"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I knew you were a dick but a fag too?\n\nnice job on the morgan discussion\n\nI liked how you buried the comments in the archive section", "tokenize_content": ["i", "knew", "you", "were", "a", "dick", "but", "a", "fa", "##g", "too", "?", "nice", "job", "on", "the", "morgan", "discussion", "i", "liked", "how", "you", "buried", "the", "comments", "in", "the", "archive", "section"], "span": ["i knew", "knew you", "you were", "were a", "a dick", "dick but", "but a", "a fa", "fag", "##g too", "too?", "? nice", "nice job", "job on", "on the", "the morgan", "morgan discussion", "discussion i", "i liked", "liked how", "how you", "you buried", "buried the", "the comments", "comments in", "in the", "the archive", "archive section"], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "IN THE ASS BITCH FUCKING COCK SUCKER!", "tokenize_content": ["in", "the", "ass", "bitch", "fucking", "cock", "sucker", "!"], "span": ["in the", "the ass", "ass bitch", "bitch fucking", "fucking cock", "cock sucker", "sucker!"], "toxic": 1, "score": [0, 1, 1, 1, 1, 1, 1]}
{"content": "hi am ahs I like this anime sow how ever thasent well well they can go to hell", "tokenize_content": ["hi", "am", "ah", "##s", "i", "like", "this", "anime", "so", "##w", "how", "ever", "tha", "##sen", "##t", "well", "well", "they", "can", "go", "to", "hell"], "span": ["hi am", "am ah", "ahs", "##s i", "i like", "like this", "this anime", "anime so", "sow", "##w how", "how ever", "ever tha", "thasen", "##sent", "##t well", "well well", "well they", "they can", "can go", "go to", "to hell"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "\"\n\nAre you a pole smoker? Do you suck cock?  \u2014Preceding unsigned comment added by 173.70.228.251   \"", "tokenize_content": ["\"", "are", "you", "a", "pole", "smoke", "##r", "?", "do", "you", "suck", "cock", "?", "\u2014", "preceding", "unsigned", "comment", "added", "by", "173", ".", "70", ".", "228", ".", "251", "\""], "span": ["\" are", "are you", "you a", "a pole", "pole smoke", "smoker", "##r?", "? do", "do you", "you suck", "suck cock", "cock?", "? \u2014", "\u2014 preceding", "preceding unsigned", "unsigned comment", "comment added", "added by", "by 173", "173.", ". 70", "70.", ". 228", "228.", ". 251", "251 \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "You are 22 years older than your husband! You are an old cougar! \n\nYou are an old cougar! You are an old cougar!", "tokenize_content": ["you", "are", "22", "years", "older", "than", "your", "husband", "!", "you", "are", "an", "old", "co", "##uga", "##r", "!", "you", "are", "an", "old", "co", "##uga", "##r", "!", "you", "are", "an", "old", "co", "##uga", "##r", "!"], "span": ["you are", "are 22", "22 years", "years older", "older than", "than your", "your husband", "husband!", "! you", "you are", "are an", "an old", "old co", "couga", "##ugar", "##r!", "! you", "you are", "are an", "an old", "old co", "couga", "##ugar", "##r!", "! you", "you are", "are an", "an old", "old co", "couga", "##ugar", "##r!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "|fukin arseholes dicks cunts die u priks", "tokenize_content": ["|", "fu", "##kin", "ars", "##eh", "##oles", "dick", "##s", "cu", "##nts", "die", "u", "pri", "##ks"], "span": ["| fu", "fukin", "##kin ars", "arseh", "##eholes", "##oles dick", "dicks", "##s cu", "cunts", "##nts die", "die u", "u pri", "priks"], "toxic": 1, "score": [0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0]}
{"content": "caden s should b shot in the head 100x u best shut up u piece of dog shitt u no nuthin u stupid piece of shitt larry king  is victim", "tokenize_content": ["caden", "s", "should", "b", "shot", "in", "the", "head", "100", "##x", "u", "best", "shut", "up", "u", "piece", "of", "dog", "shit", "##t", "u", "no", "nut", "##hin", "u", "stupid", "piece", "of", "shit", "##t", "larry", "king", "is", "victim"], "span": ["caden s", "s should", "should b", "b shot", "shot in", "in the", "the head", "head 100", "100x", "##x u", "u best", "best shut", "shut up", "up u", "u piece", "piece of", "of dog", "dog shit", "shitt", "##t u", "u no", "no nut", "nuthin", "##hin u", "u stupid", "stupid piece", "piece of", "of shit", "shitt", "##t larry", "larry king", "king is", "is victim"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0]}
{"content": "Burn Deck \n\nIf that'd guy's burn deck is like what I think it is than he is in for a blrude awakening!!! Leviathan motherfucker!!!", "tokenize_content": ["burn", "deck", "if", "that", "'", "d", "guy", "'", "s", "burn", "deck", "is", "like", "what", "i", "think", "it", "is", "than", "he", "is", "in", "for", "a", "b", "##lr", "##ude", "awakening", "!", "!", "!", "levi", "##athan", "mother", "##fu", "##cker", "!", "!", "!"], "span": ["burn deck", "deck if", "if that", "that '", "' d", "d guy", "guy '", "' s", "s burn", "burn deck", "deck is", "is like", "like what", "what i", "i think", "think it", "it is", "is than", "than he", "he is", "is in", "in for", "for a", "a b", "blr", "##lrude", "##ude awakening", "awakening!", "!!", "!!", "! levi", "leviathan", "##athan mother", "motherfu", "##fucker", "##cker!", "!!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "Whoops \n\nWhat!? You blocked me from editting? Damn...oh wait, nevermind, you're just an idiot.\n\np.s. I'm not a person, I'm a reminder.", "tokenize_content": ["who", "##ops", "what", "!", "?", "you", "blocked", "me", "from", "edit", "##ting", "?", "damn", ".", ".", ".", "oh", "wait", ",", "never", "##mind", ",", "you", "'", "re", "just", "an", "idiot", ".", "p", ".", "s", ".", "i", "'", "m", "not", "a", "person", ",", "i", "'", "m", "a", "reminder", "."], "span": ["whoops", "##ops what", "what!", "!?", "? you", "you blocked", "blocked me", "me from", "from edit", "editting", "##ting?", "? damn", "damn.", "..", "..", ". oh", "oh wait", "wait,", ", never", "nevermind", "##mind,", ", you", "you '", "' re", "re just", "just an", "an idiot", "idiot.", ". p", "p.", ". s", "s.", ". i", "i '", "' m", "m not", "not a", "a person", "person,", ", i", "i '", "' m", "m a", "a reminder", "reminder."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Your a moron  everything is on the articles that are on the page.  Yeah the ones that are actually legit  or they still exist.  And he doesnt have a birth certificate  he says he's 14  its not proven even to this day", "tokenize_content": ["your", "a", "mor", "##on", "everything", "is", "on", "the", "articles", "that", "are", "on", "the", "page", ".", "yeah", "the", "ones", "that", "are", "actually", "leg", "##it", "or", "they", "still", "exist", ".", "and", "he", "doesn", "##t", "have", "a", "birth", "certificate", "he", "says", "he", "'", "s", "14", "its", "not", "proven", "even", "to", "this", "day"], "span": ["your a", "a mor", "moron", "##on everything", "everything is", "is on", "on the", "the articles", "articles that", "that are", "are on", "on the", "the page", "page.", ". yeah", "yeah the", "the ones", "ones that", "that are", "are actually", "actually leg", "legit", "##it or", "or they", "they still", "still exist", "exist.", ". and", "and he", "he doesn", "doesnt", "##t have", "have a", "a birth", "birth certificate", "certificate he", "he says", "says he", "he '", "' s", "s 14", "14 its", "its not", "not proven", "proven even", "even to", "to this", "this day"], "toxic": 1, "score": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Malta is an Arab! \n\nStop lying!", "tokenize_content": ["malta", "is", "an", "arab", "!", "stop", "lying", "!"], "span": ["malta is", "is an", "an arab", "arab!", "! stop", "stop lying", "lying!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0]}
{"content": "don't u dear delete my page again alrite u nigger", "tokenize_content": ["don", "'", "t", "u", "dear", "del", "##ete", "my", "page", "again", "al", "##rite", "u", "ni", "##gger"], "span": ["don '", "' t", "t u", "u dear", "dear del", "delete", "##ete my", "my page", "page again", "again al", "alrite", "##rite u", "u ni", "nigger"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "Block me all you like, jizzballs. I care not in the slightest.", "tokenize_content": ["block", "me", "all", "you", "like", ",", "ji", "##zz", "##balls", ".", "i", "care", "not", "in", "the", "slightest", "."], "span": ["block me", "me all", "all you", "you like", "like,", ", ji", "jizz", "##zzballs", "##balls.", ". i", "i care", "care not", "not in", "in the", "the slightest", "slightest."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "How about this: fuck off. Just a suggestion.", "tokenize_content": ["how", "about", "this", ":", "fuck", "off", ".", "just", "a", "suggestion", "."], "span": ["how about", "about this", "this :", ": fuck", "fuck off", "off.", ". just", "just a", "a suggestion", "suggestion."], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]}
{"content": "Myanw is a cockteaseing homophobe.", "tokenize_content": ["my", "##an", "##w", "is", "a", "cock", "##tea", "##sei", "##ng", "homo", "##ph", "##obe", "."], "span": ["myan", "##anw", "##w is", "is a", "a cock", "cocktea", "##teasei", "##seing", "##ng homo", "homoph", "##phobe", "##obe."], "toxic": 1, "score": [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]}
{"content": "And stick it up your asshole.", "tokenize_content": ["and", "stick", "it", "up", "your", "asshole", "."], "span": ["and stick", "stick it", "it up", "up your", "your asshole", "asshole."], "toxic": 1, "score": [0, 0, 0, 0, 1, 1]}
{"content": "Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker Wanker", "tokenize_content": ["wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker", "wan", "##ker"], "span": ["wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker", "##ker wan", "wanker"], "toxic": 1, "score": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]}
{"content": "\"\nYou omitted \"\"I am a c*nt\"\" also. Happy to be of service.\"", "tokenize_content": ["\"", "you", "omitted", "\"", "\"", "i", "am", "a", "c", "*", "nt", "\"", "\"", "also", ".", "happy", "to", "be", "of", "service", ".", "\""], "span": ["\" you", "you omitted", "omitted \"", "\" \"", "\" i", "i am", "am a", "a c", "c *", "* nt", "nt \"", "\" \"", "\" also", "also.", ". happy", "happy to", "to be", "be of", "of service", "service.", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "You're just senseless and clueless making false accuses.", "tokenize_content": ["you", "'", "re", "just", "sense", "##less", "and", "clue", "##less", "making", "false", "accuse", "##s", "."], "span": ["you '", "' re", "re just", "just sense", "senseless", "##less and", "and clue", "clueless", "##less making", "making false", "false accuse", "accuses", "##s."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\nI'm sorry, I was across the room and heard someone say \"\"gay slut\"\", so I had to come check it out.  Can I buy someone a drink?   \"", "tokenize_content": ["\"", "i", "'", "m", "sorry", ",", "i", "was", "across", "the", "room", "and", "heard", "someone", "say", "\"", "\"", "gay", "sl", "##ut", "\"", "\"", ",", "so", "i", "had", "to", "come", "check", "it", "out", ".", "can", "i", "buy", "someone", "a", "drink", "?", "\""], "span": ["\" i", "i '", "' m", "m sorry", "sorry,", ", i", "i was", "was across", "across the", "the room", "room and", "and heard", "heard someone", "someone say", "say \"", "\" \"", "\" gay", "gay sl", "slut", "##ut \"", "\" \"", "\",", ", so", "so i", "i had", "had to", "to come", "come check", "check it", "it out", "out.", ". can", "can i", "i buy", "buy someone", "someone a", "a drink", "drink?", "? \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Comment from Kansai Goma \n\nI still have more accounts on here which you will never find because I am too smart for you dickheads and you are a dumass.\n\nfuck ya!", "tokenize_content": ["comment", "from", "kan", "##sai", "go", "##ma", "i", "still", "have", "more", "accounts", "on", "here", "which", "you", "will", "never", "find", "because", "i", "am", "too", "smart", "for", "you", "dick", "##heads", "and", "you", "are", "a", "du", "##mas", "##s", ".", "fuck", "ya", "!"], "span": ["comment from", "from kan", "kansai", "##sai go", "goma", "##ma i", "i still", "still have", "have more", "more accounts", "accounts on", "on here", "here which", "which you", "you will", "will never", "never find", "find because", "because i", "i am", "am too", "too smart", "smart for", "for you", "you dick", "dickheads", "##heads and", "and you", "you are", "are a", "a du", "dumas", "##mass", "##s.", ". fuck", "fuck ya", "ya!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "your right bro, your so right.....not! i hate you. block me you fagplease", "tokenize_content": ["your", "right", "bro", ",", "your", "so", "right", ".", ".", ".", ".", ".", "not", "!", "i", "hate", "you", ".", "block", "me", "you", "fa", "##gp", "##lea", "##se"], "span": ["your right", "right bro", "bro,", ", your", "your so", "so right", "right.", "..", "..", "..", "..", ". not", "not!", "! i", "i hate", "hate you", "you.", ". block", "block me", "me you", "you fa", "fagp", "##gplea", "##lease"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Nick Graves is a lier and a blackmailer. He openly told me that he is a sock puppet of someone.", "tokenize_content": ["nick", "graves", "is", "a", "lie", "##r", "and", "a", "blackmail", "##er", ".", "he", "openly", "told", "me", "that", "he", "is", "a", "sock", "puppet", "of", "someone", "."], "span": ["nick graves", "graves is", "is a", "a lie", "lier", "##r and", "and a", "a blackmail", "blackmailer", "##er.", ". he", "he openly", "openly told", "told me", "me that", "that he", "he is", "is a", "a sock", "sock puppet", "puppet of", "of someone", "someone."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Michael Schiavo\nHe is breaking WP:3RR and you accuse me of vandalism? Go suck a fuck!", "tokenize_content": ["michael", "sc", "##hia", "##vo", "he", "is", "breaking", "w", "##p", ":", "3", "##rr", "and", "you", "accuse", "me", "of", "van", "##dal", "##ism", "?", "go", "suck", "a", "fuck", "!"], "span": ["michael sc", "schia", "##hiavo", "##vo he", "he is", "is breaking", "breaking w", "wp", "##p :", ": 3", "3rr", "##rr and", "and you", "you accuse", "accuse me", "me of", "of van", "vandal", "##dalism", "##ism?", "? go", "go suck", "suck a", "a fuck", "fuck!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]}
{"content": "YOU FUCKING IDIOT 75.125.163.147", "tokenize_content": ["you", "fucking", "idiot", "75", ".", "125", ".", "163", ".", "147"], "span": ["you fucking", "fucking idiot", "idiot 75", "75.", ". 125", "125.", ". 163", "163.", ". 147"], "toxic": 1, "score": [1, 1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "| decline=Niggers, jews, bad news! Also my cock is hard so it's time for rape lol 86.181.0.14", "tokenize_content": ["|", "decline", "=", "ni", "##gger", "##s", ",", "jews", ",", "bad", "news", "!", "also", "my", "cock", "is", "hard", "so", "it", "'", "s", "time", "for", "rape", "lo", "##l", "86", ".", "181", ".", "0", ".", "14"], "span": ["| decline", "decline =", "= ni", "nigger", "##ggers", "##s,", ", jews", "jews,", ", bad", "bad news", "news!", "! also", "also my", "my cock", "cock is", "is hard", "hard so", "so it", "it '", "' s", "s time", "time for", "for rape", "rape lo", "lol", "##l 86", "86.", ". 181", "181.", ". 0", "0.", ". 14"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "May Lucifer's love be with you, Lift-off. Beep beep beep", "tokenize_content": ["may", "lucifer", "'", "s", "love", "be", "with", "you", ",", "lift", "-", "off", ".", "bee", "##p", "bee", "##p", "bee", "##p"], "span": ["may lucifer", "lucifer '", "' s", "s love", "love be", "be with", "with you", "you,", ", lift", "lift -", "- off", "off.", ". bee", "beep", "##p bee", "beep", "##p bee", "beep"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "unblock|Retarded brother hacked my pc.", "tokenize_content": ["un", "##block", "|", "re", "##tar", "##ded", "brother", "hacked", "my", "pc", "."], "span": ["unblock", "##block |", "| re", "retar", "##tarded", "##ded brother", "brother hacked", "hacked my", "my pc", "pc."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Fuck off, asshole. Go back to ruining Wikipedia, why don't you?", "tokenize_content": ["fuck", "off", ",", "asshole", ".", "go", "back", "to", "ruining", "wikipedia", ",", "why", "don", "'", "t", "you", "?"], "span": ["fuck off", "off,", ", asshole", "asshole.", ". go", "go back", "back to", "to ruining", "ruining wikipedia", "wikipedia,", ", why", "why don", "don '", "' t", "t you", "you?"], "toxic": 1, "score": [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Fuck off \n\nyou can fuck right off mate!", "tokenize_content": ["fuck", "off", "you", "can", "fuck", "right", "off", "mate", "!"], "span": ["fuck off", "off you", "you can", "can fuck", "fuck right", "right off", "off mate", "mate!"], "toxic": 1, "score": [1, 0, 0, 1, 1, 0, 0, 1]}
{"content": "Yep, as I said, Bite me, Hitler, err... Scrapiron. Disappear it to make you look like less of an asshole, you will be hiding it because you can. Fuck you.", "tokenize_content": ["yep", ",", "as", "i", "said", ",", "bite", "me", ",", "hitler", ",", "er", "##r", ".", ".", ".", "scrap", "##iro", "##n", ".", "disappear", "it", "to", "make", "you", "look", "like", "less", "of", "an", "asshole", ",", "you", "will", "be", "hiding", "it", "because", "you", "can", ".", "fuck", "you", "."], "span": ["yep,", ", as", "as i", "i said", "said,", ", bite", "bite me", "me,", ", hitler", "hitler,", ", er", "err", "##r.", "..", "..", ". scrap", "scrapiro", "##iron", "##n.", ". disappear", "disappear it", "it to", "to make", "make you", "you look", "look like", "like less", "less of", "of an", "an asshole", "asshole,", ", you", "you will", "will be", "be hiding", "hiding it", "it because", "because you", "you can", "can.", ". fuck", "fuck you", "you."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "Where is the real vagina? \n\nThe real photo of vagina is gone!\n\nWould you mind if I make the new one?\n\nThe vagina picture is Indonesian's vagina. Do you love it?", "tokenize_content": ["where", "is", "the", "real", "va", "##gina", "?", "the", "real", "photo", "of", "va", "##gina", "is", "gone", "!", "would", "you", "mind", "if", "i", "make", "the", "new", "one", "?", "the", "va", "##gina", "picture", "is", "indonesian", "'", "s", "va", "##gina", ".", "do", "you", "love", "it", "?"], "span": ["where is", "is the", "the real", "real va", "vagina", "##gina?", "? the", "the real", "real photo", "photo of", "of va", "vagina", "##gina is", "is gone", "gone!", "! would", "would you", "you mind", "mind if", "if i", "i make", "make the", "the new", "new one", "one?", "? the", "the va", "vagina", "##gina picture", "picture is", "is indonesian", "indonesian '", "' s", "s va", "vagina", "##gina.", ". do", "do you", "you love", "love it", "it?"], "toxic": 1, "score": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]}
{"content": "eat me \n\ngo blow yourself", "tokenize_content": ["eat", "me", "go", "blow", "yourself"], "span": ["eat me", "me go", "go blow", "blow yourself"], "toxic": 1, "score": [0, 0, 0, 0]}
{"content": "\"\nOh, right, so you did, silly Zilla forget! [Expels radioactive breath with mighty explosion of relief. Face returns slowly from dark blue to normal scaly green.]  ROARR!! .\"", "tokenize_content": ["\"", "oh", ",", "right", ",", "so", "you", "did", ",", "silly", "z", "##illa", "forget", "!", "[", "ex", "##pel", "##s", "radioactive", "breath", "with", "mighty", "explosion", "of", "relief", ".", "face", "returns", "slowly", "from", "dark", "blue", "to", "normal", "sc", "##aly", "green", ".", "]", "roar", "##r", "!", "!", ".", "\""], "span": ["\" oh", "oh,", ", right", "right,", ", so", "so you", "you did", "did,", ", silly", "silly z", "zilla", "##illa forget", "forget!", "! [", "[ ex", "expel", "##pels", "##s radioactive", "radioactive breath", "breath with", "with mighty", "mighty explosion", "explosion of", "of relief", "relief.", ". face", "face returns", "returns slowly", "slowly from", "from dark", "dark blue", "blue to", "to normal", "normal sc", "scaly", "##aly green", "green.", ". ]", "] roar", "roarr", "##r!", "!!", "!.", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Byzant\u0131um \nWhat the fuck \u0131s your problem?  The real Byzantium flags are here: http://en.wikipedia.org/wiki/Byzantine_Empire", "tokenize_content": ["by", "##zan", "##t", "##\u0131", "##um", "what", "the", "fuck", "\u0131", "##s", "your", "problem", "?", "the", "real", "by", "##zan", "##tium", "flags", "are", "here", ":", "http", ":", "/", "/", "en", ".", "wikipedia", ".", "org", "/", "wi", "##ki", "/", "byzantine", "_", "empire"], "span": ["byzan", "##zant", "##t\u0131", "##\u0131um", "##um what", "what the", "the fuck", "fuck \u0131", "\u0131s", "##s your", "your problem", "problem?", "? the", "the real", "real by", "byzan", "##zantium", "##tium flags", "flags are", "are here", "here :", ": http", "http :", ": /", "/ /", "/ en", "en.", ". wikipedia", "wikipedia.", ". org", "org /", "/ wi", "wiki", "##ki /", "/ byzantine", "byzantine _", "_ empire"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "SUP NIGGA \n\nI WUZ JUS CHILLIN WIT MY OG'S ON DA WEST SIDE NIGGA, YO JIGABOO BLOCKED MY CRACKA ASS, DA WU TANG AIN'T NUTTIN TA FUCK WIT BIOTCH", "tokenize_content": ["su", "##p", "ni", "##gga", "i", "wu", "##z", "ju", "##s", "chill", "##in", "wit", "my", "og", "'", "s", "on", "da", "west", "side", "ni", "##gga", ",", "yo", "ji", "##ga", "##bo", "##o", "blocked", "my", "crack", "##a", "ass", ",", "da", "wu", "tang", "ain", "'", "t", "nut", "##tin", "ta", "fuck", "wit", "bio", "##tch"], "span": ["sup", "##p ni", "nigga", "##gga i", "i wu", "wuz", "##z ju", "jus", "##s chill", "chillin", "##in wit", "wit my", "my og", "og '", "' s", "s on", "on da", "da west", "west side", "side ni", "nigga", "##gga,", ", yo", "yo ji", "jiga", "##gabo", "##boo", "##o blocked", "blocked my", "my crack", "cracka", "##a ass", "ass,", ", da", "da wu", "wu tang", "tang ain", "ain '", "' t", "t nut", "nuttin", "##tin ta", "ta fuck", "fuck wit", "wit bio", "biotch"], "toxic": 1, "score": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]}
{"content": "Who the hell are you, and where did you get this rubbish??? 24.5.122.13", "tokenize_content": ["who", "the", "hell", "are", "you", ",", "and", "where", "did", "you", "get", "this", "rubbish", "?", "?", "?", "24", ".", "5", ".", "122", ".", "13"], "span": ["who the", "the hell", "hell are", "are you", "you,", ", and", "and where", "where did", "did you", "you get", "get this", "this rubbish", "rubbish?", "??", "??", "? 24", "24.", ". 5", "5.", ". 122", "122.", ". 13"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "HOW DARE YOU, TOO....... \n\nHOW DARE YOU FOR ATTACKING ME!", "tokenize_content": ["how", "dare", "you", ",", "too", ".", ".", ".", ".", ".", ".", ".", "how", "dare", "you", "for", "attacking", "me", "!"], "span": ["how dare", "dare you", "you,", ", too", "too.", "..", "..", "..", "..", "..", "..", ". how", "how dare", "dare you", "you for", "for attacking", "attacking me", "me!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "AM A BIG FUCKING RETARD", "tokenize_content": ["am", "a", "big", "fucking", "re", "##tar", "##d"], "span": ["am a", "a big", "big fucking", "fucking re", "retar", "##tard"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0]}
{"content": "oh i bet you are little boy. now go up stairs, your mummy made your lunch", "tokenize_content": ["oh", "i", "bet", "you", "are", "little", "boy", ".", "now", "go", "up", "stairs", ",", "your", "mummy", "made", "your", "lunch"], "span": ["oh i", "i bet", "bet you", "you are", "are little", "little boy", "boy.", ". now", "now go", "go up", "up stairs", "stairs,", ", your", "your mummy", "mummy made", "made your", "your lunch"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Am I welcome on Wikipedia? My brother is an abusive sockpuppet and I'm scared that I will be blocked if I say who.", "tokenize_content": ["am", "i", "welcome", "on", "wikipedia", "?", "my", "brother", "is", "an", "abusive", "sock", "##pu", "##ppet", "and", "i", "'", "m", "scared", "that", "i", "will", "be", "blocked", "if", "i", "say", "who", "."], "span": ["am i", "i welcome", "welcome on", "on wikipedia", "wikipedia?", "? my", "my brother", "brother is", "is an", "an abusive", "abusive sock", "sockpu", "##puppet", "##ppet and", "and i", "i '", "' m", "m scared", "scared that", "that i", "i will", "will be", "be blocked", "blocked if", "if i", "i say", "say who", "who."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Hello \n\nHey there Metros. You know me. Why pretend you don't, bitchy poo? Who else is a beeg fan of beeg mooonster poonag?", "tokenize_content": ["hello", "hey", "there", "metro", "##s", ".", "you", "know", "me", ".", "why", "pretend", "you", "don", "'", "t", ",", "bitch", "##y", "po", "##o", "?", "who", "else", "is", "a", "bee", "##g", "fan", "of", "bee", "##g", "mo", "##oons", "##ter", "po", "##ona", "##g", "?"], "span": ["hello hey", "hey there", "there metro", "metros", "##s.", ". you", "you know", "know me", "me.", ". why", "why pretend", "pretend you", "you don", "don '", "' t", "t,", ", bitch", "bitchy", "##y po", "poo", "##o?", "? who", "who else", "else is", "is a", "a bee", "beeg", "##g fan", "fan of", "of bee", "beeg", "##g mo", "mooons", "##oonster", "##ter po", "poona", "##onag", "##g?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Re. dicks \n\nHow many dicks do you have in your mouth right now? Tell the truth. It's over fifty, isn't it?", "tokenize_content": ["re", ".", "dick", "##s", "how", "many", "dick", "##s", "do", "you", "have", "in", "your", "mouth", "right", "now", "?", "tell", "the", "truth", ".", "it", "'", "s", "over", "fifty", ",", "isn", "'", "t", "it", "?"], "span": ["re.", ". dick", "dicks", "##s how", "how many", "many dick", "dicks", "##s do", "do you", "you have", "have in", "in your", "your mouth", "mouth right", "right now", "now?", "? tell", "tell the", "the truth", "truth.", ". it", "it '", "' s", "s over", "over fifty", "fifty,", ", isn", "isn '", "' t", "t it", "it?"], "toxic": 1, "score": [0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "try harder dick \n\nthis is war, you cunts are a latter day religion that will be taken out!", "tokenize_content": ["try", "harder", "dick", "this", "is", "war", ",", "you", "cu", "##nts", "are", "a", "latter", "day", "religion", "that", "will", "be", "taken", "out", "!"], "span": ["try harder", "harder dick", "dick this", "this is", "is war", "war,", ", you", "you cu", "cunts", "##nts are", "are a", "a latter", "latter day", "day religion", "religion that", "that will", "will be", "be taken", "taken out", "out!"], "toxic": 1, "score": [0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "EAT SHIT HORSE FACE!!!", "tokenize_content": ["eat", "shit", "horse", "face", "!", "!", "!"], "span": ["eat shit", "shit horse", "horse face", "face!", "!!", "!!"], "toxic": 1, "score": [1, 1, 0, 0, 0, 0]}
{"content": "In my opinion something bad might happen to you in the next few days, just saying...", "tokenize_content": ["in", "my", "opinion", "something", "bad", "might", "happen", "to", "you", "in", "the", "next", "few", "days", ",", "just", "saying", ".", ".", "."], "span": ["in my", "my opinion", "opinion something", "something bad", "bad might", "might happen", "happen to", "to you", "you in", "in the", "the next", "next few", "few days", "days,", ", just", "just saying", "saying.", "..", ".."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\n int add(int a, int b \n\n  being a Vandal FUCK YOU!!!!   \"", "tokenize_content": ["\"", "int", "add", "(", "int", "a", ",", "int", "b", "being", "a", "van", "##dal", "fuck", "you", "!", "!", "!", "!", "\""], "span": ["\" int", "int add", "add (", "( int", "int a", "a,", ", int", "int b", "b being", "being a", "a van", "vandal", "##dal fuck", "fuck you", "you!", "!!", "!!", "!!", "! \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]}
{"content": "my balls \n\nBIG BALLS\n\n ive got big balls youve got big balls shes got big balls \n  theyve got big balls   weve got big balls  weve got big balls \n \n\n        ive got great balls of fire \n                      BY david swartz", "tokenize_content": ["my", "balls", "big", "balls", "iv", "##e", "got", "big", "balls", "you", "##ve", "got", "big", "balls", "she", "##s", "got", "big", "balls", "they", "##ve", "got", "big", "balls", "we", "##ve", "got", "big", "balls", "we", "##ve", "got", "big", "balls", "iv", "##e", "got", "great", "balls", "of", "fire", "by", "david", "sw", "##art", "##z"], "span": ["my balls", "balls big", "big balls", "balls iv", "ive", "##e got", "got big", "big balls", "balls you", "youve", "##ve got", "got big", "big balls", "balls she", "shes", "##s got", "got big", "big balls", "balls they", "theyve", "##ve got", "got big", "big balls", "balls we", "weve", "##ve got", "got big", "big balls", "balls we", "weve", "##ve got", "got big", "big balls", "balls iv", "ive", "##e got", "got great", "great balls", "balls of", "of fire", "fire by", "by david", "david sw", "swart", "##artz"], "toxic": 1, "score": [1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Go fuck yourself for giving me a sandbox warning \n\nHis face was BURNT in the attack. Watch the fucking episode before giving me your fucking warning.", "tokenize_content": ["go", "fuck", "yourself", "for", "giving", "me", "a", "sand", "##box", "warning", "his", "face", "was", "burnt", "in", "the", "attack", ".", "watch", "the", "fucking", "episode", "before", "giving", "me", "your", "fucking", "warning", "."], "span": ["go fuck", "fuck yourself", "yourself for", "for giving", "giving me", "me a", "a sand", "sandbox", "##box warning", "warning his", "his face", "face was", "was burnt", "burnt in", "in the", "the attack", "attack.", ". watch", "watch the", "the fucking", "fucking episode", "episode before", "before giving", "giving me", "me your", "your fucking", "fucking warning", "warning."], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0]}
{"content": "am gay, or homosexual, or a fag. Im sorry its a personal choice", "tokenize_content": ["am", "gay", ",", "or", "homosexual", ",", "or", "a", "fa", "##g", ".", "im", "sorry", "its", "a", "personal", "choice"], "span": ["am gay", "gay,", ", or", "or homosexual", "homosexual,", ", or", "or a", "a fa", "fag", "##g.", ". im", "im sorry", "sorry its", "its a", "a personal", "personal choice"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Let's see her tits \n\nLOL - I HAVE NO PENIS", "tokenize_content": ["let", "'", "s", "see", "her", "tits", "lo", "##l", "-", "i", "have", "no", "penis"], "span": ["let '", "' s", "s see", "see her", "her tits", "tits lo", "lol", "##l -", "- i", "i have", "have no", "no penis"], "toxic": 1, "score": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]}
{"content": "closedmouth is a DICK-FUCK \n\nthis guy is a jackass who sux cock 4 a fuckin job y the fuck does the trans do it?????cuz its into tht kinda shit >:(", "tokenize_content": ["closed", "##mouth", "is", "a", "dick", "-", "fuck", "this", "guy", "is", "a", "jack", "##ass", "who", "su", "##x", "cock", "4", "a", "fuck", "##in", "job", "y", "the", "fuck", "does", "the", "trans", "do", "it", "?", "?", "?", "?", "?", "cu", "##z", "its", "into", "th", "##t", "kinda", "shit", ">", ":", "("], "span": ["closedmouth", "##mouth is", "is a", "a dick", "dick -", "- fuck", "fuck this", "this guy", "guy is", "is a", "a jack", "jackass", "##ass who", "who su", "sux", "##x cock", "cock 4", "4 a", "a fuck", "fuckin", "##in job", "job y", "y the", "the fuck", "fuck does", "does the", "the trans", "trans do", "do it", "it?", "??", "??", "??", "??", "? cu", "cuz", "##z its", "its into", "into th", "tht", "##t kinda", "kinda shit", "shit >", "> :", ": ("], "toxic": 1, "score": [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}
{"content": "Shut up. I can do what the fuck I want.  4 July 2005 01:31 (UTC)", "tokenize_content": ["shut", "up", ".", "i", "can", "do", "what", "the", "fuck", "i", "want", ".", "4", "july", "2005", "01", ":", "31", "(", "utc", ")"], "span": ["shut up", "up.", ". i", "i can", "can do", "do what", "what the", "the fuck", "fuck i", "i want", "want.", ". 4", "4 july", "july 2005", "2005 01", "01 :", ": 31", "31 (", "( utc", "utc )"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "mildred taylor is  \n\nshe is totally stupid o.j", "tokenize_content": ["mildred", "taylor", "is", "she", "is", "totally", "stupid", "o", ".", "j"], "span": ["mildred taylor", "taylor is", "is she", "she is", "is totally", "totally stupid", "stupid o", "o.", ". j"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "\"\n\n You are a dick! \n\n  nerd.\n\nJonah Young out. Add me on Facebook. <3 8======D~~   \n\n A kitten for you! \n\ngo fuck your self\n\n  \n\"", "tokenize_content": ["\"", "you", "are", "a", "dick", "!", "ne", "##rd", ".", "jonah", "young", "out", ".", "add", "me", "on", "facebook", ".", "<", "3", "8", "=", "=", "=", "=", "=", "=", "d", "~", "~", "a", "kitten", "for", "you", "!", "go", "fuck", "your", "self", "\""], "span": ["\" you", "you are", "are a", "a dick", "dick!", "! ne", "nerd", "##rd.", ". jonah", "jonah young", "young out", "out.", ". add", "add me", "me on", "on facebook", "facebook.", ". <", "< 3", "3 8", "8 =", "= =", "= =", "= =", "= =", "= =", "= d", "d ~", "~ ~", "~ a", "a kitten", "kitten for", "for you", "you!", "! go", "go fuck", "fuck your", "your self", "self \""], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "I'd call you a pompous ass, but that would be redundant, after reading all of your prior talk entries.", "tokenize_content": ["i", "'", "d", "call", "you", "a", "po", "##mp", "##ous", "ass", ",", "but", "that", "would", "be", "redundant", ",", "after", "reading", "all", "of", "your", "prior", "talk", "entries", "."], "span": ["i '", "' d", "d call", "call you", "you a", "a po", "pomp", "##mpous", "##ous ass", "ass,", ", but", "but that", "that would", "would be", "be redundant", "redundant,", ", after", "after reading", "reading all", "all of", "of your", "your prior", "prior talk", "talk entries", "entries."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Again, comparing the Kiedis images, are you a retard or simply still in kindergarden ?", "tokenize_content": ["again", ",", "comparing", "the", "ki", "##ed", "##is", "images", ",", "are", "you", "a", "re", "##tar", "##d", "or", "simply", "still", "in", "kind", "##er", "##gard", "##en", "?"], "span": ["again,", ", comparing", "comparing the", "the ki", "kied", "##edis", "##is images", "images,", ", are", "are you", "you a", "a re", "retar", "##tard", "##d or", "or simply", "simply still", "still in", "in kind", "kinder", "##ergard", "##garden", "##en?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "fucking germanian piece of shit", "tokenize_content": ["fucking", "german", "##ian", "piece", "of", "shit"], "span": ["fucking german", "germanian", "##ian piece", "piece of", "of shit"], "toxic": 1, "score": [1, 0, 0, 0, 1]}
{"content": "Your incorrect opinion, and lord knows you are certainly full of them.  But get your eyes checked so you can avoid such stupid statements in the future.", "tokenize_content": ["your", "incorrect", "opinion", ",", "and", "lord", "knows", "you", "are", "certainly", "full", "of", "them", ".", "but", "get", "your", "eyes", "checked", "so", "you", "can", "avoid", "such", "stupid", "statements", "in", "the", "future", "."], "span": ["your incorrect", "incorrect opinion", "opinion,", ", and", "and lord", "lord knows", "knows you", "you are", "are certainly", "certainly full", "full of", "of them", "them.", ". but", "but get", "get your", "your eyes", "eyes checked", "checked so", "so you", "you can", "can avoid", "avoid such", "such stupid", "stupid statements", "statements in", "in the", "the future", "future."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "I'd like a word with you \n\nJust what the FUCK do you think you are playing at?!?! 94.4.3.210", "tokenize_content": ["i", "'", "d", "like", "a", "word", "with", "you", "just", "what", "the", "fuck", "do", "you", "think", "you", "are", "playing", "at", "?", "!", "?", "!", "94", ".", "4", ".", "3", ".", "210"], "span": ["i '", "' d", "d like", "like a", "a word", "word with", "with you", "you just", "just what", "what the", "the fuck", "fuck do", "do you", "you think", "think you", "you are", "are playing", "playing at", "at?", "?!", "!?", "?!", "! 94", "94.", ". 4", "4.", ". 3", "3.", ". 210"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "The final verdict now shut up", "tokenize_content": ["the", "final", "verdict", "now", "shut", "up"], "span": ["the final", "final verdict", "verdict now", "now shut", "shut up"], "toxic": 1, "score": [0, 0, 0, 0, 1]}
{"content": "This isn't even fair! The old Like A Boy cover was fake and I uploaded the ACTUAL one! You know what, fuck Wikipedia. No one actually believes this pathetic excuse for a factual website anyway!", "tokenize_content": ["this", "isn", "'", "t", "even", "fair", "!", "the", "old", "like", "a", "boy", "cover", "was", "fake", "and", "i", "uploaded", "the", "actual", "one", "!", "you", "know", "what", ",", "fuck", "wikipedia", ".", "no", "one", "actually", "believes", "this", "pathetic", "excuse", "for", "a", "factual", "website", "anyway", "!"], "span": ["this isn", "isn '", "' t", "t even", "even fair", "fair!", "! the", "the old", "old like", "like a", "a boy", "boy cover", "cover was", "was fake", "fake and", "and i", "i uploaded", "uploaded the", "the actual", "actual one", "one!", "! you", "you know", "know what", "what,", ", fuck", "fuck wikipedia", "wikipedia.", ". no", "no one", "one actually", "actually believes", "believes this", "this pathetic", "pathetic excuse", "excuse for", "for a", "a factual", "factual website", "website anyway", "anyway!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "why are you such an idiot? \n\n?", "tokenize_content": ["why", "are", "you", "such", "an", "idiot", "?", "?"], "span": ["why are", "are you", "you such", "such an", "an idiot", "idiot?", "??"], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 0]}
{"content": "fuck you \n\nMuthafucka ,  you jerk you scum lowlife loser !! hehe hahah188.23.179.183", "tokenize_content": ["fuck", "you", "mu", "##tha", "##fu", "##ck", "##a", ",", "you", "jerk", "you", "sc", "##um", "low", "##life", "loser", "!", "!", "he", "##he", "ha", "##ha", "##h", "##18", "##8", ".", "23", ".", "179", ".", "183"], "span": ["fuck you", "you mu", "mutha", "##thafu", "##fuck", "##cka", "##a,", ", you", "you jerk", "jerk you", "you sc", "scum", "##um low", "lowlife", "##life loser", "loser!", "!!", "! he", "hehe", "##he ha", "haha", "##hah", "##h18", "##188", "##8.", ". 23", "23.", ". 179", "179.", ". 183"], "toxic": 1, "score": [1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Miss me? Thought so. PENIS!", "tokenize_content": ["miss", "me", "?", "thought", "so", ".", "penis", "!"], "span": ["miss me", "me?", "? thought", "thought so", "so.", ". penis", "penis!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1]}
{"content": "stop pimping that shitty gwen gale slut", "tokenize_content": ["stop", "pi", "##mp", "##ing", "that", "shitty", "gwen", "gale", "sl", "##ut"], "span": ["stop pi", "pimp", "##mping", "##ing that", "that shitty", "shitty gwen", "gwen gale", "gale sl", "slut"], "toxic": 1, "score": [0, 0, 0, 0, 1, 0, 0, 0, 1]}
{"content": "unblock me you prick \n\nyeah", "tokenize_content": ["un", "##block", "me", "you", "prick", "yeah"], "span": ["unblock", "##block me", "me you", "you prick", "prick yeah"], "toxic": 1, "score": [0, 0, 0, 1, 0]}
{"content": "Power hungry assholes are annoying. Not pointing fingers...just a statement of fact.", "tokenize_content": ["power", "hungry", "asshole", "##s", "are", "annoying", ".", "not", "pointing", "fingers", ".", ".", ".", "just", "a", "statement", "of", "fact", "."], "span": ["power hungry", "hungry asshole", "assholes", "##s are", "are annoying", "annoying.", ". not", "not pointing", "pointing fingers", "fingers.", "..", "..", ". just", "just a", "a statement", "statement of", "of fact", "fact."], "toxic": 1, "score": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Would you like me to suck your penis", "tokenize_content": ["would", "you", "like", "me", "to", "suck", "your", "penis"], "span": ["would you", "you like", "like me", "me to", "to suck", "suck your", "your penis"], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 1]}
{"content": "Too bad that admins don't care about edit warring as much as they care about templates. (now this is where they probably block talk page access because I have the audacity to be sarcastic to one of the princes. )", "tokenize_content": ["too", "bad", "that", "ad", "##mins", "don", "'", "t", "care", "about", "edit", "warring", "as", "much", "as", "they", "care", "about", "template", "##s", ".", "(", "now", "this", "is", "where", "they", "probably", "block", "talk", "page", "access", "because", "i", "have", "the", "au", "##da", "##city", "to", "be", "sarcastic", "to", "one", "of", "the", "princes", ".", ")"], "span": ["too bad", "bad that", "that ad", "admins", "##mins don", "don '", "' t", "t care", "care about", "about edit", "edit warring", "warring as", "as much", "much as", "as they", "they care", "care about", "about template", "templates", "##s.", ". (", "( now", "now this", "this is", "is where", "where they", "they probably", "probably block", "block talk", "talk page", "page access", "access because", "because i", "i have", "have the", "the au", "auda", "##dacity", "##city to", "to be", "be sarcastic", "sarcastic to", "to one", "one of", "of the", "the princes", "princes.", ". )"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I         AM A nOOb. I suck bad.Real Bad. I am sorry for my uncivilised actions on wikipedia. Please forgive my noobness.", "tokenize_content": ["i", "am", "a", "no", "##ob", ".", "i", "suck", "bad", ".", "real", "bad", ".", "i", "am", "sorry", "for", "my", "un", "##ci", "##vili", "##sed", "actions", "on", "wikipedia", ".", "please", "forgive", "my", "no", "##ob", "##ness", "."], "span": ["i am", "am a", "a no", "noob", "##ob.", ". i", "i suck", "suck bad", "bad.", ". real", "real bad", "bad.", ". i", "i am", "am sorry", "sorry for", "for my", "my un", "unci", "##civili", "##vilised", "##sed actions", "actions on", "on wikipedia", "wikipedia.", ". please", "please forgive", "forgive my", "my no", "noob", "##obness", "##ness."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "AVALA you are full of shit. that is all. Love you bitch. Hahaha later. !!! )))___+++!!!!!!!!!!", "tokenize_content": ["ava", "##la", "you", "are", "full", "of", "shit", ".", "that", "is", "all", ".", "love", "you", "bitch", ".", "ha", "##ha", "##ha", "later", ".", "!", "!", "!", ")", ")", ")", "_", "_", "_", "+", "+", "+", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!"], "span": ["avala", "##la you", "you are", "are full", "full of", "of shit", "shit.", ". that", "that is", "is all", "all.", ". love", "love you", "you bitch", "bitch.", ". ha", "haha", "##haha", "##ha later", "later.", ".!", "!!", "!!", "! )", ") )", ") )", ") _", "_ _", "_ _", "_ +", "+ +", "+ +", "+!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\nThat article sucks. It's time to relist it and BLP<1E it.  type! snype? \"", "tokenize_content": ["\"", "that", "article", "sucks", ".", "it", "'", "s", "time", "to", "re", "##list", "it", "and", "b", "##lp", "<", "1", "##e", "it", ".", "type", "!", "s", "##ny", "##pe", "?", "\""], "span": ["\" that", "that article", "article sucks", "sucks.", ". it", "it '", "' s", "s time", "time to", "to re", "relist", "##list it", "it and", "and b", "blp", "##lp <", "< 1", "1e", "##e it", "it.", ". type", "type!", "! s", "sny", "##nype", "##pe?", "? \""], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "please delete my account i dont respect wikipedia anymore. suck ittttttt!!!!", "tokenize_content": ["please", "del", "##ete", "my", "account", "i", "don", "##t", "respect", "wikipedia", "anymore", ".", "suck", "it", "##tt", "##tt", "##tt", "!", "!", "!", "!"], "span": ["please del", "delete", "##ete my", "my account", "account i", "i don", "dont", "##t respect", "respect wikipedia", "wikipedia anymore", "anymore.", ". suck", "suck it", "ittt", "##tttt", "##tttt", "##tt!", "!!", "!!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "orgy \n\norgy penis pecker fuckstick", "tokenize_content": ["org", "##y", "org", "##y", "penis", "peck", "##er", "fuck", "##stick"], "span": ["orgy", "##y org", "orgy", "##y penis", "penis peck", "pecker", "##er fuck", "fuckstick"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 1, 1]}
{"content": ". Graeme Bartlet MUST BE KILLED BY S.T.INC FOR ABSOLUTELY NO REASON AT ALL. IT'S THE END OF THE WORLD", "tokenize_content": [".", "graeme", "bart", "##let", "must", "be", "killed", "by", "s", ".", "t", ".", "inc", "for", "absolutely", "no", "reason", "at", "all", ".", "it", "'", "s", "the", "end", "of", "the", "world"], "span": [". graeme", "graeme bart", "bartlet", "##let must", "must be", "be killed", "killed by", "by s", "s.", ". t", "t.", ". inc", "inc for", "for absolutely", "absolutely no", "no reason", "reason at", "at all", "all.", ". it", "it '", "' s", "s the", "the end", "end of", "of the", "the world"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Suck my penis, you nerdy virgin.", "tokenize_content": ["suck", "my", "penis", ",", "you", "ne", "##rdy", "virgin", "."], "span": ["suck my", "my penis", "penis,", ", you", "you ne", "nerdy", "##rdy virgin", "virgin."], "toxic": 1, "score": [1, 1, 1, 0, 0, 0, 0, 0]}
{"content": "hey motherfucker hurry up!", "tokenize_content": ["hey", "mother", "##fu", "##cker", "hurry", "up", "!"], "span": ["hey mother", "motherfu", "##fucker", "##cker hurry", "hurry up", "up!"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0]}
{"content": "Get a proper job kilt lifter", "tokenize_content": ["get", "a", "proper", "job", "ki", "##lt", "lift", "##er"], "span": ["get a", "a proper", "proper job", "job ki", "kilt", "##lt lift", "lifter"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0]}
{"content": "you fag israel is terrorism", "tokenize_content": ["you", "fa", "##g", "israel", "is", "terrorism"], "span": ["you fa", "fag", "##g israel", "israel is", "is terrorism"], "toxic": 1, "score": [0, 1, 0, 0, 0]}
{"content": "I will **** you. \n\nYou mess with my boy, you mess with me? understand? \n\nyahhhh", "tokenize_content": ["i", "will", "*", "*", "*", "*", "you", ".", "you", "mess", "with", "my", "boy", ",", "you", "mess", "with", "me", "?", "understand", "?", "ya", "##hh", "##hh"], "span": ["i will", "will *", "* *", "* *", "* *", "* you", "you.", ". you", "you mess", "mess with", "with my", "my boy", "boy,", ", you", "you mess", "mess with", "with me", "me?", "? understand", "understand?", "? ya", "yahh", "##hhhh"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "A message for you \n\nFuck you!\n\nGAYFullbuster!\n\nPut this finger in yourasshole, bastard!", "tokenize_content": ["a", "message", "for", "you", "fuck", "you", "!", "gay", "##ful", "##lb", "##ust", "##er", "!", "put", "this", "finger", "in", "your", "##ass", "##hole", ",", "bastard", "!"], "span": ["a message", "message for", "for you", "you fuck", "fuck you", "you!", "! gay", "gayful", "##fullb", "##lbust", "##uster", "##er!", "! put", "put this", "this finger", "finger in", "in your", "yourass", "##asshole", "##hole,", ", bastard", "bastard!"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1]}
{"content": "Wowwww. \n\nYou're really fucking ignorant. -", "tokenize_content": ["wow", "##w", "##w", "##w", ".", "you", "'", "re", "really", "fucking", "ignorant", ".", "-"], "span": ["woww", "##ww", "##ww", "##w.", ". you", "you '", "' re", "re really", "really fucking", "fucking ignorant", "ignorant.", ". -"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]}
{"content": "go fuck yourself \n\njohn cline sucks cock", "tokenize_content": ["go", "fuck", "yourself", "john", "cl", "##ine", "sucks", "cock"], "span": ["go fuck", "fuck yourself", "yourself john", "john cl", "cline", "##ine sucks", "sucks cock"], "toxic": 1, "score": [1, 1, 0, 0, 0, 1, 1]}
{"content": "GAY SEX,  ANAL, ALL NIGHT \n\nWhy are you reverting me? SPUI saya on his talk page that he doesn't want modifications to his talk page reverted. Pull your head out of your ass.", "tokenize_content": ["gay", "sex", ",", "anal", ",", "all", "night", "why", "are", "you", "rev", "##ert", "##ing", "me", "?", "sp", "##ui", "say", "##a", "on", "his", "talk", "page", "that", "he", "doesn", "'", "t", "want", "modifications", "to", "his", "talk", "page", "reverted", ".", "pull", "your", "head", "out", "of", "your", "ass", "."], "span": ["gay sex", "sex,", ", anal", "anal,", ", all", "all night", "night why", "why are", "are you", "you rev", "revert", "##erting", "##ing me", "me?", "? sp", "spui", "##ui say", "saya", "##a on", "on his", "his talk", "talk page", "page that", "that he", "he doesn", "doesn '", "' t", "t want", "want modifications", "modifications to", "to his", "his talk", "talk page", "page reverted", "reverted.", ". pull", "pull your", "your head", "head out", "out of", "of your", "your ass", "ass."], "toxic": 1, "score": [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "everybody fuck off \n\nwhy doesn't everybody just fuck off and leave this page alone? It was perfectly fine before people started fucking with it and removing shit. \n\nAnd no it does NOT sound like a promotional article. Fuck off.", "tokenize_content": ["everybody", "fuck", "off", "why", "doesn", "'", "t", "everybody", "just", "fuck", "off", "and", "leave", "this", "page", "alone", "?", "it", "was", "perfectly", "fine", "before", "people", "started", "fucking", "with", "it", "and", "removing", "shit", ".", "and", "no", "it", "does", "not", "sound", "like", "a", "promotional", "article", ".", "fuck", "off", "."], "span": ["everybody fuck", "fuck off", "off why", "why doesn", "doesn '", "' t", "t everybody", "everybody just", "just fuck", "fuck off", "off and", "and leave", "leave this", "this page", "page alone", "alone?", "? it", "it was", "was perfectly", "perfectly fine", "fine before", "before people", "people started", "started fucking", "fucking with", "with it", "it and", "and removing", "removing shit", "shit.", ". and", "and no", "no it", "it does", "does not", "not sound", "sound like", "like a", "a promotional", "promotional article", "article.", ". fuck", "fuck off", "off."], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "Umm why should i care what u hafta say.your gay.=]", "tokenize_content": ["umm", "why", "should", "i", "care", "what", "u", "ha", "##ft", "##a", "say", ".", "your", "gay", ".", "=", "]"], "span": ["umm why", "why should", "should i", "i care", "care what", "what u", "u ha", "haft", "##fta", "##a say", "say.", ". your", "your gay", "gay.", ". =", "= ]"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]}
{"content": "You piece of chickenshit cunt \n\nI'm going to have my way with the zero hedge article punk, and if you get in my way I'm going to rape your user page motherfucker.", "tokenize_content": ["you", "piece", "of", "chickens", "##hit", "cu", "##nt", "i", "'", "m", "going", "to", "have", "my", "way", "with", "the", "zero", "hedge", "article", "punk", ",", "and", "if", "you", "get", "in", "my", "way", "i", "'", "m", "going", "to", "rape", "your", "user", "page", "mother", "##fu", "##cker", "."], "span": ["you piece", "piece of", "of chickens", "chickenshit", "##hit cu", "cunt", "##nt i", "i '", "' m", "m going", "going to", "to have", "have my", "my way", "way with", "with the", "the zero", "zero hedge", "hedge article", "article punk", "punk,", ", and", "and if", "if you", "you get", "get in", "in my", "my way", "way i", "i '", "' m", "m going", "going to", "to rape", "rape your", "your user", "user page", "page mother", "motherfu", "##fucker", "##cker."], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1]}
{"content": "\\fuck you, who the shit is ari?", "tokenize_content": ["\\", "fuck", "you", ",", "who", "the", "shit", "is", "ari", "?"], "span": ["\\ fuck", "fuck you", "you,", ", who", "who the", "the shit", "shit is", "is ari", "ari?"], "toxic": 1, "score": [1, 1, 0, 0, 0, 1, 1, 0, 0]}
{"content": "Simply put, neither the song nor the penis are notable enough.   | (talk)", "tokenize_content": ["simply", "put", ",", "neither", "the", "song", "nor", "the", "penis", "are", "notable", "enough", ".", "|", "(", "talk", ")"], "span": ["simply put", "put,", ", neither", "neither the", "the song", "song nor", "nor the", "the penis", "penis are", "are notable", "notable enough", "enough.", ". |", "| (", "( talk", "talk )"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "hey everyone User: Xeno sucks on mens dick!!!!!!!", "tokenize_content": ["hey", "everyone", "user", ":", "x", "##eno", "sucks", "on", "men", "##s", "dick", "!", "!", "!", "!", "!", "!", "!"], "span": ["hey everyone", "everyone user", "user :", ": x", "xeno", "##eno sucks", "sucks on", "on men", "mens", "##s dick", "dick!", "!!", "!!", "!!", "!!", "!!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "Fuck shit kwa kwa kwa!", "tokenize_content": ["fuck", "shit", "kw", "##a", "kw", "##a", "kw", "##a", "!"], "span": ["fuck shit", "shit kw", "kwa", "##a kw", "kwa", "##a kw", "kwa", "##a!"], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "fuck u little bitch. im the porn king", "tokenize_content": ["fuck", "u", "little", "bitch", ".", "im", "the", "porn", "king"], "span": ["fuck u", "u little", "little bitch", "bitch.", ". im", "im the", "the porn", "porn king"], "toxic": 1, "score": [1, 0, 1, 1, 0, 0, 0, 0]}
{"content": "Wimpy whiny wimpy whiny", "tokenize_content": ["wi", "##mp", "##y", "w", "##hin", "##y", "wi", "##mp", "##y", "w", "##hin", "##y"], "span": ["wimp", "##mpy", "##y w", "whin", "##hiny", "##y wi", "wimp", "##mpy", "##y w", "whin", "##hiny"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "FUCK YOU KANSAS B\u0130TCH", "tokenize_content": ["fuck", "you", "kansas", "bitch"], "span": ["fuck you", "you kansas", "kansas bitch"], "toxic": 1, "score": [1, 0, 1]}
{"content": "Yes, you need to, because your fucking ass doesn't know shit about it AT ALL.Rocky", "tokenize_content": ["yes", ",", "you", "need", "to", ",", "because", "your", "fucking", "ass", "doesn", "'", "t", "know", "shit", "about", "it", "at", "all", ".", "rocky"], "span": ["yes,", ", you", "you need", "need to", "to,", ", because", "because your", "your fucking", "fucking ass", "ass doesn", "doesn '", "' t", "t know", "know shit", "shit about", "about it", "it at", "at all", "all.", ". rocky"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]}
{"content": "you bitch why does it matter it's the same goddamn thing all other nycs articles have that same sort of wording rathe than saying the end stop depending on which borough they are in so leave the fuck alone and cut your crap", "tokenize_content": ["you", "bitch", "why", "does", "it", "matter", "it", "'", "s", "the", "same", "goddamn", "thing", "all", "other", "nyc", "##s", "articles", "have", "that", "same", "sort", "of", "word", "##ing", "rat", "##he", "than", "saying", "the", "end", "stop", "depending", "on", "which", "borough", "they", "are", "in", "so", "leave", "the", "fuck", "alone", "and", "cut", "your", "crap"], "span": ["you bitch", "bitch why", "why does", "does it", "it matter", "matter it", "it '", "' s", "s the", "the same", "same goddamn", "goddamn thing", "thing all", "all other", "other nyc", "nycs", "##s articles", "articles have", "have that", "that same", "same sort", "sort of", "of word", "wording", "##ing rat", "rathe", "##he than", "than saying", "saying the", "the end", "end stop", "stop depending", "depending on", "on which", "which borough", "borough they", "they are", "are in", "in so", "so leave", "leave the", "the fuck", "fuck alone", "alone and", "and cut", "cut your", "your crap"], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1]}
{"content": "has a massive stick wedged firmly in his gaping ass crack and it's making him a little bit cranky", "tokenize_content": ["has", "a", "massive", "stick", "wedge", "##d", "firmly", "in", "his", "gaping", "ass", "crack", "and", "it", "'", "s", "making", "him", "a", "little", "bit", "crank", "##y"], "span": ["has a", "a massive", "massive stick", "stick wedge", "wedged", "##d firmly", "firmly in", "in his", "his gaping", "gaping ass", "ass crack", "crack and", "and it", "it '", "' s", "s making", "making him", "him a", "a little", "little bit", "bit crank", "cranky"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "See? \n\nI warned you not to piss me off, and you went ahead and did so.", "tokenize_content": ["see", "?", "i", "warned", "you", "not", "to", "piss", "me", "off", ",", "and", "you", "went", "ahead", "and", "did", "so", "."], "span": ["see?", "? i", "i warned", "warned you", "you not", "not to", "to piss", "piss me", "me off", "off,", ", and", "and you", "you went", "went ahead", "ahead and", "and did", "did so", "so."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Fuck off... 85.73.224.212", "tokenize_content": ["fuck", "off", ".", ".", ".", "85", ".", "73", ".", "224", ".", "212"], "span": ["fuck off", "off.", "..", "..", ". 85", "85.", ". 73", "73.", ". 224", "224.", ". 212"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "what the fuck was that!?", "tokenize_content": ["what", "the", "fuck", "was", "that", "!", "?"], "span": ["what the", "the fuck", "fuck was", "was that", "that!", "!?"], "toxic": 1, "score": [0, 1, 1, 0, 0, 0]}
{"content": "Utter nonsense. I questioned and I challenged and seemingly no-one has the balls.\n\nSTOP Wikipedia elitism.", "tokenize_content": ["utter", "nonsense", ".", "i", "questioned", "and", "i", "challenged", "and", "seemingly", "no", "-", "one", "has", "the", "balls", ".", "stop", "wikipedia", "eli", "##tism", "."], "span": ["utter nonsense", "nonsense.", ". i", "i questioned", "questioned and", "and i", "i challenged", "challenged and", "and seemingly", "seemingly no", "no -", "- one", "one has", "has the", "the balls", "balls.", ". stop", "stop wikipedia", "wikipedia eli", "elitism", "##tism."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]}
{"content": "I want to masturbate with you. ;;", "tokenize_content": ["i", "want", "to", "mast", "##ur", "##bate", "with", "you", ".", ";", ";"], "span": ["i want", "want to", "to mast", "mastur", "##urbate", "##bate with", "with you", "you.", ". ;", "; ;"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "hey \n\nhey pan dan. you're a cunt\n\nhave a nice day", "tokenize_content": ["hey", "hey", "pan", "dan", ".", "you", "'", "re", "a", "cu", "##nt", "have", "a", "nice", "day"], "span": ["hey hey", "hey pan", "pan dan", "dan.", ". you", "you '", "' re", "re a", "a cu", "cunt", "##nt have", "have a", "a nice", "nice day"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]}
{"content": "Ilegal \n\nwhat idiot made that law! cos it threatens an indosty this from a captisit country what a bunch of morons.", "tokenize_content": ["ile", "##gal", "what", "idiot", "made", "that", "law", "!", "co", "##s", "it", "threatens", "an", "indo", "##sty", "this", "from", "a", "capt", "##isi", "##t", "country", "what", "a", "bunch", "of", "mor", "##ons", "."], "span": ["ilegal", "##gal what", "what idiot", "idiot made", "made that", "that law", "law!", "! co", "cos", "##s it", "it threatens", "threatens an", "an indo", "indosty", "##sty this", "this from", "from a", "a capt", "captisi", "##isit", "##t country", "country what", "what a", "a bunch", "bunch of", "of mor", "morons", "##ons."], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}
{"content": "You are a FIRST RATE A-HOLE. I hope you never lose a child or someone in your life like the Burgess family and have people be so blatantly insentive to you as you are to them.  You are a disgrace!", "tokenize_content": ["you", "are", "a", "first", "rate", "a", "-", "hole", ".", "i", "hope", "you", "never", "lose", "a", "child", "or", "someone", "in", "your", "life", "like", "the", "burgess", "family", "and", "have", "people", "be", "so", "b", "##lat", "##antly", "ins", "##ent", "##ive", "to", "you", "as", "you", "are", "to", "them", ".", "you", "are", "a", "disgrace", "!"], "span": ["you are", "are a", "a first", "first rate", "rate a", "a -", "- hole", "hole.", ". i", "i hope", "hope you", "you never", "never lose", "lose a", "a child", "child or", "or someone", "someone in", "in your", "your life", "life like", "like the", "the burgess", "burgess family", "family and", "and have", "have people", "people be", "be so", "so b", "blat", "##latantly", "##antly ins", "insent", "##entive", "##ive to", "to you", "you as", "as you", "you are", "are to", "to them", "them.", ". you", "you are", "are a", "a disgrace", "disgrace!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Bollocks \n\nI'm away off for a while and may be some time.\n\nYou're a stupid cunt. \n\nCheers. 184.170.131.10", "tokenize_content": ["bo", "##llo", "##cks", "i", "'", "m", "away", "off", "for", "a", "while", "and", "may", "be", "some", "time", ".", "you", "'", "re", "a", "stupid", "cu", "##nt", ".", "cheers", ".", "184", ".", "170", ".", "131", ".", "10"], "span": ["bollo", "##llocks", "##cks i", "i '", "' m", "m away", "away off", "off for", "for a", "a while", "while and", "and may", "may be", "be some", "some time", "time.", ". you", "you '", "' re", "re a", "a stupid", "stupid cu", "cunt", "##nt.", ". cheers", "cheers.", ". 184", "184.", ". 170", "170.", ". 131", "131.", ". 10"], "toxic": 1, "score": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Waiting for Drag-Qeen Tony to ban Leather-queen Mark. TS is a whore who needs to send money to Jimbo's daugher.", "tokenize_content": ["waiting", "for", "drag", "-", "q", "##een", "tony", "to", "ban", "leather", "-", "queen", "mark", ".", "ts", "is", "a", "whore", "who", "needs", "to", "send", "money", "to", "jim", "##bo", "'", "s", "da", "##ugh", "##er", "."], "span": ["waiting for", "for drag", "drag -", "- q", "qeen", "##een tony", "tony to", "to ban", "ban leather", "leather -", "- queen", "queen mark", "mark.", ". ts", "ts is", "is a", "a whore", "whore who", "who needs", "needs to", "to send", "send money", "money to", "to jim", "jimbo", "##bo '", "' s", "s da", "daugh", "##ugher", "##er."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": ", and it's mean as shit", "tokenize_content": [",", "and", "it", "'", "s", "mean", "as", "shit"], "span": [", and", "and it", "it '", "' s", "s mean", "mean as", "as shit"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1]}
{"content": "Helo \n\nWassup I dnt know who the shit u r but ima whop yo ass for blocking me", "tokenize_content": ["he", "##lo", "was", "##su", "##p", "i", "d", "##nt", "know", "who", "the", "shit", "u", "r", "but", "im", "##a", "who", "##p", "yo", "ass", "for", "blocking", "me"], "span": ["helo", "##lo was", "wassu", "##sup", "##p i", "i d", "dnt", "##nt know", "know who", "who the", "the shit", "shit u", "u r", "r but", "but im", "ima", "##a who", "whop", "##p yo", "yo ass", "ass for", "for blocking", "blocking me"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "Saturn, your an ass, and I don't want your crap written on my page.  You're obviously not that smart.  Candidates must file with the FEC or their names cannot be on a ballot.  Catching on retard?", "tokenize_content": ["saturn", ",", "your", "an", "ass", ",", "and", "i", "don", "'", "t", "want", "your", "crap", "written", "on", "my", "page", ".", "you", "'", "re", "obviously", "not", "that", "smart", ".", "candidates", "must", "file", "with", "the", "fe", "##c", "or", "their", "names", "cannot", "be", "on", "a", "ballot", ".", "catching", "on", "re", "##tar", "##d", "?"], "span": ["saturn,", ", your", "your an", "an ass", "ass,", ", and", "and i", "i don", "don '", "' t", "t want", "want your", "your crap", "crap written", "written on", "on my", "my page", "page.", ". you", "you '", "' re", "re obviously", "obviously not", "not that", "that smart", "smart.", ". candidates", "candidates must", "must file", "file with", "with the", "the fe", "fec", "##c or", "or their", "their names", "names cannot", "cannot be", "be on", "on a", "a ballot", "ballot.", ". catching", "catching on", "on re", "retar", "##tard", "##d?"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I didn't mean that, but you are being a real jerk.  Calm down and breath, and realize if you didnt block people like a nazi, you wouldn't be such a douche.", "tokenize_content": ["i", "didn", "'", "t", "mean", "that", ",", "but", "you", "are", "being", "a", "real", "jerk", ".", "calm", "down", "and", "breath", ",", "and", "realize", "if", "you", "didn", "##t", "block", "people", "like", "a", "nazi", ",", "you", "wouldn", "'", "t", "be", "such", "a", "do", "##uche", "."], "span": ["i didn", "didn '", "' t", "t mean", "mean that", "that,", ", but", "but you", "you are", "are being", "being a", "a real", "real jerk", "jerk.", ". calm", "calm down", "down and", "and breath", "breath,", ", and", "and realize", "realize if", "if you", "you didn", "didnt", "##t block", "block people", "people like", "like a", "a nazi", "nazi,", ", you", "you wouldn", "wouldn '", "' t", "t be", "be such", "such a", "a do", "douche", "##uche."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "What are you talking about? When did I use my adminship in any argument? You are being ridiculous. -  (formerly ) talk", "tokenize_content": ["what", "are", "you", "talking", "about", "?", "when", "did", "i", "use", "my", "ad", "##mins", "##hip", "in", "any", "argument", "?", "you", "are", "being", "ridiculous", ".", "-", "(", "formerly", ")", "talk"], "span": ["what are", "are you", "you talking", "talking about", "about?", "? when", "when did", "did i", "i use", "use my", "my ad", "admins", "##minship", "##hip in", "in any", "any argument", "argument?", "? you", "you are", "are being", "being ridiculous", "ridiculous.", ". -", "- (", "( formerly", "formerly )", ") talk"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]}
{"content": "harass and threaten people", "tokenize_content": ["hara", "##ss", "and", "threaten", "people"], "span": ["harass", "##ss and", "and threaten", "threaten people"], "toxic": 1, "score": [0, 0, 0, 0]}
{"content": "YOu are one sick individual. The amount of lies you tell... wow... I am speechless. May God have Mercy on your soul.", "tokenize_content": ["you", "are", "one", "sick", "individual", ".", "the", "amount", "of", "lies", "you", "tell", ".", ".", ".", "wow", ".", ".", ".", "i", "am", "speechless", ".", "may", "god", "have", "mercy", "on", "your", "soul", "."], "span": ["you are", "are one", "one sick", "sick individual", "individual.", ". the", "the amount", "amount of", "of lies", "lies you", "you tell", "tell.", "..", "..", ". wow", "wow.", "..", "..", ". i", "i am", "am speechless", "speechless.", ". may", "may god", "god have", "have mercy", "mercy on", "on your", "your soul", "soul."], "toxic": 1, "score": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "She is only notable for being a second rate writer with homophobic views. She is a spiteful person with no real talent or skill, unlike the man she slated. Sack her. 82.6.12.212", "tokenize_content": ["she", "is", "only", "notable", "for", "being", "a", "second", "rate", "writer", "with", "homo", "##phobic", "views", ".", "she", "is", "a", "spite", "##ful", "person", "with", "no", "real", "talent", "or", "skill", ",", "unlike", "the", "man", "she", "slated", ".", "sack", "her", ".", "82", ".", "6", ".", "12", ".", "212"], "span": ["she is", "is only", "only notable", "notable for", "for being", "being a", "a second", "second rate", "rate writer", "writer with", "with homo", "homophobic", "##phobic views", "views.", ". she", "she is", "is a", "a spite", "spiteful", "##ful person", "person with", "with no", "no real", "real talent", "talent or", "or skill", "skill,", ", unlike", "unlike the", "the man", "man she", "she slated", "slated.", ". sack", "sack her", "her.", ". 82", "82.", ". 6", "6.", ". 12", "12.", ". 212"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "do you know that girl NwJerseyLiz? She did stupid things on wikipedia. Be carefull!", "tokenize_content": ["do", "you", "know", "that", "girl", "nw", "##jer", "##sey", "##li", "##z", "?", "she", "did", "stupid", "things", "on", "wikipedia", ".", "be", "careful", "##l", "!"], "span": ["do you", "you know", "know that", "that girl", "girl nw", "nwjer", "##jersey", "##seyli", "##liz", "##z?", "? she", "she did", "did stupid", "stupid things", "things on", "on wikipedia", "wikipedia.", ". be", "be careful", "carefull", "##l!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "screw you\ni do what i want", "tokenize_content": ["screw", "you", "i", "do", "what", "i", "want"], "span": ["screw you", "you i", "i do", "do what", "what i", "i want"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0]}
{"content": "YOURE A FAG. AND IF YOU WRITE ANYTHING ELSE ON MY TALK PAGE IN RESPONSE TO THIS, THAT IS HOW YOU WILL ADMIT BEING A FAG.", "tokenize_content": ["your", "##e", "a", "fa", "##g", ".", "and", "if", "you", "write", "anything", "else", "on", "my", "talk", "page", "in", "response", "to", "this", ",", "that", "is", "how", "you", "will", "admit", "being", "a", "fa", "##g", "."], "span": ["youre", "##e a", "a fa", "fag", "##g.", ". and", "and if", "if you", "you write", "write anything", "anything else", "else on", "on my", "my talk", "talk page", "page in", "in response", "response to", "to this", "this,", ", that", "that is", "is how", "how you", "you will", "will admit", "admit being", "being a", "a fa", "fag", "##g."], "toxic": 1, "score": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}
{"content": "I didnt attack you, you retard\nDO NOT POST ON MY PAGE\nkthx\n80.192.85.232", "tokenize_content": ["i", "didn", "##t", "attack", "you", ",", "you", "re", "##tar", "##d", "do", "not", "post", "on", "my", "page", "k", "##th", "##x", "80", ".", "192", ".", "85", ".", "232"], "span": ["i didn", "didnt", "##t attack", "attack you", "you,", ", you", "you re", "retar", "##tard", "##d do", "do not", "not post", "post on", "on my", "my page", "page k", "kth", "##thx", "##x 80", "80.", ". 192", "192.", ". 85", "85.", ". 232"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "LAY OFF\nBack off reverting my letter to newyorkbrad, jerk. Or does this have to get personal?", "tokenize_content": ["lay", "off", "back", "off", "rev", "##ert", "##ing", "my", "letter", "to", "new", "##yo", "##rk", "##bra", "##d", ",", "jerk", ".", "or", "does", "this", "have", "to", "get", "personal", "?"], "span": ["lay off", "off back", "back off", "off rev", "revert", "##erting", "##ing my", "my letter", "letter to", "to new", "newyo", "##york", "##rkbra", "##brad", "##d,", ", jerk", "jerk.", ". or", "or does", "does this", "this have", "have to", "to get", "get personal", "personal?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Page should just be deleted. \n\nNo, seriously.\n\nObviously some stooge from Teletoon just pasted in the marketing boilerplate on this crapass show made from stolen ideas.\n\nThe whole page is non-notable just like the crappy show.", "tokenize_content": ["page", "should", "just", "be", "deleted", ".", "no", ",", "seriously", ".", "obviously", "some", "st", "##oo", "##ge", "from", "tel", "##eto", "##on", "just", "paste", "##d", "in", "the", "marketing", "boiler", "##plate", "on", "this", "crap", "##ass", "show", "made", "from", "stolen", "ideas", ".", "the", "whole", "page", "is", "non", "-", "notable", "just", "like", "the", "crap", "##py", "show", "."], "span": ["page should", "should just", "just be", "be deleted", "deleted.", ". no", "no,", ", seriously", "seriously.", ". obviously", "obviously some", "some st", "stoo", "##ooge", "##ge from", "from tel", "teleto", "##etoon", "##on just", "just paste", "pasted", "##d in", "in the", "the marketing", "marketing boiler", "boilerplate", "##plate on", "on this", "this crap", "crapass", "##ass show", "show made", "made from", "from stolen", "stolen ideas", "ideas.", ". the", "the whole", "whole page", "page is", "is non", "non -", "- notable", "notable just", "just like", "like the", "the crap", "crappy", "##py show", "show."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]}
{"content": "Ban me \n\nHello, could you ban me? I'm the fucker you threatened with contacting my provider (telenet), so how is that going? So ban me again, idiot.", "tokenize_content": ["ban", "me", "hello", ",", "could", "you", "ban", "me", "?", "i", "'", "m", "the", "fuck", "##er", "you", "threatened", "with", "contact", "##ing", "my", "provider", "(", "tel", "##ene", "##t", ")", ",", "so", "how", "is", "that", "going", "?", "so", "ban", "me", "again", ",", "idiot", "."], "span": ["ban me", "me hello", "hello,", ", could", "could you", "you ban", "ban me", "me?", "? i", "i '", "' m", "m the", "the fuck", "fucker", "##er you", "you threatened", "threatened with", "with contact", "contacting", "##ing my", "my provider", "provider (", "( tel", "telene", "##enet", "##t )", "),", ", so", "so how", "how is", "is that", "that going", "going?", "? so", "so ban", "ban me", "me again", "again,", ", idiot", "idiot."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "MATE, you are pathetic, just pathetic", "tokenize_content": ["mate", ",", "you", "are", "pathetic", ",", "just", "pathetic"], "span": ["mate,", ", you", "you are", "are pathetic", "pathetic,", ", just", "just pathetic"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 1]}
{"content": "That newspaper picture\nIs stupid as hell.", "tokenize_content": ["that", "newspaper", "picture", "is", "stupid", "as", "hell", "."], "span": ["that newspaper", "newspaper picture", "picture is", "is stupid", "stupid as", "as hell", "hell."], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0]}
{"content": "You moron\u2014I did no such thing. I reverted the addition of scare quotes to the article. And I'm about to do it again. \u2014\u00a0\u00a0Talk/Stalk", "tokenize_content": ["you", "mor", "##on", "\u2014", "i", "did", "no", "such", "thing", ".", "i", "reverted", "the", "addition", "of", "scare", "quotes", "to", "the", "article", ".", "and", "i", "'", "m", "about", "to", "do", "it", "again", ".", "\u2014", "talk", "/", "stalk"], "span": ["you mor", "moron", "##on \u2014", "\u2014 i", "i did", "did no", "no such", "such thing", "thing.", ". i", "i reverted", "reverted the", "the addition", "addition of", "of scare", "scare quotes", "quotes to", "to the", "the article", "article.", ". and", "and i", "i '", "' m", "m about", "about to", "to do", "do it", "it again", "again.", ". \u2014", "\u2014 talk", "talk /", "/ stalk"], "toxic": 1, "score": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\nYou call MacDonald's a part of your \"\"culture\"\"? Nonsense! Spend some 10 years in France, and then you will have a hint of what Culture is!   \"", "tokenize_content": ["\"", "you", "call", "macdonald", "'", "s", "a", "part", "of", "your", "\"", "\"", "culture", "\"", "\"", "?", "nonsense", "!", "spend", "some", "10", "years", "in", "france", ",", "and", "then", "you", "will", "have", "a", "hint", "of", "what", "culture", "is", "!", "\""], "span": ["\" you", "you call", "call macdonald", "macdonald '", "' s", "s a", "a part", "part of", "of your", "your \"", "\" \"", "\" culture", "culture \"", "\" \"", "\"?", "? nonsense", "nonsense!", "! spend", "spend some", "some 10", "10 years", "years in", "in france", "france,", ", and", "and then", "then you", "you will", "will have", "have a", "a hint", "hint of", "of what", "what culture", "culture is", "is!", "! \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "hey bro \n\nHAPPY THANXGIVING FUCKFACE GET A LIFE", "tokenize_content": ["hey", "bro", "happy", "than", "##x", "##giving", "fuck", "##face", "get", "a", "life"], "span": ["hey bro", "bro happy", "happy than", "thanx", "##xgiving", "##giving fuck", "fuckface", "##face get", "get a", "a life"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0]}
{"content": "I WILL FUCK YOU UP, YOU IRISH PANSY \n\nFUCK YOUR MOTHER", "tokenize_content": ["i", "will", "fuck", "you", "up", ",", "you", "irish", "pan", "##sy", "fuck", "your", "mother"], "span": ["i will", "will fuck", "fuck you", "you up", "up,", ", you", "you irish", "irish pan", "pansy", "##sy fuck", "fuck your", "your mother"], "toxic": 1, "score": [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "yuck \n\nyour one of the most disgusting creatures ive ever met", "tokenize_content": ["yu", "##ck", "your", "one", "of", "the", "most", "disgusting", "creatures", "iv", "##e", "ever", "met"], "span": ["yuck", "##ck your", "your one", "one of", "of the", "the most", "most disgusting", "disgusting creatures", "creatures iv", "ive", "##e ever", "ever met"], "toxic": 1, "score": [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]}
{"content": "she is a little lesbian", "tokenize_content": ["she", "is", "a", "little", "lesbian"], "span": ["she is", "is a", "a little", "little lesbian"], "toxic": 1, "score": [0, 0, 0, 1]}
{"content": "Your a twat, you just delete things that you dont have a clue about! Che Finlay Will orientate your ass!! He'l find you!!", "tokenize_content": ["your", "a", "t", "##wat", ",", "you", "just", "del", "##ete", "things", "that", "you", "don", "##t", "have", "a", "clue", "about", "!", "che", "fin", "##lay", "will", "orient", "##ate", "your", "ass", "!", "!", "he", "'", "l", "find", "you", "!", "!"], "span": ["your a", "a t", "twat", "##wat,", ", you", "you just", "just del", "delete", "##ete things", "things that", "that you", "you don", "dont", "##t have", "have a", "a clue", "clue about", "about!", "! che", "che fin", "finlay", "##lay will", "will orient", "orientate", "##ate your", "your ass", "ass!", "!!", "! he", "he '", "' l", "l find", "find you", "you!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\nwell, i suppose, i spoke with a wrong person.... you're just as fucked up as the other user who posted the \"\"study\"\".\n\np.s. fuck you you fucking government shill\"", "tokenize_content": ["\"", "well", ",", "i", "suppose", ",", "i", "spoke", "with", "a", "wrong", "person", ".", ".", ".", ".", "you", "'", "re", "just", "as", "fucked", "up", "as", "the", "other", "user", "who", "posted", "the", "\"", "\"", "study", "\"", "\"", ".", "p", ".", "s", ".", "fuck", "you", "you", "fucking", "government", "shi", "##ll", "\""], "span": ["\" well", "well,", ", i", "i suppose", "suppose,", ", i", "i spoke", "spoke with", "with a", "a wrong", "wrong person", "person.", "..", "..", "..", ". you", "you '", "' re", "re just", "just as", "as fucked", "fucked up", "up as", "as the", "the other", "other user", "user who", "who posted", "posted the", "the \"", "\" \"", "\" study", "study \"", "\" \"", "\".", ". p", "p.", ". s", "s.", ". fuck", "fuck you", "you you", "you fucking", "fucking government", "government shi", "shill", "##ll \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]}
{"content": "Hi there! \n\nYou wanna fuck my ass?", "tokenize_content": ["hi", "there", "!", "you", "wanna", "fuck", "my", "ass", "?"], "span": ["hi there", "there!", "! you", "you wanna", "wanna fuck", "fuck my", "my ass", "ass?"], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 1, 1]}
{"content": "if u hate cena again,you will be blocked from editing,your final chance!\nuser:dark-hooded smoker", "tokenize_content": ["if", "u", "hate", "ce", "##na", "again", ",", "you", "will", "be", "blocked", "from", "editing", ",", "your", "final", "chance", "!", "user", ":", "dark", "-", "hooded", "smoke", "##r"], "span": ["if u", "u hate", "hate ce", "cena", "##na again", "again,", ", you", "you will", "will be", "be blocked", "blocked from", "from editing", "editing,", ", your", "your final", "final chance", "chance!", "! user", "user :", ": dark", "dark -", "- hooded", "hooded smoke", "smoker"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "YOU DON'T KNOW ABOUT THE HISTORY!!,I THINK YOU ARE THE BIG LOSER", "tokenize_content": ["you", "don", "'", "t", "know", "about", "the", "history", "!", "!", ",", "i", "think", "you", "are", "the", "big", "loser"], "span": ["you don", "don '", "' t", "t know", "know about", "about the", "the history", "history!", "!!", "!,", ", i", "i think", "think you", "you are", "are the", "the big", "big loser"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "Everyone knows Tony Sidaway is gay.", "tokenize_content": ["everyone", "knows", "tony", "sid", "##away", "is", "gay", "."], "span": ["everyone knows", "knows tony", "tony sid", "sidaway", "##away is", "is gay", "gay."], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 0]}
{"content": "Also, I have the fucking rights to advertise my youtube.com videos1", "tokenize_content": ["also", ",", "i", "have", "the", "fucking", "rights", "to", "ad", "##vert", "##ise", "my", "youtube", ".", "com", "videos", "##1"], "span": ["also,", ", i", "i have", "have the", "the fucking", "fucking rights", "rights to", "to ad", "advert", "##vertise", "##ise my", "my youtube", "youtube.", ". com", "com videos", "videos1"], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Missrain4, I will make a rain of cum on your face.", "tokenize_content": ["miss", "##rain", "##4", ",", "i", "will", "make", "a", "rain", "of", "cum", "on", "your", "face", "."], "span": ["missrain", "##rain4", "##4,", ", i", "i will", "will make", "make a", "a rain", "rain of", "of cum", "cum on", "on your", "your face", "face."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]}
{"content": "YOU ARE A FAGGIT. DARRY WAS HERE AS A FAGGIT. LET ME TALK TRASH TO KURT WARNER.", "tokenize_content": ["you", "are", "a", "fa", "##gg", "##it", ".", "dar", "##ry", "was", "here", "as", "a", "fa", "##gg", "##it", ".", "let", "me", "talk", "trash", "to", "kurt", "warner", "."], "span": ["you are", "are a", "a fa", "fagg", "##ggit", "##it.", ". dar", "darry", "##ry was", "was here", "here as", "as a", "a fa", "fagg", "##ggit", "##it.", ". let", "let me", "me talk", "talk trash", "trash to", "to kurt", "kurt warner", "warner."], "toxic": 1, "score": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]}
{"content": "This girl is an emo cunt", "tokenize_content": ["this", "girl", "is", "an", "em", "##o", "cu", "##nt"], "span": ["this girl", "girl is", "is an", "an em", "emo", "##o cu", "cunt"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1]}
{"content": "ORLY? Fuck You Again n00b", "tokenize_content": ["or", "##ly", "?", "fuck", "you", "again", "n", "##00", "##b"], "span": ["orly", "##ly?", "? fuck", "fuck you", "you again", "again n", "n00", "##00b"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "Haha!! You're both such losers!", "tokenize_content": ["ha", "##ha", "!", "!", "you", "'", "re", "both", "such", "losers", "!"], "span": ["haha", "##ha!", "!!", "! you", "you '", "' re", "re both", "both such", "such losers", "losers!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "You are crazy man. You keep deleting my posts; no admin is like that. You are no admin. Wow...", "tokenize_content": ["you", "are", "crazy", "man", ".", "you", "keep", "del", "##eti", "##ng", "my", "posts", ";", "no", "ad", "##min", "is", "like", "that", ".", "you", "are", "no", "ad", "##min", ".", "wow", ".", ".", "."], "span": ["you are", "are crazy", "crazy man", "man.", ". you", "you keep", "keep del", "deleti", "##eting", "##ng my", "my posts", "posts ;", "; no", "no ad", "admin", "##min is", "is like", "like that", "that.", ". you", "you are", "are no", "no ad", "admin", "##min.", ". wow", "wow.", "..", ".."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "good night \n\nGood night fucking shit that you may be upset because I do bullshit on wikipedia but you cock is worth what I do \nSo let me in peace, or you swear that all the editing wikipedia pages without exception", "tokenize_content": ["good", "night", "good", "night", "fucking", "shit", "that", "you", "may", "be", "upset", "because", "i", "do", "bullshit", "on", "wikipedia", "but", "you", "cock", "is", "worth", "what", "i", "do", "so", "let", "me", "in", "peace", ",", "or", "you", "swear", "that", "all", "the", "editing", "wikipedia", "pages", "without", "exception"], "span": ["good night", "night good", "good night", "night fucking", "fucking shit", "shit that", "that you", "you may", "may be", "be upset", "upset because", "because i", "i do", "do bullshit", "bullshit on", "on wikipedia", "wikipedia but", "but you", "you cock", "cock is", "is worth", "worth what", "what i", "i do", "do so", "so let", "let me", "me in", "in peace", "peace,", ", or", "or you", "you swear", "swear that", "that all", "all the", "the editing", "editing wikipedia", "wikipedia pages", "pages without", "without exception"], "toxic": 1, "score": [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Your full of shit. What, is the big, bad Zion conspiracy after you for your truth-spewing.\n\nWhat a harpy...", "tokenize_content": ["your", "full", "of", "shit", ".", "what", ",", "is", "the", "big", ",", "bad", "zion", "conspiracy", "after", "you", "for", "your", "truth", "-", "sp", "##ew", "##ing", ".", "what", "a", "harp", "##y", ".", ".", "."], "span": ["your full", "full of", "of shit", "shit.", ". what", "what,", ", is", "is the", "the big", "big,", ", bad", "bad zion", "zion conspiracy", "conspiracy after", "after you", "you for", "for your", "your truth", "truth -", "- sp", "spew", "##ewing", "##ing.", ". what", "what a", "a harp", "harpy", "##y.", "..", ".."], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "really want cramers balls in your mouth huh?", "tokenize_content": ["really", "want", "cramer", "##s", "balls", "in", "your", "mouth", "huh", "?"], "span": ["really want", "want cramer", "cramers", "##s balls", "balls in", "in your", "your mouth", "mouth huh", "huh?"], "toxic": 1, "score": [0, 0, 0, 1, 0, 0, 0, 0, 0]}
{"content": "No, maybe you should get a life instead of being like a shot to revert my vandalism on a page relating to a game nobody has talked about in the last two years. Wiki = made you their bitch.", "tokenize_content": ["no", ",", "maybe", "you", "should", "get", "a", "life", "instead", "of", "being", "like", "a", "shot", "to", "rev", "##ert", "my", "van", "##dal", "##ism", "on", "a", "page", "relating", "to", "a", "game", "nobody", "has", "talked", "about", "in", "the", "last", "two", "years", ".", "wi", "##ki", "=", "made", "you", "their", "bitch", "."], "span": ["no,", ", maybe", "maybe you", "you should", "should get", "get a", "a life", "life instead", "instead of", "of being", "being like", "like a", "a shot", "shot to", "to rev", "revert", "##ert my", "my van", "vandal", "##dalism", "##ism on", "on a", "a page", "page relating", "relating to", "to a", "a game", "game nobody", "nobody has", "has talked", "talked about", "about in", "in the", "the last", "last two", "two years", "years.", ". wi", "wiki", "##ki =", "= made", "made you", "you their", "their bitch", "bitch."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "PLEASE STOP RUINING MY LEGITIMATE EDIT. THANK YOU. - A NIGGER.", "tokenize_content": ["please", "stop", "ruining", "my", "legitimate", "edit", ".", "thank", "you", ".", "-", "a", "ni", "##gger", "."], "span": ["please stop", "stop ruining", "ruining my", "my legitimate", "legitimate edit", "edit.", ". thank", "thank you", "you.", ". -", "- a", "a ni", "nigger", "##gger."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "For the record, I did have a valid reason for removeing the section I did which was on the discussion portion of that page.  M1ss1ontomars2k4 is a fucking anal control freak like about a million other wikipedia members.", "tokenize_content": ["for", "the", "record", ",", "i", "did", "have", "a", "valid", "reason", "for", "remove", "##ing", "the", "section", "i", "did", "which", "was", "on", "the", "discussion", "portion", "of", "that", "page", ".", "m1", "##ss", "##1", "##ont", "##oma", "##rs", "##2", "##k", "##4", "is", "a", "fucking", "anal", "control", "freak", "like", "about", "a", "million", "other", "wikipedia", "members", "."], "span": ["for the", "the record", "record,", ", i", "i did", "did have", "have a", "a valid", "valid reason", "reason for", "for remove", "removeing", "##ing the", "the section", "section i", "i did", "did which", "which was", "was on", "on the", "the discussion", "discussion portion", "portion of", "of that", "that page", "page.", ". m1", "m1ss", "##ss1", "##1ont", "##ontoma", "##omars", "##rs2", "##2k", "##k4", "##4 is", "is a", "a fucking", "fucking anal", "anal control", "control freak", "freak like", "like about", "about a", "a million", "million other", "other wikipedia", "wikipedia members", "members."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "And why the fuck should i care? \n\ng e t  r i d  o f  a l l  i  d i d  p l e a s e  j a ck a s s", "tokenize_content": ["and", "why", "the", "fuck", "should", "i", "care", "?", "g", "e", "t", "r", "i", "d", "o", "f", "a", "l", "l", "i", "d", "i", "d", "p", "l", "e", "a", "s", "e", "j", "a", "ck", "a", "s", "s"], "span": ["and why", "why the", "the fuck", "fuck should", "should i", "i care", "care?", "? g", "g e", "e t", "t r", "r i", "i d", "d o", "o f", "f a", "a l", "l l", "l i", "i d", "d i", "i d", "d p", "p l", "l e", "e a", "a s", "s e", "e j", "j a", "a ck", "ck a", "a s", "s s"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "What the f*** do you want at my talk page. I got no time to spend with you kiddo.", "tokenize_content": ["what", "the", "f", "*", "*", "*", "do", "you", "want", "at", "my", "talk", "page", ".", "i", "got", "no", "time", "to", "spend", "with", "you", "kidd", "##o", "."], "span": ["what the", "the f", "f *", "* *", "* *", "* do", "do you", "you want", "want at", "at my", "my talk", "talk page", "page.", ". i", "i got", "got no", "no time", "time to", "to spend", "spend with", "with you", "you kidd", "kiddo", "##o."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "(UTC)\nChrist what a dumb question.21:37, 31 December 2009", "tokenize_content": ["(", "utc", ")", "christ", "what", "a", "dumb", "question", ".", "21", ":", "37", ",", "31", "december", "2009"], "span": ["( utc", "utc )", ") christ", "christ what", "what a", "a dumb", "dumb question", "question.", ". 21", "21 :", ": 37", "37,", ", 31", "31 december", "december 2009"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Dear Snigbrook \n\nYour days are numbered, the stabbing knife is headed your way! Be prepared for HORRIBLE HORRIBLE THINGS!!!\n\nP.S you are a fucking aspie hahaha", "tokenize_content": ["dear", "s", "##nig", "##brook", "your", "days", "are", "numbered", ",", "the", "stabbing", "knife", "is", "headed", "your", "way", "!", "be", "prepared", "for", "horrible", "horrible", "things", "!", "!", "!", "p", ".", "s", "you", "are", "a", "fucking", "as", "##pie", "ha", "##ha", "##ha"], "span": ["dear s", "snig", "##nigbrook", "##brook your", "your days", "days are", "are numbered", "numbered,", ", the", "the stabbing", "stabbing knife", "knife is", "is headed", "headed your", "your way", "way!", "! be", "be prepared", "prepared for", "for horrible", "horrible horrible", "horrible things", "things!", "!!", "!!", "! p", "p.", ". s", "s you", "you are", "are a", "a fucking", "fucking as", "aspie", "##pie ha", "haha", "##haha"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "hey look at this shit vandalism! \n\nFirst image on the Web", "tokenize_content": ["hey", "look", "at", "this", "shit", "van", "##dal", "##ism", "!", "first", "image", "on", "the", "web"], "span": ["hey look", "look at", "at this", "this shit", "shit van", "vandal", "##dalism", "##ism!", "! first", "first image", "image on", "on the", "the web"], "toxic": 1, "score": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "WIKIPEDIA SUX RANK FAGOTY ASS ==", "tokenize_content": ["wikipedia", "su", "##x", "rank", "fa", "##go", "##ty", "ass", "=", "="], "span": ["wikipedia su", "sux", "##x rank", "rank fa", "fago", "##goty", "##ty ass", "ass =", "= ="], "toxic": 1, "score": [0, 0, 0, 0, 1, 0, 1, 1, 0]}
{"content": "I agree, this guy is a piece of shit!", "tokenize_content": ["i", "agree", ",", "this", "guy", "is", "a", "piece", "of", "shit", "!"], "span": ["i agree", "agree,", ", this", "this guy", "guy is", "is a", "a piece", "piece of", "of shit", "shit!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "\"\n\n Stop \n\nJust stop!! okay? Quit removing championships from the AAA page without reason, you've been told to stop once or twice already - it's vandalism to remove information that's valid.\u00a0(No Drama) Talk\u00a0 \"", "tokenize_content": ["\"", "stop", "just", "stop", "!", "!", "okay", "?", "quit", "removing", "championships", "from", "the", "aaa", "page", "without", "reason", ",", "you", "'", "ve", "been", "told", "to", "stop", "once", "or", "twice", "already", "-", "it", "'", "s", "van", "##dal", "##ism", "to", "remove", "information", "that", "'", "s", "valid", ".", "(", "no", "drama", ")", "talk", "\""], "span": ["\" stop", "stop just", "just stop", "stop!", "!!", "! okay", "okay?", "? quit", "quit removing", "removing championships", "championships from", "from the", "the aaa", "aaa page", "page without", "without reason", "reason,", ", you", "you '", "' ve", "ve been", "been told", "told to", "to stop", "stop once", "once or", "or twice", "twice already", "already -", "- it", "it '", "' s", "s van", "vandal", "##dalism", "##ism to", "to remove", "remove information", "information that", "that '", "' s", "s valid", "valid.", ". (", "( no", "no drama", "drama )", ") talk", "talk \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Just another bitter Zionist pig. Leave Nableezy alone!", "tokenize_content": ["just", "another", "bitter", "zionist", "pig", ".", "leave", "na", "##ble", "##ez", "##y", "alone", "!"], "span": ["just another", "another bitter", "bitter zionist", "zionist pig", "pig.", ". leave", "leave na", "nable", "##bleez", "##ezy", "##y alone", "alone!"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Eddits \n\nWho the fuck are you to be reversing my eddits and such?  Mind your own fucking business, jerk.", "tokenize_content": ["ed", "##dit", "##s", "who", "the", "fuck", "are", "you", "to", "be", "rev", "##ers", "##ing", "my", "ed", "##dit", "##s", "and", "such", "?", "mind", "your", "own", "fucking", "business", ",", "jerk", "."], "span": ["eddit", "##dits", "##s who", "who the", "the fuck", "fuck are", "are you", "you to", "to be", "be rev", "revers", "##ersing", "##ing my", "my ed", "eddit", "##dits", "##s and", "and such", "such?", "? mind", "mind your", "your own", "own fucking", "fucking business", "business,", ", jerk", "jerk."], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1]}
{"content": "Fuck you!!!You are a pig!", "tokenize_content": ["fuck", "you", "!", "!", "!", "you", "are", "a", "pig", "!"], "span": ["fuck you", "you!", "!!", "!!", "! you", "you are", "are a", "a pig", "pig!"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "' Bold text \n'BRIDGER IS THE MOTHER FUCKING SHIIIIIIIIIIIT. NIGGA!!!", "tokenize_content": ["'", "bold", "text", "'", "bridge", "##r", "is", "the", "mother", "fucking", "shi", "##iii", "##iii", "##iii", "##it", ".", "ni", "##gga", "!", "!", "!"], "span": ["' bold", "bold text", "text '", "' bridge", "bridger", "##r is", "is the", "the mother", "mother fucking", "fucking shi", "shiiii", "##iiiiii", "##iiiiii", "##iiiit", "##it.", ". ni", "nigga", "##gga!", "!!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]}
{"content": "He did blunt it by altering the stress, though: GIVE a damn instead of give a DAMN.", "tokenize_content": ["he", "did", "blunt", "it", "by", "altering", "the", "stress", ",", "though", ":", "give", "a", "damn", "instead", "of", "give", "a", "damn", "."], "span": ["he did", "did blunt", "blunt it", "it by", "by altering", "altering the", "the stress", "stress,", ", though", "though :", ": give", "give a", "a damn", "damn instead", "instead of", "of give", "give a", "a damn", "damn."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]}
{"content": "The leftist cowards are so afraid of terrorist attacks that they will bend over backwards for the Muhammadans.", "tokenize_content": ["the", "leftist", "coward", "##s", "are", "so", "afraid", "of", "terrorist", "attacks", "that", "they", "will", "bend", "over", "backwards", "for", "the", "muhammad", "##ans", "."], "span": ["the leftist", "leftist coward", "cowards", "##s are", "are so", "so afraid", "afraid of", "of terrorist", "terrorist attacks", "attacks that", "that they", "they will", "will bend", "bend over", "over backwards", "backwards for", "for the", "the muhammad", "muhammadans", "##ans."], "toxic": 1, "score": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "hey you deleted your bio and stuff, that kinda sucks =/", "tokenize_content": ["hey", "you", "deleted", "your", "bio", "and", "stuff", ",", "that", "kinda", "sucks", "=", "/"], "span": ["hey you", "you deleted", "deleted your", "your bio", "bio and", "and stuff", "stuff,", ", that", "that kinda", "kinda sucks", "sucks =", "= /"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "We dont cares about you,  is a fucking shit, bitch............. 195.30.108.27", "tokenize_content": ["we", "don", "##t", "cares", "about", "you", ",", "is", "a", "fucking", "shit", ",", "bitch", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "195", ".", "30", ".", "108", ".", "27"], "span": ["we don", "dont", "##t cares", "cares about", "about you", "you,", ", is", "is a", "a fucking", "fucking shit", "shit,", ", bitch", "bitch.", "..", "..", "..", "..", "..", "..", "..", "..", "..", "..", "..", "..", ". 195", "195.", ". 30", "30.", ". 108", "108.", ". 27"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "ALL OF YOU COCK CUCKING FAGGOTS AND RULE ABIDERS GO THE FUCK HOME!\n\nFUCK YOU,\n\nMIKEY", "tokenize_content": ["all", "of", "you", "cock", "cu", "##cking", "fa", "##gg", "##ots", "and", "rule", "ab", "##ider", "##s", "go", "the", "fuck", "home", "!", "fuck", "you", ",", "mikey"], "span": ["all of", "of you", "you cock", "cock cu", "cucking", "##cking fa", "fagg", "##ggots", "##ots and", "and rule", "rule ab", "abider", "##iders", "##s go", "go the", "the fuck", "fuck home", "home!", "! fuck", "fuck you", "you,", ", mikey"], "toxic": 1, "score": [0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0]}
{"content": "Nazis \n\nAnyone who believes that Jews should be kicked out of their native homeland is a Nazi propagandist.", "tokenize_content": ["nazis", "anyone", "who", "believes", "that", "jews", "should", "be", "kicked", "out", "of", "their", "native", "homeland", "is", "a", "nazi", "prop", "##aga", "##ndi", "##st", "."], "span": ["nazis anyone", "anyone who", "who believes", "believes that", "that jews", "jews should", "should be", "be kicked", "kicked out", "out of", "of their", "their native", "native homeland", "homeland is", "is a", "a nazi", "nazi prop", "propaga", "##agandi", "##ndist", "##st."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\n Whoa! \n\nHaha, aren't you glad I didn't put a section called \"\"Penis size\"\" on your talk page? ;)   \"", "tokenize_content": ["\"", "whoa", "!", "ha", "##ha", ",", "aren", "'", "t", "you", "glad", "i", "didn", "'", "t", "put", "a", "section", "called", "\"", "\"", "penis", "size", "\"", "\"", "on", "your", "talk", "page", "?", ";", ")", "\""], "span": ["\" whoa", "whoa!", "! ha", "haha", "##ha,", ", aren", "aren '", "' t", "t you", "you glad", "glad i", "i didn", "didn '", "' t", "t put", "put a", "a section", "section called", "called \"", "\" \"", "\" penis", "penis size", "size \"", "\" \"", "\" on", "on your", "your talk", "talk page", "page?", "? ;", "; )", ") \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Man you are one ugly bitch \n\nAnd that's a fact, Bedford", "tokenize_content": ["man", "you", "are", "one", "ugly", "bitch", "and", "that", "'", "s", "a", "fact", ",", "bedford"], "span": ["man you", "you are", "are one", "one ugly", "ugly bitch", "bitch and", "and that", "that '", "' s", "s a", "a fact", "fact,", ", bedford"], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "redneck means racist, idiotic English \nredneck actually means english.  i am not saying all english but brobablt % 99.99 of them.  It means racist, idiot, scumbag etc", "tokenize_content": ["red", "##neck", "means", "racist", ",", "idiot", "##ic", "english", "red", "##neck", "actually", "means", "english", ".", "i", "am", "not", "saying", "all", "english", "but", "bro", "##ba", "##bl", "##t", "%", "99", ".", "99", "of", "them", ".", "it", "means", "racist", ",", "idiot", ",", "sc", "##umb", "##ag", "etc"], "span": ["redneck", "##neck means", "means racist", "racist,", ", idiot", "idiotic", "##ic english", "english red", "redneck", "##neck actually", "actually means", "means english", "english.", ". i", "i am", "am not", "not saying", "saying all", "all english", "english but", "but bro", "broba", "##babl", "##blt", "##t %", "% 99", "99.", ". 99", "99 of", "of them", "them.", ". it", "it means", "means racist", "racist,", ", idiot", "idiot,", ", sc", "scumb", "##umbag", "##ag etc"], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0]}
{"content": "Oi Wankstain ==\n\nFuck off you ignorant cunt, yeah? Revert this you arsewipe, REVERT ME LOLOLOLOL\n\n==", "tokenize_content": ["o", "##i", "wan", "##ks", "##tain", "=", "=", "fuck", "off", "you", "ignorant", "cu", "##nt", ",", "yeah", "?", "rev", "##ert", "this", "you", "ars", "##ew", "##ipe", ",", "rev", "##ert", "me", "lo", "##lo", "##lo", "##lo", "##l", "=", "="], "span": ["oi", "##i wan", "wanks", "##kstain", "##tain =", "= =", "= fuck", "fuck off", "off you", "you ignorant", "ignorant cu", "cunt", "##nt,", ", yeah", "yeah?", "? rev", "revert", "##ert this", "this you", "you ars", "arsew", "##ewipe", "##ipe,", ", rev", "revert", "##ert me", "me lo", "lolo", "##lolo", "##lolo", "##lol", "##l =", "= ="], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I can explain\n\nMfield is a penis", "tokenize_content": ["i", "can", "explain", "m", "##field", "is", "a", "penis"], "span": ["i can", "can explain", "explain m", "mfield", "##field is", "is a", "a penis"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1]}
{"content": "MarkS what the fuck are you going that was comedia gold I had written", "tokenize_content": ["marks", "what", "the", "fuck", "are", "you", "going", "that", "was", "come", "##dia", "gold", "i", "had", "written"], "span": ["marks what", "what the", "the fuck", "fuck are", "are you", "you going", "going that", "that was", "was come", "comedia", "##dia gold", "gold i", "i had", "had written"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "And why did Eric ask you to be his meatpuppet again? Is he paying you to do this?", "tokenize_content": ["and", "why", "did", "eric", "ask", "you", "to", "be", "his", "meat", "##pu", "##ppet", "again", "?", "is", "he", "paying", "you", "to", "do", "this", "?"], "span": ["and why", "why did", "did eric", "eric ask", "ask you", "you to", "to be", "be his", "his meat", "meatpu", "##puppet", "##ppet again", "again?", "? is", "is he", "he paying", "paying you", "you to", "to do", "do this", "this?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Vats because im a child you Gungadin peice of shit, ill be back at u too, as well as User:Bungle. phoooee!", "tokenize_content": ["va", "##ts", "because", "im", "a", "child", "you", "gun", "##ga", "##din", "pei", "##ce", "of", "shit", ",", "ill", "be", "back", "at", "u", "too", ",", "as", "well", "as", "user", ":", "bun", "##gle", ".", "ph", "##oo", "##oe", "##e", "!"], "span": ["vats", "##ts because", "because im", "im a", "a child", "child you", "you gun", "gunga", "##gadin", "##din pei", "peice", "##ce of", "of shit", "shit,", ", ill", "ill be", "be back", "back at", "at u", "u too", "too,", ", as", "as well", "well as", "as user", "user :", ": bun", "bungle", "##gle.", ". ph", "phoo", "##oooe", "##oee", "##e!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "What, you think this block will work better than your last one?  God, but you are stupid!", "tokenize_content": ["what", ",", "you", "think", "this", "block", "will", "work", "better", "than", "your", "last", "one", "?", "god", ",", "but", "you", "are", "stupid", "!"], "span": ["what,", ", you", "you think", "think this", "this block", "block will", "will work", "work better", "better than", "than your", "your last", "last one", "one?", "? god", "god,", ", but", "but you", "you are", "are stupid", "stupid!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "ok \n\noh i seeeeeeeeee, but still you said i should apologise for calling him an idiot then you called me one so basically shut the fuck up...", "tokenize_content": ["ok", "oh", "i", "see", "##ee", "##ee", "##ee", "##ee", ",", "but", "still", "you", "said", "i", "should", "ap", "##olo", "##gis", "##e", "for", "calling", "him", "an", "idiot", "then", "you", "called", "me", "one", "so", "basically", "shut", "the", "fuck", "up", ".", ".", "."], "span": ["ok oh", "oh i", "i see", "seeee", "##eeee", "##eeee", "##eeee", "##ee,", ", but", "but still", "still you", "you said", "said i", "i should", "should ap", "apolo", "##ologis", "##gise", "##e for", "for calling", "calling him", "him an", "an idiot", "idiot then", "then you", "you called", "called me", "me one", "one so", "so basically", "basically shut", "shut the", "the fuck", "fuck up", "up.", "..", ".."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]}
{"content": "Good riddance you fucking asshole!! Bog off forever.", "tokenize_content": ["good", "rid", "##dance", "you", "fucking", "asshole", "!", "!", "bog", "off", "forever", "."], "span": ["good rid", "riddance", "##dance you", "you fucking", "fucking asshole", "asshole!", "!!", "! bog", "bog off", "off forever", "forever."], "toxic": 1, "score": [0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0]}
{"content": "Douche?\nDear S3000,\nBe you a douchecock?  I believe it doubly so.", "tokenize_content": ["do", "##uche", "?", "dear", "s", "##30", "##00", ",", "be", "you", "a", "do", "##uche", "##cock", "?", "i", "believe", "it", "do", "##ub", "##ly", "so", "."], "span": ["douche", "##uche?", "? dear", "dear s", "s30", "##3000", "##00,", ", be", "be you", "you a", "a do", "douche", "##uchecock", "##cock?", "? i", "i believe", "believe it", "it do", "doub", "##ubly", "##ly so", "so."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I have not been or ever will be a sockpuppet. Take your rudeness elsewhere.", "tokenize_content": ["i", "have", "not", "been", "or", "ever", "will", "be", "a", "sock", "##pu", "##ppet", ".", "take", "your", "rude", "##ness", "elsewhere", "."], "span": ["i have", "have not", "not been", "been or", "or ever", "ever will", "will be", "be a", "a sock", "sockpu", "##puppet", "##ppet.", ". take", "take your", "your rude", "rudeness", "##ness elsewhere", "elsewhere."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "am a mother-fucking dweeb==", "tokenize_content": ["am", "a", "mother", "-", "fucking", "d", "##wee", "##b", "=", "="], "span": ["am a", "a mother", "mother -", "- fucking", "fucking d", "dwee", "##weeb", "##b =", "= ="], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "i know who you are \ni know your name is thomas harrison, and that you have a personal vendetta to vandalise my pages. KEEP OUT!", "tokenize_content": ["i", "know", "who", "you", "are", "i", "know", "your", "name", "is", "thomas", "harrison", ",", "and", "that", "you", "have", "a", "personal", "ve", "##nde", "##tta", "to", "van", "##dal", "##ise", "my", "pages", ".", "keep", "out", "!"], "span": ["i know", "know who", "who you", "you are", "are i", "i know", "know your", "your name", "name is", "is thomas", "thomas harrison", "harrison,", ", and", "and that", "that you", "you have", "have a", "a personal", "personal ve", "vende", "##ndetta", "##tta to", "to van", "vandal", "##dalise", "##ise my", "my pages", "pages.", ". keep", "keep out", "out!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Sup teagger \n\nStop being such a teabagger\n\n160.94.140.100  \nNot a teabagging douche", "tokenize_content": ["su", "##p", "tea", "##gger", "stop", "being", "such", "a", "tea", "##bag", "##ger", "160", ".", "94", ".", "140", ".", "100", "not", "a", "tea", "##bag", "##ging", "do", "##uche"], "span": ["sup", "##p tea", "teagger", "##gger stop", "stop being", "being such", "such a", "a tea", "teabag", "##bagger", "##ger 160", "160.", ". 94", "94.", ". 140", "140.", ". 100", "100 not", "not a", "a tea", "teabag", "##bagging", "##ging do", "douche"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "ROB you're a fat dork.", "tokenize_content": ["rob", "you", "'", "re", "a", "fat", "do", "##rk", "."], "span": ["rob you", "you '", "' re", "re a", "a fat", "fat do", "dork", "##rk."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Bananas\nWill you PLEASE leave my entries alone.  Dumbass.", "tokenize_content": ["bananas", "will", "you", "please", "leave", "my", "entries", "alone", ".", "dumb", "##ass", "."], "span": ["bananas will", "will you", "you please", "please leave", "leave my", "my entries", "entries alone", "alone.", ". dumb", "dumbass", "##ass."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]}
{"content": "Full Bullshit. I HAVE provide over a dozen references NONE OF WHICH are acceptable to paid whore.", "tokenize_content": ["full", "bullshit", ".", "i", "have", "provide", "over", "a", "dozen", "references", "none", "of", "which", "are", "acceptable", "to", "paid", "whore", "."], "span": ["full bullshit", "bullshit.", ". i", "i have", "have provide", "provide over", "over a", "a dozen", "dozen references", "references none", "none of", "of which", "which are", "are acceptable", "acceptable to", "to paid", "paid whore", "whore."], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "What complete garbage, I never had anything to do with that Verdict nonsense, which is made clear . And I trust 100% that you will be back, either as this or some other user name.", "tokenize_content": ["what", "complete", "garbage", ",", "i", "never", "had", "anything", "to", "do", "with", "that", "verdict", "nonsense", ",", "which", "is", "made", "clear", ".", "and", "i", "trust", "100", "%", "that", "you", "will", "be", "back", ",", "either", "as", "this", "or", "some", "other", "user", "name", "."], "span": ["what complete", "complete garbage", "garbage,", ", i", "i never", "never had", "had anything", "anything to", "to do", "do with", "with that", "that verdict", "verdict nonsense", "nonsense,", ", which", "which is", "is made", "made clear", "clear.", ". and", "and i", "i trust", "trust 100", "100 %", "% that", "that you", "you will", "will be", "be back", "back,", ", either", "either as", "as this", "this or", "or some", "some other", "other user", "user name", "name."], "toxic": 1, "score": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "CANT BLOCK ME NIGGA", "tokenize_content": ["can", "##t", "block", "me", "ni", "##gga"], "span": ["cant", "##t block", "block me", "me ni", "nigga"], "toxic": 1, "score": [0, 0, 0, 0, 1]}
{"content": "Mangojuice is a piece of shit that should fucking die!!!!!!!!!!!!!", "tokenize_content": ["mango", "##ju", "##ice", "is", "a", "piece", "of", "shit", "that", "should", "fucking", "die", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!"], "span": ["mangoju", "##juice", "##ice is", "is a", "a piece", "piece of", "of shit", "shit that", "that should", "should fucking", "fucking die", "die!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "CALM DOWN, CALM DOWN, DON'T GET A BIG DICK", "tokenize_content": ["calm", "down", ",", "calm", "down", ",", "don", "'", "t", "get", "a", "big", "dick"], "span": ["calm down", "down,", ", calm", "calm down", "down,", ", don", "don '", "' t", "t get", "get a", "a big", "big dick"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "Uh oh, Mr. Big shot registered User is crying like a little girl because I called him out on his BS.", "tokenize_content": ["uh", "oh", ",", "mr", ".", "big", "shot", "registered", "user", "is", "crying", "like", "a", "little", "girl", "because", "i", "called", "him", "out", "on", "his", "bs", "."], "span": ["uh oh", "oh,", ", mr", "mr.", ". big", "big shot", "shot registered", "registered user", "user is", "is crying", "crying like", "like a", "a little", "little girl", "girl because", "because i", "i called", "called him", "him out", "out on", "on his", "his bs", "bs."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "ITS STILL FUNNY \nSon of a bitch! _|_", "tokenize_content": ["its", "still", "funny", "son", "of", "a", "bitch", "!", "_", "|", "_"], "span": ["its still", "still funny", "funny son", "son of", "of a", "a bitch", "bitch!", "! _", "_ |", "| _"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0]}
{"content": "stop fuicky reverting my fucking edits it", "tokenize_content": ["stop", "fu", "##ick", "##y", "rev", "##ert", "##ing", "my", "fucking", "edit", "##s", "it"], "span": ["stop fu", "fuick", "##icky", "##y rev", "revert", "##erting", "##ing my", "my fucking", "fucking edit", "edits", "##s it"], "toxic": 1, "score": [0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "Take the latter part of your advice, then shove the rest of the message right up your ass.", "tokenize_content": ["take", "the", "latter", "part", "of", "your", "advice", ",", "then", "shove", "the", "rest", "of", "the", "message", "right", "up", "your", "ass", "."], "span": ["take the", "the latter", "latter part", "part of", "of your", "your advice", "advice,", ", then", "then shove", "shove the", "the rest", "rest of", "of the", "the message", "message right", "right up", "up your", "your ass", "ass."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "I'm a fat pig.  Does that belong on Wikipedia?", "tokenize_content": ["i", "'", "m", "a", "fat", "pig", ".", "does", "that", "belong", "on", "wikipedia", "?"], "span": ["i '", "' m", "m a", "a fat", "fat pig", "pig.", ". does", "does that", "that belong", "belong on", "on wikipedia", "wikipedia?"], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "Meters is a piece of shit as well as User:Ponyo.", "tokenize_content": ["meters", "is", "a", "piece", "of", "shit", "as", "well", "as", "user", ":", "pony", "##o", "."], "span": ["meters is", "is a", "a piece", "piece of", "of shit", "shit as", "as well", "well as", "as user", "user :", ": pony", "ponyo", "##o."], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I was wondering the same thing for my User page. Either way, I don't even understand why I was blocked in the first place. Other than that some idiot named Rhobite seems to have a hard time dealing with defeat and reality.", "tokenize_content": ["i", "was", "wondering", "the", "same", "thing", "for", "my", "user", "page", ".", "either", "way", ",", "i", "don", "'", "t", "even", "understand", "why", "i", "was", "blocked", "in", "the", "first", "place", ".", "other", "than", "that", "some", "idiot", "named", "r", "##ho", "##bit", "##e", "seems", "to", "have", "a", "hard", "time", "dealing", "with", "defeat", "and", "reality", "."], "span": ["i was", "was wondering", "wondering the", "the same", "same thing", "thing for", "for my", "my user", "user page", "page.", ". either", "either way", "way,", ", i", "i don", "don '", "' t", "t even", "even understand", "understand why", "why i", "i was", "was blocked", "blocked in", "in the", "the first", "first place", "place.", ". other", "other than", "than that", "that some", "some idiot", "idiot named", "named r", "rho", "##hobit", "##bite", "##e seems", "seems to", "to have", "have a", "a hard", "hard time", "time dealing", "dealing with", "with defeat", "defeat and", "and reality", "reality."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "If I wanted a kiss I'd call your mother", "tokenize_content": ["if", "i", "wanted", "a", "kiss", "i", "'", "d", "call", "your", "mother"], "span": ["if i", "i wanted", "wanted a", "a kiss", "kiss i", "i '", "' d", "d call", "call your", "your mother"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Charles Knight is an anal king \n\nI have proof.", "tokenize_content": ["charles", "knight", "is", "an", "anal", "king", "i", "have", "proof", "."], "span": ["charles knight", "knight is", "is an", "an anal", "anal king", "king i", "i have", "have proof", "proof."], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "\"\n\n A kitten for you! \n\nyou are a cunt\n\n  \n\"", "tokenize_content": ["\"", "a", "kitten", "for", "you", "!", "you", "are", "a", "cu", "##nt", "\""], "span": ["\" a", "a kitten", "kitten for", "for you", "you!", "! you", "you are", "are a", "a cu", "cunt", "##nt \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}
{"content": "Your wife isn't half bad \nCan I fuck her?", "tokenize_content": ["your", "wife", "isn", "'", "t", "half", "bad", "can", "i", "fuck", "her", "?"], "span": ["your wife", "wife isn", "isn '", "' t", "t half", "half bad", "bad can", "can i", "i fuck", "fuck her", "her?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "Mrschimpf is an wikipedia troll.", "tokenize_content": ["mrs", "##chi", "##mp", "##f", "is", "an", "wikipedia", "troll", "."], "span": ["mrschi", "##chimp", "##mpf", "##f is", "is an", "an wikipedia", "wikipedia troll", "troll."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "u guys are all a bunch of jerks fuck u i hate you", "tokenize_content": ["u", "guys", "are", "all", "a", "bunch", "of", "jerk", "##s", "fuck", "u", "i", "hate", "you"], "span": ["u guys", "guys are", "are all", "all a", "a bunch", "bunch of", "of jerk", "jerks", "##s fuck", "fuck u", "u i", "i hate", "hate you"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1]}
{"content": "THE MOST ANNOYING FUCKING IDIOT EVER.", "tokenize_content": ["the", "most", "annoying", "fucking", "idiot", "ever", "."], "span": ["the most", "most annoying", "annoying fucking", "fucking idiot", "idiot ever", "ever."], "toxic": 1, "score": [0, 0, 1, 1, 1, 0]}
{"content": "and in the program on last night Crime Museum: The Blackout Ripper he is called a serial killer not only by experts but by the police who catched him !!!! so get your facts right you retards", "tokenize_content": ["and", "in", "the", "program", "on", "last", "night", "crime", "museum", ":", "the", "blackout", "rip", "##per", "he", "is", "called", "a", "serial", "killer", "not", "only", "by", "experts", "but", "by", "the", "police", "who", "catch", "##ed", "him", "!", "!", "!", "!", "so", "get", "your", "facts", "right", "you", "re", "##tar", "##ds"], "span": ["and in", "in the", "the program", "program on", "on last", "last night", "night crime", "crime museum", "museum :", ": the", "the blackout", "blackout rip", "ripper", "##per he", "he is", "is called", "called a", "a serial", "serial killer", "killer not", "not only", "only by", "by experts", "experts but", "but by", "by the", "the police", "police who", "who catch", "catched", "##ed him", "him!", "!!", "!!", "!!", "! so", "so get", "get your", "your facts", "facts right", "right you", "you re", "retar", "##tards"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "okay \n\nWHAT A BUM BANDIT", "tokenize_content": ["okay", "what", "a", "bum", "bandit"], "span": ["okay what", "what a", "a bum", "bum bandit"], "toxic": 1, "score": [0, 0, 0, 0]}
{"content": "Suck my horny dutch balls", "tokenize_content": ["suck", "my", "horn", "##y", "dutch", "balls"], "span": ["suck my", "my horn", "horny", "##y dutch", "dutch balls"], "toxic": 1, "score": [1, 0, 0, 0, 0]}
{"content": "Are you a deaf idiot? He BROKE the bird's neck. The sound clearly shows the neck snap and the bird cry out in pain", "tokenize_content": ["are", "you", "a", "deaf", "idiot", "?", "he", "broke", "the", "bird", "'", "s", "neck", ".", "the", "sound", "clearly", "shows", "the", "neck", "snap", "and", "the", "bird", "cry", "out", "in", "pain"], "span": ["are you", "you a", "a deaf", "deaf idiot", "idiot?", "? he", "he broke", "broke the", "the bird", "bird '", "' s", "s neck", "neck.", ". the", "the sound", "sound clearly", "clearly shows", "shows the", "the neck", "neck snap", "snap and", "and the", "the bird", "bird cry", "cry out", "out in", "in pain"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I hope to God your kids are trapped inside burning cars.", "tokenize_content": ["i", "hope", "to", "god", "your", "kids", "are", "trapped", "inside", "burning", "cars", "."], "span": ["i hope", "hope to", "to god", "god your", "your kids", "kids are", "are trapped", "trapped inside", "inside burning", "burning cars", "cars."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Oh God. Not you again. \n\nGo away and stop bothering me, non-administrator. 98.221.192.218", "tokenize_content": ["oh", "god", ".", "not", "you", "again", ".", "go", "away", "and", "stop", "bothering", "me", ",", "non", "-", "administrator", ".", "98", ".", "221", ".", "192", ".", "218"], "span": ["oh god", "god.", ". not", "not you", "you again", "again.", ". go", "go away", "away and", "and stop", "stop bothering", "bothering me", "me,", ", non", "non -", "- administrator", "administrator.", ". 98", "98.", ". 221", "221.", ". 192", "192.", ". 218"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Yeah fuck you \n\nseriously fuck you. All you do is protect racists and homophobes. You're as bad as they are.", "tokenize_content": ["yeah", "fuck", "you", "seriously", "fuck", "you", ".", "all", "you", "do", "is", "protect", "racist", "##s", "and", "homo", "##ph", "##obe", "##s", ".", "you", "'", "re", "as", "bad", "as", "they", "are", "."], "span": ["yeah fuck", "fuck you", "you seriously", "seriously fuck", "fuck you", "you.", ". all", "all you", "you do", "do is", "is protect", "protect racist", "racists", "##s and", "and homo", "homoph", "##phobe", "##obes", "##s.", ". you", "you '", "' re", "re as", "as bad", "bad as", "as they", "they are", "are."], "toxic": 1, "score": [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Yo\n\nWhy you being such as hater all of the time man? Get off my dick. - A Different World - 4:59 PM - Friday, August 25, 2006.", "tokenize_content": ["yo", "why", "you", "being", "such", "as", "hate", "##r", "all", "of", "the", "time", "man", "?", "get", "off", "my", "dick", ".", "-", "a", "different", "world", "-", "4", ":", "59", "pm", "-", "friday", ",", "august", "25", ",", "2006", "."], "span": ["yo why", "why you", "you being", "being such", "such as", "as hate", "hater", "##r all", "all of", "of the", "the time", "time man", "man?", "? get", "get off", "off my", "my dick", "dick.", ". -", "- a", "a different", "different world", "world -", "- 4", "4 :", ": 59", "59 pm", "pm -", "- friday", "friday,", ", august", "august 25", "25,", ", 2006", "2006."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "i hate lewis and clark", "tokenize_content": ["i", "hate", "lewis", "and", "clark"], "span": ["i hate", "hate lewis", "lewis and", "and clark"], "toxic": 1, "score": [0, 0, 0, 0]}
{"content": "You're a little queer Jew bag.", "tokenize_content": ["you", "'", "re", "a", "little", "queer", "jew", "bag", "."], "span": ["you '", "' re", "re a", "a little", "little queer", "queer jew", "jew bag", "bag."], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 0, 0]}
{"content": "IDIOT BYTCH \n\nOnce again, I only have 1 computer and PS3 with internet. My IP address change after an admistor banned my original IP. Now It happen again you d!ck.", "tokenize_content": ["idiot", "by", "##tch", "once", "again", ",", "i", "only", "have", "1", "computer", "and", "ps", "##3", "with", "internet", ".", "my", "ip", "address", "change", "after", "an", "ad", "##mist", "##or", "banned", "my", "original", "ip", ".", "now", "it", "happen", "again", "you", "d", "!", "ck", "."], "span": ["idiot by", "bytch", "##tch once", "once again", "again,", ", i", "i only", "only have", "have 1", "1 computer", "computer and", "and ps", "ps3", "##3 with", "with internet", "internet.", ". my", "my ip", "ip address", "address change", "change after", "after an", "an ad", "admist", "##mistor", "##or banned", "banned my", "my original", "original ip", "ip.", ". now", "now it", "it happen", "happen again", "again you", "you d", "d!", "! ck", "ck."], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Albanian Optimiology \n\nWhat is Albanian for masturbation?69.243.42.251", "tokenize_content": ["albanian", "opt", "##imi", "##ology", "what", "is", "albanian", "for", "mast", "##ur", "##bation", "?", "69", ".", "243", ".", "42", ".", "251"], "span": ["albanian opt", "optimi", "##imiology", "##ology what", "what is", "is albanian", "albanian for", "for mast", "mastur", "##urbation", "##bation?", "? 69", "69.", ". 243", "243.", ". 42", "42.", ". 251"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"Reply ==\nHello \n\"\"ThePeg\"\", you do yourself a grave injustice. There are no \"\"Stupid questions\"\", only \"\"Stupid answers\"\". Cheers   \n\n== \"", "tokenize_content": ["\"", "reply", "=", "=", "hello", "\"", "\"", "the", "##pe", "##g", "\"", "\"", ",", "you", "do", "yourself", "a", "grave", "injustice", ".", "there", "are", "no", "\"", "\"", "stupid", "questions", "\"", "\"", ",", "only", "\"", "\"", "stupid", "answers", "\"", "\"", ".", "cheers", "=", "=", "\""], "span": ["\" reply", "reply =", "= =", "= hello", "hello \"", "\" \"", "\" the", "thepe", "##peg", "##g \"", "\" \"", "\",", ", you", "you do", "do yourself", "yourself a", "a grave", "grave injustice", "injustice.", ". there", "there are", "are no", "no \"", "\" \"", "\" stupid", "stupid questions", "questions \"", "\" \"", "\",", ", only", "only \"", "\" \"", "\" stupid", "stupid answers", "answers \"", "\" \"", "\".", ". cheers", "cheers =", "= =", "= \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Removed the statement.  It would be obvious from the specifics I mentioned that I have read the article.  So in response to your blatant insult, fuck you too.", "tokenize_content": ["removed", "the", "statement", ".", "it", "would", "be", "obvious", "from", "the", "specific", "##s", "i", "mentioned", "that", "i", "have", "read", "the", "article", ".", "so", "in", "response", "to", "your", "b", "##lat", "##ant", "insult", ",", "fuck", "you", "too", "."], "span": ["removed the", "the statement", "statement.", ". it", "it would", "would be", "be obvious", "obvious from", "from the", "the specific", "specifics", "##s i", "i mentioned", "mentioned that", "that i", "i have", "have read", "read the", "the article", "article.", ". so", "so in", "in response", "response to", "to your", "your b", "blat", "##latant", "##ant insult", "insult,", ", fuck", "fuck you", "you too", "too."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "George Washington had 2 on the vine. Two sets of testicles, so divine.", "tokenize_content": ["george", "washington", "had", "2", "on", "the", "vine", ".", "two", "sets", "of", "test", "##icles", ",", "so", "divine", "."], "span": ["george washington", "washington had", "had 2", "2 on", "on the", "the vine", "vine.", ". two", "two sets", "sets of", "of test", "testicles", "##icles,", ", so", "so divine", "divine."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Nonsense?  kiss off, geek. what I said is true.  I'll have your account terminated.", "tokenize_content": ["nonsense", "?", "kiss", "off", ",", "geek", ".", "what", "i", "said", "is", "true", ".", "i", "'", "ll", "have", "your", "account", "terminated", "."], "span": ["nonsense?", "? kiss", "kiss off", "off,", ", geek", "geek.", ". what", "what i", "i said", "said is", "is true", "true.", ". i", "i '", "' ll", "ll have", "have your", "your account", "account terminated", "terminated."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Japanese Bastard \n\nFuck off you evil race.", "tokenize_content": ["japanese", "bastard", "fuck", "off", "you", "evil", "race", "."], "span": ["japanese bastard", "bastard fuck", "fuck off", "off you", "you evil", "evil race", "race."], "toxic": 1, "score": [1, 1, 1, 0, 0, 0, 0]}
{"content": "You're nothing dude, end yourself now \n\nYou have absolutely nothing going for you - just end it, bro.", "tokenize_content": ["you", "'", "re", "nothing", "dude", ",", "end", "yourself", "now", "you", "have", "absolutely", "nothing", "going", "for", "you", "-", "just", "end", "it", ",", "bro", "."], "span": ["you '", "' re", "re nothing", "nothing dude", "dude,", ", end", "end yourself", "yourself now", "now you", "you have", "have absolutely", "absolutely nothing", "nothing going", "going for", "for you", "you -", "- just", "just end", "end it", "it,", ", bro", "bro."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I DETEST you \n\nI absolutely hate you. You are scum. Nothing more than scum. I can tell by your wikipedia editing.", "tokenize_content": ["i", "det", "##est", "you", "i", "absolutely", "hate", "you", ".", "you", "are", "sc", "##um", ".", "nothing", "more", "than", "sc", "##um", ".", "i", "can", "tell", "by", "your", "wikipedia", "editing", "."], "span": ["i det", "detest", "##est you", "you i", "i absolutely", "absolutely hate", "hate you", "you.", ". you", "you are", "are sc", "scum", "##um.", ". nothing", "nothing more", "more than", "than sc", "scum", "##um.", ". i", "i can", "can tell", "tell by", "by your", "your wikipedia", "wikipedia editing", "editing."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "This is pure tripe stolen from their bio on their official website, which is outdated by the way. That's bad wiki practice.", "tokenize_content": ["this", "is", "pure", "trip", "##e", "stolen", "from", "their", "bio", "on", "their", "official", "website", ",", "which", "is", "outdated", "by", "the", "way", ".", "that", "'", "s", "bad", "wi", "##ki", "practice", "."], "span": ["this is", "is pure", "pure trip", "tripe", "##e stolen", "stolen from", "from their", "their bio", "bio on", "on their", "their official", "official website", "website,", ", which", "which is", "is outdated", "outdated by", "by the", "the way", "way.", ". that", "that '", "' s", "s bad", "bad wi", "wiki", "##ki practice", "practice."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I will \u20b5ut off your dick and balls and make you my bitch. \n\nI shall name you Reek.", "tokenize_content": ["i", "will", "[UNK]", "off", "your", "dick", "and", "balls", "and", "make", "you", "my", "bitch", ".", "i", "shall", "name", "you", "re", "##ek", "."], "span": ["i will", "will", "off", "off your", "your dick", "dick and", "and balls", "balls and", "and make", "make you", "you my", "my bitch", "bitch.", ". i", "i shall", "shall name", "name you", "you re", "reek", "##ek."], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": ". Concerning your comment about Pro Evolution Soccer, it nullifies your whole argument, due to the fact that it's shit", "tokenize_content": [".", "concerning", "your", "comment", "about", "pro", "evolution", "soccer", ",", "it", "null", "##ifies", "your", "whole", "argument", ",", "due", "to", "the", "fact", "that", "it", "'", "s", "shit"], "span": [". concerning", "concerning your", "your comment", "comment about", "about pro", "pro evolution", "evolution soccer", "soccer,", ", it", "it null", "nullifies", "##ifies your", "your whole", "whole argument", "argument,", ", due", "due to", "to the", "the fact", "fact that", "that it", "it '", "' s", "s shit"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "Who the hell are you \n\nWho are you trying to tell me I will be blocked If I dont stop   Ilovedirtbikes", "tokenize_content": ["who", "the", "hell", "are", "you", "who", "are", "you", "trying", "to", "tell", "me", "i", "will", "be", "blocked", "if", "i", "don", "##t", "stop", "il", "##ove", "##di", "##rt", "##bi", "##kes"], "span": ["who the", "the hell", "hell are", "are you", "you who", "who are", "are you", "you trying", "trying to", "to tell", "tell me", "me i", "i will", "will be", "be blocked", "blocked if", "if i", "i don", "dont", "##t stop", "stop il", "ilove", "##ovedi", "##dirt", "##rtbi", "##bikes"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Can you read? \n\nOr are you one of those morons who just blindly reverts?  Don't answer that, I already know.  Idiot.  174.91.2.68", "tokenize_content": ["can", "you", "read", "?", "or", "are", "you", "one", "of", "those", "mor", "##ons", "who", "just", "blindly", "rev", "##ert", "##s", "?", "don", "'", "t", "answer", "that", ",", "i", "already", "know", ".", "idiot", ".", "174", ".", "91", ".", "2", ".", "68"], "span": ["can you", "you read", "read?", "? or", "or are", "are you", "you one", "one of", "of those", "those mor", "morons", "##ons who", "who just", "just blindly", "blindly rev", "revert", "##erts", "##s?", "? don", "don '", "' t", "t answer", "answer that", "that,", ", i", "i already", "already know", "know.", ". idiot", "idiot.", ". 174", "174.", ". 91", "91.", ". 2", "2.", ". 68"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Criss Angel is a cocksucker", "tokenize_content": ["cr", "##iss", "angel", "is", "a", "cock", "##su", "##cker"], "span": ["criss", "##iss angel", "angel is", "is a", "a cock", "cocksu", "##sucker"], "toxic": 1, "score": [0, 0, 0, 0, 1, 0, 1]}
{"content": "I didn't ask how often you jerk off.  A Simpsons episode is where the mass of twitchy muscle is from.  69.158.165.129", "tokenize_content": ["i", "didn", "'", "t", "ask", "how", "often", "you", "jerk", "off", ".", "a", "simpsons", "episode", "is", "where", "the", "mass", "of", "twitch", "##y", "muscle", "is", "from", ".", "69", ".", "158", ".", "165", ".", "129"], "span": ["i didn", "didn '", "' t", "t ask", "ask how", "how often", "often you", "you jerk", "jerk off", "off.", ". a", "a simpsons", "simpsons episode", "episode is", "is where", "where the", "the mass", "mass of", "of twitch", "twitchy", "##y muscle", "muscle is", "is from", "from.", ". 69", "69.", ". 158", "158.", ". 165", "165.", ". 129"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "On another note,  FUCK U DR NICK YOU POOFY FUCK.", "tokenize_content": ["on", "another", "note", ",", "fuck", "u", "dr", "nick", "you", "po", "##of", "##y", "fuck", "."], "span": ["on another", "another note", "note,", ", fuck", "fuck u", "u dr", "dr nick", "nick you", "you po", "poof", "##ofy", "##y fuck", "fuck."], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "_   ANYWAY, GOTTA MAKE OUT ANOTHER ACCOUNT IF I FEEL THE NEED TO CHEW YOU OUT AGAIN", "tokenize_content": ["_", "anyway", ",", "gotta", "make", "out", "another", "account", "if", "i", "feel", "the", "need", "to", "chew", "you", "out", "again"], "span": ["_ anyway", "anyway,", ", gotta", "gotta make", "make out", "out another", "another account", "account if", "if i", "i feel", "feel the", "the need", "need to", "to chew", "chew you", "you out", "out again"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "you are a f@g kill yourself cus nobody likes you", "tokenize_content": ["you", "are", "a", "f", "@", "g", "kill", "yourself", "cu", "##s", "nobody", "likes", "you"], "span": ["you are", "are a", "a f", "f @", "@ g", "g kill", "kill yourself", "yourself cu", "cus", "##s nobody", "nobody likes", "likes you"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]}
{"content": "I bet this asshole is far from playing by her own rulesI have arrived just in time", "tokenize_content": ["i", "bet", "this", "asshole", "is", "far", "from", "playing", "by", "her", "own", "rules", "##i", "have", "arrived", "just", "in", "time"], "span": ["i bet", "bet this", "this asshole", "asshole is", "is far", "far from", "from playing", "playing by", "by her", "her own", "own rules", "rulesi", "##i have", "have arrived", "arrived just", "just in", "in time"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I HATE THIS GUY HE IS SOME INTERNET THUG THAT THINKS HE KNOWS WHAT REAL HIP HIP IS ABOUT HE LIVES IN DAYTON FROM THE MEAN STREETS OF DAYTON YOU LITTLE INTERNET POPO.", "tokenize_content": ["i", "hate", "this", "guy", "he", "is", "some", "internet", "thug", "that", "thinks", "he", "knows", "what", "real", "hip", "hip", "is", "about", "he", "lives", "in", "dayton", "from", "the", "mean", "streets", "of", "dayton", "you", "little", "internet", "pop", "##o", "."], "span": ["i hate", "hate this", "this guy", "guy he", "he is", "is some", "some internet", "internet thug", "thug that", "that thinks", "thinks he", "he knows", "knows what", "what real", "real hip", "hip hip", "hip is", "is about", "about he", "he lives", "lives in", "in dayton", "dayton from", "from the", "the mean", "mean streets", "streets of", "of dayton", "dayton you", "you little", "little internet", "internet pop", "popo", "##o."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "You are such a cracker.", "tokenize_content": ["you", "are", "such", "a", "crack", "##er", "."], "span": ["you are", "are such", "such a", "a crack", "cracker", "##er."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0]}
{"content": "\" (UTC)\nThat is very rich coming from you. Don't fucking call me \"\"pathetic\"\".  17:00, 14 July 2005\"", "tokenize_content": ["\"", "(", "utc", ")", "that", "is", "very", "rich", "coming", "from", "you", ".", "don", "'", "t", "fucking", "call", "me", "\"", "\"", "pathetic", "\"", "\"", ".", "17", ":", "00", ",", "14", "july", "2005", "\""], "span": ["\" (", "( utc", "utc )", ") that", "that is", "is very", "very rich", "rich coming", "coming from", "from you", "you.", ". don", "don '", "' t", "t fucking", "fucking call", "call me", "me \"", "\" \"", "\" pathetic", "pathetic \"", "\" \"", "\".", ". 17", "17 :", ": 00", "00,", ", 14", "14 july", "july 2005", "2005 \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "i lost my civility when you started being outrageous fucking liars, fuck you liar, burn in hell for your fucking blasphemy!\n\ni will leave when you stop fucking lying!", "tokenize_content": ["i", "lost", "my", "civil", "##ity", "when", "you", "started", "being", "outrageous", "fucking", "liar", "##s", ",", "fuck", "you", "liar", ",", "burn", "in", "hell", "for", "your", "fucking", "b", "##las", "##ph", "##emy", "!", "i", "will", "leave", "when", "you", "stop", "fucking", "lying", "!"], "span": ["i lost", "lost my", "my civil", "civility", "##ity when", "when you", "you started", "started being", "being outrageous", "outrageous fucking", "fucking liar", "liars", "##s,", ", fuck", "fuck you", "you liar", "liar,", ", burn", "burn in", "in hell", "hell for", "for your", "your fucking", "fucking b", "blas", "##lasph", "##phemy", "##emy!", "! i", "i will", "will leave", "leave when", "when you", "you stop", "stop fucking", "fucking lying", "lying!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "CODY IS FUCKING AWESOME", "tokenize_content": ["cody", "is", "fucking", "awesome"], "span": ["cody is", "is fucking", "fucking awesome"], "toxic": 1, "score": [0, 1, 1]}
{"content": "The bastard always does it to me. An eye for an eye. \n\nSean.hoyland is a fucking cunt.", "tokenize_content": ["the", "bastard", "always", "does", "it", "to", "me", ".", "an", "eye", "for", "an", "eye", ".", "sean", ".", "ho", "##yla", "##nd", "is", "a", "fucking", "cu", "##nt", "."], "span": ["the bastard", "bastard always", "always does", "does it", "it to", "to me", "me.", ". an", "an eye", "eye for", "for an", "an eye", "eye.", ". sean", "sean.", ". ho", "hoyla", "##yland", "##nd is", "is a", "a fucking", "fucking cu", "cunt", "##nt."], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]}
{"content": "Molesterfield \n\nMe trying to be a hero for making the Westerfield article?!!!???  That's ridiculous!  Pass me some of that joint you're smoking!  )", "tokenize_content": ["mole", "##ster", "##field", "me", "trying", "to", "be", "a", "hero", "for", "making", "the", "west", "##er", "##field", "article", "?", "!", "!", "!", "?", "?", "?", "that", "'", "s", "ridiculous", "!", "pass", "me", "some", "of", "that", "joint", "you", "'", "re", "smoking", "!", ")"], "span": ["molester", "##sterfield", "##field me", "me trying", "trying to", "to be", "be a", "a hero", "hero for", "for making", "making the", "the west", "wester", "##erfield", "##field article", "article?", "?!", "!!", "!!", "!?", "??", "??", "? that", "that '", "' s", "s ridiculous", "ridiculous!", "! pass", "pass me", "me some", "some of", "of that", "that joint", "joint you", "you '", "' re", "re smoking", "smoking!", "! )"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "- IM BLOCKED BITCH!!!!!!!!!!!!!!!", "tokenize_content": ["-", "im", "blocked", "bitch", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!"], "span": ["- im", "im blocked", "blocked bitch", "bitch!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Saxifrage has too many cocks in his mouth and they are obstructing his vision, I think he may have banned me on accident when one of them fell out his mouth onto this keyboard.", "tokenize_content": ["sax", "##if", "##rage", "has", "too", "many", "cock", "##s", "in", "his", "mouth", "and", "they", "are", "ob", "##st", "##ru", "##cting", "his", "vision", ",", "i", "think", "he", "may", "have", "banned", "me", "on", "accident", "when", "one", "of", "them", "fell", "out", "his", "mouth", "onto", "this", "keyboard", "."], "span": ["saxif", "##ifrage", "##rage has", "has too", "too many", "many cock", "cocks", "##s in", "in his", "his mouth", "mouth and", "and they", "they are", "are ob", "obst", "##stru", "##ructing", "##cting his", "his vision", "vision,", ", i", "i think", "think he", "he may", "may have", "have banned", "banned me", "me on", "on accident", "accident when", "when one", "one of", "of them", "them fell", "fell out", "out his", "his mouth", "mouth onto", "onto this", "this keyboard", "keyboard."], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "you are sick bastard, and hope get your lesson soon", "tokenize_content": ["you", "are", "sick", "bastard", ",", "and", "hope", "get", "your", "lesson", "soon"], "span": ["you are", "are sick", "sick bastard", "bastard,", ", and", "and hope", "hope get", "get your", "your lesson", "lesson soon"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "yes, yes, thank you. good to know, but who decides what vandalism is?  Does some stupid commie fag named redvers/", "tokenize_content": ["yes", ",", "yes", ",", "thank", "you", ".", "good", "to", "know", ",", "but", "who", "decides", "what", "van", "##dal", "##ism", "is", "?", "does", "some", "stupid", "com", "##mie", "fa", "##g", "named", "red", "##vers", "/"], "span": ["yes,", ", yes", "yes,", ", thank", "thank you", "you.", ". good", "good to", "to know", "know,", ", but", "but who", "who decides", "decides what", "what van", "vandal", "##dalism", "##ism is", "is?", "? does", "does some", "some stupid", "stupid com", "commie", "##mie fa", "fag", "##g named", "named red", "redvers", "##vers /"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0]}
{"content": "This page is fucked up can someone please fix it ?", "tokenize_content": ["this", "page", "is", "fucked", "up", "can", "someone", "please", "fix", "it", "?"], "span": ["this page", "page is", "is fucked", "fucked up", "up can", "can someone", "someone please", "please fix", "fix it", "it?"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n I AM NOT THE \"\"SAN DIEGO IP\"\"!!  Go ahead and block me -  I have ZERO interest in participating in Wiki for this very reason.  You all are armchair deputies with no proof to back your accusations.  \"", "tokenize_content": ["\"", "i", "am", "not", "the", "\"", "\"", "san", "diego", "ip", "\"", "\"", "!", "!", "go", "ahead", "and", "block", "me", "-", "i", "have", "zero", "interest", "in", "participating", "in", "wi", "##ki", "for", "this", "very", "reason", ".", "you", "all", "are", "armchair", "deputies", "with", "no", "proof", "to", "back", "your", "accusations", ".", "\""], "span": ["\" i", "i am", "am not", "not the", "the \"", "\" \"", "\" san", "san diego", "diego ip", "ip \"", "\" \"", "\"!", "!!", "! go", "go ahead", "ahead and", "and block", "block me", "me -", "- i", "i have", "have zero", "zero interest", "interest in", "in participating", "participating in", "in wi", "wiki", "##ki for", "for this", "this very", "very reason", "reason.", ". you", "you all", "all are", "are armchair", "armchair deputies", "deputies with", "with no", "no proof", "proof to", "to back", "back your", "your accusations", "accusations.", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Dear Sinebot\n\nFuck you.  In case you didn't know... If I don't sign... you take care of it for me...so take those tildes and shove them up your cyber ass mother fucker", "tokenize_content": ["dear", "sin", "##eb", "##ot", "fuck", "you", ".", "in", "case", "you", "didn", "'", "t", "know", ".", ".", ".", "if", "i", "don", "'", "t", "sign", ".", ".", ".", "you", "take", "care", "of", "it", "for", "me", ".", ".", ".", "so", "take", "those", "til", "##des", "and", "shove", "them", "up", "your", "cyber", "ass", "mother", "fuck", "##er"], "span": ["dear sin", "sineb", "##ebot", "##ot fuck", "fuck you", "you.", ". in", "in case", "case you", "you didn", "didn '", "' t", "t know", "know.", "..", "..", ". if", "if i", "i don", "don '", "' t", "t sign", "sign.", "..", "..", ". you", "you take", "take care", "care of", "of it", "it for", "for me", "me.", "..", "..", ". so", "so take", "take those", "those til", "tildes", "##des and", "and shove", "shove them", "them up", "up your", "your cyber", "cyber ass", "ass mother", "mother fuck", "fucker"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]}
{"content": "fuck \n\ni want to fuck you mo", "tokenize_content": ["fuck", "i", "want", "to", "fuck", "you", "mo"], "span": ["fuck i", "i want", "want to", "to fuck", "fuck you", "you mo"], "toxic": 1, "score": [1, 0, 0, 1, 1, 0]}
{"content": "man its all about captain morgans spiced rum. \n\nshut the fuck up barry i hate you.-", "tokenize_content": ["man", "its", "all", "about", "captain", "morgan", "##s", "spice", "##d", "rum", ".", "shut", "the", "fuck", "up", "barry", "i", "hate", "you", ".", "-"], "span": ["man its", "its all", "all about", "about captain", "captain morgan", "morgans", "##s spice", "spiced", "##d rum", "rum.", ". shut", "shut the", "the fuck", "fuck up", "up barry", "barry i", "i hate", "hate you", "you.", ". -"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0]}
{"content": "Yeah, all you have to do is stop being such a bitch.", "tokenize_content": ["yeah", ",", "all", "you", "have", "to", "do", "is", "stop", "being", "such", "a", "bitch", "."], "span": ["yeah,", ", all", "all you", "you have", "have to", "to do", "do is", "is stop", "stop being", "being such", "such a", "a bitch", "bitch."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "Instead of being an asshole, why don't you actually make an effort to help?", "tokenize_content": ["instead", "of", "being", "an", "asshole", ",", "why", "don", "'", "t", "you", "actually", "make", "an", "effort", "to", "help", "?"], "span": ["instead of", "of being", "being an", "an asshole", "asshole,", ", why", "why don", "don '", "' t", "t you", "you actually", "actually make", "make an", "an effort", "effort to", "to help", "help?"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Fuck you Juliancolton.", "tokenize_content": ["fuck", "you", "julian", "##col", "##ton", "."], "span": ["fuck you", "you julian", "juliancol", "##colton", "##ton."], "toxic": 1, "score": [1, 0, 0, 0, 0]}
{"content": "I am going to shoot you in the head and laugh as your brains splatter onto the ground.", "tokenize_content": ["i", "am", "going", "to", "shoot", "you", "in", "the", "head", "and", "laugh", "as", "your", "brains", "sp", "##lat", "##ter", "onto", "the", "ground", "."], "span": ["i am", "am going", "going to", "to shoot", "shoot you", "you in", "in the", "the head", "head and", "and laugh", "laugh as", "as your", "your brains", "brains sp", "splat", "##latter", "##ter onto", "onto the", "the ground", "ground."], "toxic": 1, "score": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "No it isn't.  I came here specifically for this information and it is nowhere to be found.  What a useless puff piece of an article.", "tokenize_content": ["no", "it", "isn", "'", "t", ".", "i", "came", "here", "specifically", "for", "this", "information", "and", "it", "is", "nowhere", "to", "be", "found", ".", "what", "a", "useless", "puff", "piece", "of", "an", "article", "."], "span": ["no it", "it isn", "isn '", "' t", "t.", ". i", "i came", "came here", "here specifically", "specifically for", "for this", "this information", "information and", "and it", "it is", "is nowhere", "nowhere to", "to be", "be found", "found.", ". what", "what a", "a useless", "useless puff", "puff piece", "piece of", "of an", "an article", "article."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "NOT REAL \n\nTHIS GLOBAL WARMING YOU NON GOD FEARING DEMOCRATS TALK ABOUT IS FAKE! - PRESIDENT GEORGE WALKER BUSH", "tokenize_content": ["not", "real", "this", "global", "warming", "you", "non", "god", "fearing", "democrats", "talk", "about", "is", "fake", "!", "-", "president", "george", "walker", "bush"], "span": ["not real", "real this", "this global", "global warming", "warming you", "you non", "non god", "god fearing", "fearing democrats", "democrats talk", "talk about", "about is", "is fake", "fake!", "! -", "- president", "president george", "george walker", "walker bush"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "you have a message re your last change, go fuckyourself!!!", "tokenize_content": ["you", "have", "a", "message", "re", "your", "last", "change", ",", "go", "fuck", "##you", "##rse", "##lf", "!", "!", "!"], "span": ["you have", "have a", "a message", "message re", "re your", "your last", "last change", "change,", ", go", "go fuck", "fuckyou", "##yourse", "##rself", "##lf!", "!!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]}
{"content": "That was really stupid, were you trying to sound cool just now?", "tokenize_content": ["that", "was", "really", "stupid", ",", "were", "you", "trying", "to", "sound", "cool", "just", "now", "?"], "span": ["that was", "was really", "really stupid", "stupid,", ", were", "were you", "you trying", "trying to", "to sound", "sound cool", "cool just", "just now", "now?"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\nWhat? You're too chicken to change your \"\"Declined\"\" decision? You're an admin too, act like one!   \n\n\"", "tokenize_content": ["\"", "what", "?", "you", "'", "re", "too", "chicken", "to", "change", "your", "\"", "\"", "declined", "\"", "\"", "decision", "?", "you", "'", "re", "an", "ad", "##min", "too", ",", "act", "like", "one", "!", "\""], "span": ["\" what", "what?", "? you", "you '", "' re", "re too", "too chicken", "chicken to", "to change", "change your", "your \"", "\" \"", "\" declined", "declined \"", "\" \"", "\" decision", "decision?", "? you", "you '", "' re", "re an", "an ad", "admin", "##min too", "too,", ", act", "act like", "like one", "one!", "! \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\n hi ) \n\n  Fuck You Award As you wish.   \"", "tokenize_content": ["\"", "hi", ")", "fuck", "you", "award", "as", "you", "wish", ".", "\""], "span": ["\" hi", "hi )", ") fuck", "fuck you", "you award", "award as", "as you", "you wish", "wish.", ". \""], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "fag \n\nyou fucking suck. people need to know the true meaning of thumbing", "tokenize_content": ["fa", "##g", "you", "fucking", "suck", ".", "people", "need", "to", "know", "the", "true", "meaning", "of", "thumb", "##ing"], "span": ["fag", "##g you", "you fucking", "fucking suck", "suck.", ". people", "people need", "need to", "to know", "know the", "the true", "true meaning", "meaning of", "of thumb", "thumbing"], "toxic": 1, "score": [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "It is a shame what people are here, I am disgusting of you.", "tokenize_content": ["it", "is", "a", "shame", "what", "people", "are", "here", ",", "i", "am", "disgusting", "of", "you", "."], "span": ["it is", "is a", "a shame", "shame what", "what people", "people are", "are here", "here,", ", i", "i am", "am disgusting", "disgusting of", "of you", "you."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "hey \n\nhey persian gal. i have got a couple of your pubes from when we had some naughty fun back at school.\n\nup 4 cyber?", "tokenize_content": ["hey", "hey", "persian", "gal", ".", "i", "have", "got", "a", "couple", "of", "your", "pub", "##es", "from", "when", "we", "had", "some", "naughty", "fun", "back", "at", "school", ".", "up", "4", "cyber", "?"], "span": ["hey hey", "hey persian", "persian gal", "gal.", ". i", "i have", "have got", "got a", "a couple", "couple of", "of your", "your pub", "pubes", "##es from", "from when", "when we", "we had", "had some", "some naughty", "naughty fun", "fun back", "back at", "at school", "school.", ". up", "up 4", "4 cyber", "cyber?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Question \n\nAre you going to put the images back on the page, if there isn't any more suck puppetry?", "tokenize_content": ["question", "are", "you", "going", "to", "put", "the", "images", "back", "on", "the", "page", ",", "if", "there", "isn", "'", "t", "any", "more", "suck", "puppet", "##ry", "?"], "span": ["question are", "are you", "you going", "going to", "to put", "put the", "the images", "images back", "back on", "on the", "the page", "page,", ", if", "if there", "there isn", "isn '", "' t", "t any", "any more", "more suck", "suck puppet", "puppetry", "##ry?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "You can't delete shit from my talk page you faggot, get that shit out of here", "tokenize_content": ["you", "can", "'", "t", "del", "##ete", "shit", "from", "my", "talk", "page", "you", "fa", "##gg", "##ot", ",", "get", "that", "shit", "out", "of", "here"], "span": ["you can", "can '", "' t", "t del", "delete", "##ete shit", "shit from", "from my", "my talk", "talk page", "page you", "you fa", "fagg", "##ggot", "##ot,", ", get", "get that", "that shit", "shit out", "out of", "of here"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "WHY WAS I BANNED I JUST TRIED TO EDIT A PAGE I NEVER HAVE EDITED BEFORE WTF", "tokenize_content": ["why", "was", "i", "banned", "i", "just", "tried", "to", "edit", "a", "page", "i", "never", "have", "edited", "before", "w", "##tf"], "span": ["why was", "was i", "i banned", "banned i", "i just", "just tried", "tried to", "to edit", "edit a", "a page", "page i", "i never", "never have", "have edited", "edited before", "before w", "wtf"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Hello \n\nYour such a fucking freak mate. Get a life. And get a facelift you ugly cunt. 155.245.0.46", "tokenize_content": ["hello", "your", "such", "a", "fucking", "freak", "mate", ".", "get", "a", "life", ".", "and", "get", "a", "face", "##lift", "you", "ugly", "cu", "##nt", ".", "155", ".", "245", ".", "0", ".", "46"], "span": ["hello your", "your such", "such a", "a fucking", "fucking freak", "freak mate", "mate.", ". get", "get a", "a life", "life.", ". and", "and get", "get a", "a face", "facelift", "##lift you", "you ugly", "ugly cu", "cunt", "##nt.", ". 155", "155.", ". 245", "245.", ". 0", "0.", ". 46"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Stop fucking doing this, you retarded kids, you're going to ruin it for everyone on the kfar.", "tokenize_content": ["stop", "fucking", "doing", "this", ",", "you", "re", "##tar", "##ded", "kids", ",", "you", "'", "re", "going", "to", "ruin", "it", "for", "everyone", "on", "the", "k", "##far", "."], "span": ["stop fucking", "fucking doing", "doing this", "this,", ", you", "you re", "retar", "##tarded", "##ded kids", "kids,", ", you", "you '", "' re", "re going", "going to", "to ruin", "ruin it", "it for", "for everyone", "everyone on", "on the", "the k", "kfar", "##far."], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "SALVIO GIULIANO IS A GIGANTIC ASSHOLE. \n\nI WILL DIG UP YOUR GRANDMOTHER AND SHIT ON HER DENTURES.", "tokenize_content": ["sal", "##vio", "gi", "##ulia", "##no", "is", "a", "gigantic", "asshole", ".", "i", "will", "dig", "up", "your", "grandmother", "and", "shit", "on", "her", "dent", "##ures", "."], "span": ["salvio", "##vio gi", "giulia", "##uliano", "##no is", "is a", "a gigantic", "gigantic asshole", "asshole.", ". i", "i will", "will dig", "dig up", "up your", "your grandmother", "grandmother and", "and shit", "shit on", "on her", "her dent", "dentures", "##ures."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "\"\n\n User:GeorgiaWikiWriter \n\nHello Ymblanter, \n\nI have warned  calling it \"\"a group of fucking morons.\"\" His behavior needs to be addressed asap. Thanks. Jaqeli \"", "tokenize_content": ["\"", "user", ":", "georgia", "##wi", "##ki", "##writer", "hello", "y", "##mb", "##lan", "##ter", ",", "i", "have", "warned", "calling", "it", "\"", "\"", "a", "group", "of", "fucking", "mor", "##ons", ".", "\"", "\"", "his", "behavior", "needs", "to", "be", "addressed", "asa", "##p", ".", "thanks", ".", "ja", "##q", "##eli", "\""], "span": ["\" user", "user :", ": georgia", "georgiawi", "##wiki", "##kiwriter", "##writer hello", "hello y", "ymb", "##mblan", "##lanter", "##ter,", ", i", "i have", "have warned", "warned calling", "calling it", "it \"", "\" \"", "\" a", "a group", "group of", "of fucking", "fucking mor", "morons", "##ons.", ". \"", "\" \"", "\" his", "his behavior", "behavior needs", "needs to", "to be", "be addressed", "addressed asa", "asap", "##p.", ". thanks", "thanks.", ". ja", "jaq", "##qeli", "##eli \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "and  worship the penis of jesus and believe that he was the greatest mother-fucker in the world.", "tokenize_content": ["and", "worship", "the", "penis", "of", "jesus", "and", "believe", "that", "he", "was", "the", "greatest", "mother", "-", "fuck", "##er", "in", "the", "world", "."], "span": ["and worship", "worship the", "the penis", "penis of", "of jesus", "jesus and", "and believe", "believe that", "that he", "he was", "was the", "the greatest", "greatest mother", "mother -", "- fuck", "fucker", "##er in", "in the", "the world", "world."], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "Isang sockpuppet mo! \n\nLOL Confirmed sockpuppet! Wikipedia's nice way of calling you out as a troll. Hopefully you will not be ruining Filipino articles anymore.", "tokenize_content": ["isa", "##ng", "sock", "##pu", "##ppet", "mo", "!", "lo", "##l", "confirmed", "sock", "##pu", "##ppet", "!", "wikipedia", "'", "s", "nice", "way", "of", "calling", "you", "out", "as", "a", "troll", ".", "hopefully", "you", "will", "not", "be", "ruining", "filipino", "articles", "anymore", "."], "span": ["isang", "##ng sock", "sockpu", "##puppet", "##ppet mo", "mo!", "! lo", "lol", "##l confirmed", "confirmed sock", "sockpu", "##puppet", "##ppet!", "! wikipedia", "wikipedia '", "' s", "s nice", "nice way", "way of", "of calling", "calling you", "you out", "out as", "as a", "a troll", "troll.", ". hopefully", "hopefully you", "you will", "will not", "not be", "be ruining", "ruining filipino", "filipino articles", "articles anymore", "anymore."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "You're a twat and a Jew, have a nice day!", "tokenize_content": ["you", "'", "re", "a", "t", "##wat", "and", "a", "jew", ",", "have", "a", "nice", "day", "!"], "span": ["you '", "' re", "re a", "a t", "twat", "##wat and", "and a", "a jew", "jew,", ", have", "have a", "a nice", "nice day", "day!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Jerk Off!\nI can't believe you! Not only did you have the audacity to delete my page about Mr. Jett Odle I, you also reported me. Let me tell you something you jerk, you are a JEW!", "tokenize_content": ["jerk", "off", "!", "i", "can", "'", "t", "believe", "you", "!", "not", "only", "did", "you", "have", "the", "au", "##da", "##city", "to", "del", "##ete", "my", "page", "about", "mr", ".", "jett", "o", "##dle", "i", ",", "you", "also", "reported", "me", ".", "let", "me", "tell", "you", "something", "you", "jerk", ",", "you", "are", "a", "jew", "!"], "span": ["jerk off", "off!", "! i", "i can", "can '", "' t", "t believe", "believe you", "you!", "! not", "not only", "only did", "did you", "you have", "have the", "the au", "auda", "##dacity", "##city to", "to del", "delete", "##ete my", "my page", "page about", "about mr", "mr.", ". jett", "jett o", "odle", "##dle i", "i,", ", you", "you also", "also reported", "reported me", "me.", ". let", "let me", "me tell", "tell you", "you something", "something you", "you jerk", "jerk,", ", you", "you are", "are a", "a jew", "jew!"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]}
{"content": "I want to have sex with all of you!\nI'm so excited!", "tokenize_content": ["i", "want", "to", "have", "sex", "with", "all", "of", "you", "!", "i", "'", "m", "so", "excited", "!"], "span": ["i want", "want to", "to have", "have sex", "sex with", "with all", "all of", "of you", "you!", "! i", "i '", "' m", "m so", "so excited", "excited!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Fuck off you cunt \n\nYou're suck an asshole 142.162.85.154", "tokenize_content": ["fuck", "off", "you", "cu", "##nt", "you", "'", "re", "suck", "an", "asshole", "142", ".", "162", ".", "85", ".", "154"], "span": ["fuck off", "off you", "you cu", "cunt", "##nt you", "you '", "' re", "re suck", "suck an", "an asshole", "asshole 142", "142.", ". 162", "162.", ". 85", "85.", ". 154"], "toxic": 1, "score": [1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "FUCK YOU \n\nYOU ARE THE BIGGEST PIG ON THE PLANET.\n\nDIE IN HELL ASSHOLE!", "tokenize_content": ["fuck", "you", "you", "are", "the", "biggest", "pig", "on", "the", "planet", ".", "die", "in", "hell", "asshole", "!"], "span": ["fuck you", "you you", "you are", "are the", "the biggest", "biggest pig", "pig on", "on the", "the planet", "planet.", ". die", "die in", "in hell", "hell asshole", "asshole!"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "I allways knew wikipedia was a joke, I never realized it catered to queers. You can all go and fuck yourselves", "tokenize_content": ["i", "all", "##ways", "knew", "wikipedia", "was", "a", "joke", ",", "i", "never", "realized", "it", "cater", "##ed", "to", "queer", "##s", ".", "you", "can", "all", "go", "and", "fuck", "yourselves"], "span": ["i all", "allways", "##ways knew", "knew wikipedia", "wikipedia was", "was a", "a joke", "joke,", ", i", "i never", "never realized", "realized it", "it cater", "catered", "##ed to", "to queer", "queers", "##s.", ". you", "you can", "can all", "all go", "go and", "and fuck", "fuck yourselves"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "i dont care \n\ni dont fucking care if you have reported me!!! i will start a new account.  see if i care. your still a fucking asshole!!!", "tokenize_content": ["i", "don", "##t", "care", "i", "don", "##t", "fucking", "care", "if", "you", "have", "reported", "me", "!", "!", "!", "i", "will", "start", "a", "new", "account", ".", "see", "if", "i", "care", ".", "your", "still", "a", "fucking", "asshole", "!", "!", "!"], "span": ["i don", "dont", "##t care", "care i", "i don", "dont", "##t fucking", "fucking care", "care if", "if you", "you have", "have reported", "reported me", "me!", "!!", "!!", "! i", "i will", "will start", "start a", "a new", "new account", "account.", ". see", "see if", "if i", "i care", "care.", ". your", "your still", "still a", "a fucking", "fucking asshole", "asshole!", "!!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]}
{"content": "\"\n\nOh right, like \"\"This article sucks and you know it.\"\" isn't abusive language. Hypocrite. Eat shit and die, loser.\"", "tokenize_content": ["\"", "oh", "right", ",", "like", "\"", "\"", "this", "article", "sucks", "and", "you", "know", "it", ".", "\"", "\"", "isn", "'", "t", "abusive", "language", ".", "h", "##yp", "##oc", "##rite", ".", "eat", "shit", "and", "die", ",", "loser", ".", "\""], "span": ["\" oh", "oh right", "right,", ", like", "like \"", "\" \"", "\" this", "this article", "article sucks", "sucks and", "and you", "you know", "know it", "it.", ". \"", "\" \"", "\" isn", "isn '", "' t", "t abusive", "abusive language", "language.", ". h", "hyp", "##ypoc", "##ocrite", "##rite.", ". eat", "eat shit", "shit and", "and die", "die,", ", loser", "loser.", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0]}
{"content": "You didn't ban me, this is offensive! I have a right to be banned from idiots!", "tokenize_content": ["you", "didn", "'", "t", "ban", "me", ",", "this", "is", "offensive", "!", "i", "have", "a", "right", "to", "be", "banned", "from", "idiots", "!"], "span": ["you didn", "didn '", "' t", "t ban", "ban me", "me,", ", this", "this is", "is offensive", "offensive!", "! i", "i have", "have a", "a right", "right to", "to be", "be banned", "banned from", "from idiots", "idiots!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "truly a \u201cTyranny of the Ignorant\u201d.", "tokenize_content": ["truly", "a", "\u201c", "ty", "##ran", "##ny", "of", "the", "ignorant", "\u201d", "."], "span": ["truly a", "a \u201c", "\u201c ty", "tyran", "##ranny", "##ny of", "of the", "the ignorant", "ignorant \u201d", "\u201d."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}
{"content": "No she did not die that is so stupid!", "tokenize_content": ["no", "she", "did", "not", "die", "that", "is", "so", "stupid", "!"], "span": ["no she", "she did", "did not", "not die", "die that", "that is", "is so", "so stupid", "stupid!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "Gays are disgusting\n\nIt's just my opinion but gays are disgusting.", "tokenize_content": ["gay", "##s", "are", "disgusting", "it", "'", "s", "just", "my", "opinion", "but", "gay", "##s", "are", "disgusting", "."], "span": ["gays", "##s are", "are disgusting", "disgusting it", "it '", "' s", "s just", "just my", "my opinion", "opinion but", "but gay", "gays", "##s are", "are disgusting", "disgusting."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]}
{"content": "Black Jesus \n\nI think he is BLACK JESUS!!!!!!!!!!!!!!!!!!!!!!!!!!!!", "tokenize_content": ["black", "jesus", "i", "think", "he", "is", "black", "jesus", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!", "!"], "span": ["black jesus", "jesus i", "i think", "think he", "he is", "is black", "black jesus", "jesus!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Your sexual fantasies\n\nOn this and a subsequent edit of yours: nobody here is interested in your sexual fantasies. Go away and tell them to somebody else.", "tokenize_content": ["your", "sexual", "fantasies", "on", "this", "and", "a", "subsequent", "edit", "of", "yours", ":", "nobody", "here", "is", "interested", "in", "your", "sexual", "fantasies", ".", "go", "away", "and", "tell", "them", "to", "somebody", "else", "."], "span": ["your sexual", "sexual fantasies", "fantasies on", "on this", "this and", "and a", "a subsequent", "subsequent edit", "edit of", "of yours", "yours :", ": nobody", "nobody here", "here is", "is interested", "interested in", "in your", "your sexual", "sexual fantasies", "fantasies.", ". go", "go away", "away and", "and tell", "tell them", "them to", "to somebody", "somebody else", "else."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "and Pharaoh of the Wizards better fuck his asshole up!", "tokenize_content": ["and", "pharaoh", "of", "the", "wizards", "better", "fuck", "his", "asshole", "up", "!"], "span": ["and pharaoh", "pharaoh of", "of the", "the wizards", "wizards better", "better fuck", "fuck his", "his asshole", "asshole up", "up!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 1, 1, 0]}
{"content": "\"\n\"\"Please\"\", \"\"please\"\", \"\"please\"\", oh shut up.  \"", "tokenize_content": ["\"", "\"", "\"", "please", "\"", "\"", ",", "\"", "\"", "please", "\"", "\"", ",", "\"", "\"", "please", "\"", "\"", ",", "oh", "shut", "up", ".", "\""], "span": ["\" \"", "\" \"", "\" please", "please \"", "\" \"", "\",", ", \"", "\" \"", "\" please", "please \"", "\" \"", "\",", ", \"", "\" \"", "\" please", "please \"", "\" \"", "\",", ", oh", "oh shut", "shut up", "up.", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}
{"content": "THE ONLY PROBLEM WITH THE HOLOCAUST IS THAT SOME JEWS SURVIVED\nOther than that it was awesome!!!!", "tokenize_content": ["the", "only", "problem", "with", "the", "holocaust", "is", "that", "some", "jews", "survived", "other", "than", "that", "it", "was", "awesome", "!", "!", "!", "!"], "span": ["the only", "only problem", "problem with", "with the", "the holocaust", "holocaust is", "is that", "that some", "some jews", "jews survived", "survived other", "other than", "than that", "that it", "it was", "was awesome", "awesome!", "!!", "!!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Yeah you are dickface", "tokenize_content": ["yeah", "you", "are", "dick", "##face"], "span": ["yeah you", "you are", "are dick", "dickface"], "toxic": 1, "score": [0, 0, 1, 1]}
{"content": "You suck man.. Either you are ignorant or b******d. Dont add crap to articles about Hindu communities which are completely wrong..117.211.90.154", "tokenize_content": ["you", "suck", "man", ".", ".", "either", "you", "are", "ignorant", "or", "b", "*", "*", "*", "*", "*", "*", "d", ".", "don", "##t", "add", "crap", "to", "articles", "about", "hindu", "communities", "which", "are", "completely", "wrong", ".", ".", "117", ".", "211", ".", "90", ".", "154"], "span": ["you suck", "suck man", "man.", "..", ". either", "either you", "you are", "are ignorant", "ignorant or", "or b", "b *", "* *", "* *", "* *", "* *", "* *", "* d", "d.", ". don", "dont", "##t add", "add crap", "crap to", "to articles", "articles about", "about hindu", "hindu communities", "communities which", "which are", "are completely", "completely wrong", "wrong.", "..", ". 117", "117.", ". 211", "211.", ". 90", "90.", ". 154"], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\nYou call that creep \"\"a contributor\"\"? You're nuts!   \"", "tokenize_content": ["\"", "you", "call", "that", "creep", "\"", "\"", "a", "contributor", "\"", "\"", "?", "you", "'", "re", "nuts", "!", "\""], "span": ["\" you", "you call", "call that", "that creep", "creep \"", "\" \"", "\" a", "a contributor", "contributor \"", "\" \"", "\"?", "? you", "you '", "' re", "re nuts", "nuts!", "! \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Responce \n\nWhy is it funny because I'm right? You're a peace of crap Shawn. I know I'm right because you had nothing to come back. So go have fun being broken by your corporate masters.", "tokenize_content": ["res", "##pon", "##ce", "why", "is", "it", "funny", "because", "i", "'", "m", "right", "?", "you", "'", "re", "a", "peace", "of", "crap", "shawn", ".", "i", "know", "i", "'", "m", "right", "because", "you", "had", "nothing", "to", "come", "back", ".", "so", "go", "have", "fun", "being", "broken", "by", "your", "corporate", "masters", "."], "span": ["respon", "##ponce", "##ce why", "why is", "is it", "it funny", "funny because", "because i", "i '", "' m", "m right", "right?", "? you", "you '", "' re", "re a", "a peace", "peace of", "of crap", "crap shawn", "shawn.", ". i", "i know", "know i", "i '", "' m", "m right", "right because", "because you", "you had", "had nothing", "nothing to", "to come", "come back", "back.", ". so", "so go", "go have", "have fun", "fun being", "being broken", "broken by", "by your", "your corporate", "corporate masters", "masters."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Why don't you just admit you're an imposter?", "tokenize_content": ["why", "don", "'", "t", "you", "just", "admit", "you", "'", "re", "an", "imp", "##ost", "##er", "?"], "span": ["why don", "don '", "' t", "t you", "you just", "just admit", "admit you", "you '", "' re", "re an", "an imp", "impost", "##oster", "##er?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "u smell \n\nlikw dog poo", "tokenize_content": ["u", "smell", "li", "##k", "##w", "dog", "po", "##o"], "span": ["u smell", "smell li", "lik", "##kw", "##w dog", "dog po", "poo"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0]}
{"content": "Njgw? \n\nYour dead mummy ashes?", "tokenize_content": ["nj", "##g", "##w", "?", "your", "dead", "mummy", "ashes", "?"], "span": ["njg", "##gw", "##w?", "? your", "your dead", "dead mummy", "mummy ashes", "ashes?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Hell, no. I ain't serving the war, I was helping people, This is fucked up.", "tokenize_content": ["hell", ",", "no", ".", "i", "ain", "'", "t", "serving", "the", "war", ",", "i", "was", "helping", "people", ",", "this", "is", "fucked", "up", "."], "span": ["hell,", ", no", "no.", ". i", "i ain", "ain '", "' t", "t serving", "serving the", "the war", "war,", ", i", "i was", "was helping", "helping people", "people,", ", this", "this is", "is fucked", "fucked up", "up."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "WANKERS\n\nonly on wikipedia\n\neat your fucking american ego", "tokenize_content": ["wan", "##kers", "only", "on", "wikipedia", "eat", "your", "fucking", "american", "ego"], "span": ["wankers", "##kers only", "only on", "on wikipedia", "wikipedia eat", "eat your", "your fucking", "fucking american", "american ego"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "Hi! I am back again!\nLast warning!\nStop undoing my edits or die!", "tokenize_content": ["hi", "!", "i", "am", "back", "again", "!", "last", "warning", "!", "stop", "undo", "##ing", "my", "edit", "##s", "or", "die", "!"], "span": ["hi!", "! i", "i am", "am back", "back again", "again!", "! last", "last warning", "warning!", "! stop", "stop undo", "undoing", "##ing my", "my edit", "edits", "##s or", "or die", "die!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "Mud \n\nWhat the fuck are you doing?  I added the adjusted score for Mud.  Don't undo my changes you fucking moron.\n\nhttp://www.rottentomatoes.com/guides/summer-movie-scorecard-2013/", "tokenize_content": ["mud", "what", "the", "fuck", "are", "you", "doing", "?", "i", "added", "the", "adjusted", "score", "for", "mud", ".", "don", "'", "t", "undo", "my", "changes", "you", "fucking", "mor", "##on", ".", "http", ":", "/", "/", "www", ".", "rotten", "##tom", "##ato", "##es", ".", "com", "/", "guides", "/", "summer", "-", "movie", "-", "score", "##card", "-", "2013", "/"], "span": ["mud what", "what the", "the fuck", "fuck are", "are you", "you doing", "doing?", "? i", "i added", "added the", "the adjusted", "adjusted score", "score for", "for mud", "mud.", ". don", "don '", "' t", "t undo", "undo my", "my changes", "changes you", "you fucking", "fucking mor", "moron", "##on.", ". http", "http :", ": /", "/ /", "/ www", "www.", ". rotten", "rottentom", "##tomato", "##atoes", "##es.", ". com", "com /", "/ guides", "guides /", "/ summer", "summer -", "- movie", "movie -", "- score", "scorecard", "##card -", "- 2013", "2013 /"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "uh i wanna fuck you hard on the sink", "tokenize_content": ["uh", "i", "wanna", "fuck", "you", "hard", "on", "the", "sink"], "span": ["uh i", "i wanna", "wanna fuck", "fuck you", "you hard", "hard on", "on the", "the sink"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "Are you a Jew \n\nAre you a jew? Don't pollute Obama's article with your snot.", "tokenize_content": ["are", "you", "a", "jew", "are", "you", "a", "jew", "?", "don", "'", "t", "poll", "##ute", "obama", "'", "s", "article", "with", "your", "s", "##not", "."], "span": ["are you", "you a", "a jew", "jew are", "are you", "you a", "a jew", "jew?", "? don", "don '", "' t", "t poll", "pollute", "##ute obama", "obama '", "' s", "s article", "article with", "with your", "your s", "snot", "##not."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Oh come,  on not again.  Admins, stop wasting time and just permaban, you know the situation won't change.", "tokenize_content": ["oh", "come", ",", "on", "not", "again", ".", "ad", "##mins", ",", "stop", "wasting", "time", "and", "just", "per", "##ma", "##ban", ",", "you", "know", "the", "situation", "won", "'", "t", "change", "."], "span": ["oh come", "come,", ", on", "on not", "not again", "again.", ". ad", "admins", "##mins,", ", stop", "stop wasting", "wasting time", "time and", "and just", "just per", "perma", "##maban", "##ban,", ", you", "you know", "know the", "the situation", "situation won", "won '", "' t", "t change", "change."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Can't Win! \n\nHahahahahahahahahah! Did you think you could get away so easy? No matter what you do, one of 2 things will happen:\n\nA) You resign\nB) You die!\n\nChoose carefully!", "tokenize_content": ["can", "'", "t", "win", "!", "ha", "##ha", "##ha", "##ha", "##ha", "##ha", "##ha", "##ha", "##ha", "##h", "!", "did", "you", "think", "you", "could", "get", "away", "so", "easy", "?", "no", "matter", "what", "you", "do", ",", "one", "of", "2", "things", "will", "happen", ":", "a", ")", "you", "resign", "b", ")", "you", "die", "!", "choose", "carefully", "!"], "span": ["can '", "' t", "t win", "win!", "! ha", "haha", "##haha", "##haha", "##haha", "##haha", "##haha", "##haha", "##haha", "##hah", "##h!", "! did", "did you", "you think", "think you", "you could", "could get", "get away", "away so", "so easy", "easy?", "? no", "no matter", "matter what", "what you", "you do", "do,", ", one", "one of", "of 2", "2 things", "things will", "will happen", "happen :", ": a", "a )", ") you", "you resign", "resign b", "b )", ") you", "you die", "die!", "! choose", "choose carefully", "carefully!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]}
{"content": "To the faggot \n\nCoffee Expliciton", "tokenize_content": ["to", "the", "fa", "##gg", "##ot", "coffee", "explicit", "##on"], "span": ["to the", "the fa", "fagg", "##ggot", "##ot coffee", "coffee explicit", "expliciton"], "toxic": 1, "score": [0, 0, 1, 0, 0, 0, 0]}
{"content": "unblock|Material scientist isa dum dum and so is Pbass607 #yolo #swag #they are both gay with each other", "tokenize_content": ["un", "##block", "|", "material", "scientist", "isa", "du", "##m", "du", "##m", "and", "so", "is", "pba", "##ss", "##60", "##7", "#", "yo", "##lo", "#", "sw", "##ag", "#", "they", "are", "both", "gay", "with", "each", "other"], "span": ["unblock", "##block |", "| material", "material scientist", "scientist isa", "isa du", "dum", "##m du", "dum", "##m and", "and so", "so is", "is pba", "pbass", "##ss60", "##607", "##7 #", "# yo", "yolo", "##lo #", "# sw", "swag", "##ag #", "# they", "they are", "are both", "both gay", "gay with", "with each", "each other"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "Dont fuck with wikipedia admins you filthy jew  (tlk) (cntrbtns)", "tokenize_content": ["don", "##t", "fuck", "with", "wikipedia", "ad", "##mins", "you", "filthy", "jew", "(", "t", "##lk", ")", "(", "cn", "##tr", "##bt", "##ns", ")"], "span": ["dont", "##t fuck", "fuck with", "with wikipedia", "wikipedia ad", "admins", "##mins you", "you filthy", "filthy jew", "jew (", "( t", "tlk", "##lk )", ") (", "( cn", "cntr", "##trbt", "##btns", "##ns )"], "toxic": 1, "score": [0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\na play on \"\"Full of shit\"\". Unblock it if you like.  \"", "tokenize_content": ["\"", "a", "play", "on", "\"", "\"", "full", "of", "shit", "\"", "\"", ".", "un", "##block", "it", "if", "you", "like", ".", "\""], "span": ["\" a", "a play", "play on", "on \"", "\" \"", "\" full", "full of", "of shit", "shit \"", "\" \"", "\".", ". un", "unblock", "##block it", "it if", "if you", "you like", "like.", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "You must be killed by me \n\nI support \u5f71\u6b66\u8005 forever!!!", "tokenize_content": ["you", "must", "be", "killed", "by", "me", "i", "support", "[UNK]", "\u6b66", "[UNK]", "forever", "!", "!", "!"], "span": ["you must", "must be", "be killed", "killed by", "by me", "me i", "i support", "support", "\u6b66", "\u6b66", "forever", "forever!", "!!", "!!"], "toxic": 1, "score": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I don't give a fuck. I just want to point out that responding to you casting aspersions like the above, and your previous comment, and most of your recent comments in fact, is not baiting.", "tokenize_content": ["i", "don", "'", "t", "give", "a", "fuck", ".", "i", "just", "want", "to", "point", "out", "that", "responding", "to", "you", "casting", "as", "##pers", "##ions", "like", "the", "above", ",", "and", "your", "previous", "comment", ",", "and", "most", "of", "your", "recent", "comments", "in", "fact", ",", "is", "not", "bait", "##ing", "."], "span": ["i don", "don '", "' t", "t give", "give a", "a fuck", "fuck.", ". i", "i just", "just want", "want to", "to point", "point out", "out that", "that responding", "responding to", "to you", "you casting", "casting as", "aspers", "##persions", "##ions like", "like the", "the above", "above,", ", and", "and your", "your previous", "previous comment", "comment,", ", and", "and most", "most of", "of your", "your recent", "recent comments", "comments in", "in fact", "fact,", ", is", "is not", "not bait", "baiting", "##ing."], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Just because you're atheist doesn't mean you're a devil worshiper, moron. 50.53.50.113", "tokenize_content": ["just", "because", "you", "'", "re", "atheist", "doesn", "'", "t", "mean", "you", "'", "re", "a", "devil", "worship", "##er", ",", "mor", "##on", ".", "50", ".", "53", ".", "50", ".", "113"], "span": ["just because", "because you", "you '", "' re", "re atheist", "atheist doesn", "doesn '", "' t", "t mean", "mean you", "you '", "' re", "re a", "a devil", "devil worship", "worshiper", "##er,", ", mor", "moron", "##on.", ". 50", "50.", ". 53", "53.", ". 50", "50.", ". 113"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "wtf.... sefton is the highest ranking partially-selective school..\n\ndon't u know how to use google you tool.", "tokenize_content": ["w", "##tf", ".", ".", ".", ".", "se", "##ft", "##on", "is", "the", "highest", "ranking", "partially", "-", "selective", "school", ".", ".", "don", "'", "t", "u", "know", "how", "to", "use", "google", "you", "tool", "."], "span": ["wtf", "##tf.", "..", "..", "..", ". se", "seft", "##fton", "##on is", "is the", "the highest", "highest ranking", "ranking partially", "partially -", "- selective", "selective school", "school.", "..", ". don", "don '", "' t", "t u", "u know", "know how", "how to", "to use", "use google", "google you", "you tool", "tool."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I wasn't talking to you jerkso, your sucj an idiot you cant even realize when someone is talking to you. No go back to your trailer boy!", "tokenize_content": ["i", "wasn", "'", "t", "talking", "to", "you", "jerk", "##so", ",", "your", "su", "##c", "##j", "an", "idiot", "you", "can", "##t", "even", "realize", "when", "someone", "is", "talking", "to", "you", ".", "no", "go", "back", "to", "your", "trailer", "boy", "!"], "span": ["i wasn", "wasn '", "' t", "t talking", "talking to", "to you", "you jerk", "jerkso", "##so,", ", your", "your su", "suc", "##cj", "##j an", "an idiot", "idiot you", "you can", "cant", "##t even", "even realize", "realize when", "when someone", "someone is", "is talking", "talking to", "to you", "you.", ". no", "no go", "go back", "back to", "to your", "your trailer", "trailer boy", "boy!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "DON'T BLOCK ME I AM RIGHT AND I FUCKING KNOW IT. BLOCK THAT ASSHOLE KANSAS BEAR OR SOMETHING. JUST LEAVE ME THE FUCK ALONE.", "tokenize_content": ["don", "'", "t", "block", "me", "i", "am", "right", "and", "i", "fucking", "know", "it", ".", "block", "that", "asshole", "kansas", "bear", "or", "something", ".", "just", "leave", "me", "the", "fuck", "alone", "."], "span": ["don '", "' t", "t block", "block me", "me i", "i am", "am right", "right and", "and i", "i fucking", "fucking know", "know it", "it.", ". block", "block that", "that asshole", "asshole kansas", "kansas bear", "bear or", "or something", "something.", ". just", "just leave", "leave me", "me the", "the fuck", "fuck alone", "alone."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "Can you go fuck yourself?  ) 15:26, 31 March 2008 (GMT)", "tokenize_content": ["can", "you", "go", "fuck", "yourself", "?", ")", "15", ":", "26", ",", "31", "march", "2008", "(", "gm", "##t", ")"], "span": ["can you", "you go", "go fuck", "fuck yourself", "yourself?", "? )", ") 15", "15 :", ": 26", "26,", ", 31", "31 march", "march 2008", "2008 (", "( gm", "gmt", "##t )"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Is dat sum hermaphrodite? \n\nlolololololololollololololololllolololololololololo", "tokenize_content": ["is", "dat", "sum", "her", "##ma", "##ph", "##rod", "##ite", "?", "lo", "##lo", "##lo", "##lo", "##lo", "##lo", "##lo", "##lo", "##llo", "##lo", "##lo", "##lo", "##lo", "##lo", "##ll", "##lo", "##lo", "##lo", "##lo", "##lo", "##lo", "##lo", "##lo", "##lo", "##lo"], "span": ["is dat", "dat sum", "sum her", "herma", "##maph", "##phrod", "##rodite", "##ite?", "? lo", "lolo", "##lolo", "##lolo", "##lolo", "##lolo", "##lolo", "##lolo", "##lollo", "##llolo", "##lolo", "##lolo", "##lolo", "##lolo", "##loll", "##lllo", "##lolo", "##lolo", "##lolo", "##lolo", "##lolo", "##lolo", "##lolo", "##lolo", "##lolo"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "im gonna guess you are the same bigoted non normal that wrote this hate page in the first place. you and your gay friends are all pedophiles.", "tokenize_content": ["im", "gonna", "guess", "you", "are", "the", "same", "big", "##oted", "non", "normal", "that", "wrote", "this", "hate", "page", "in", "the", "first", "place", ".", "you", "and", "your", "gay", "friends", "are", "all", "pe", "##do", "##phile", "##s", "."], "span": ["im gonna", "gonna guess", "guess you", "you are", "are the", "the same", "same big", "bigoted", "##oted non", "non normal", "normal that", "that wrote", "wrote this", "this hate", "hate page", "page in", "in the", "the first", "first place", "place.", ". you", "you and", "and your", "your gay", "gay friends", "friends are", "are all", "all pe", "pedo", "##dophile", "##philes", "##s."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Ya muthafuckers \n\nblocked You guys are dumbasses. You'd better be a bit more sane or you will face a lifelong sentence in an asylum. This is directed at Pikang.", "tokenize_content": ["ya", "mu", "##tha", "##fu", "##cker", "##s", "blocked", "you", "guys", "are", "dumb", "##asse", "##s", ".", "you", "'", "d", "better", "be", "a", "bit", "more", "sane", "or", "you", "will", "face", "a", "lifelong", "sentence", "in", "an", "asylum", ".", "this", "is", "directed", "at", "pi", "##kan", "##g", "."], "span": ["ya mu", "mutha", "##thafu", "##fucker", "##ckers", "##s blocked", "blocked you", "you guys", "guys are", "are dumb", "dumbasse", "##asses", "##s.", ". you", "you '", "' d", "d better", "better be", "be a", "a bit", "bit more", "more sane", "sane or", "or you", "you will", "will face", "face a", "a lifelong", "lifelong sentence", "sentence in", "in an", "an asylum", "asylum.", ". this", "this is", "is directed", "directed at", "at pi", "pikan", "##kang", "##g."], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "your edit on my talk page \n\noh yeah, if you block me ill just turn my router on and off and ill get a new ip LOL, and vandalise everything all over again...", "tokenize_content": ["your", "edit", "on", "my", "talk", "page", "oh", "yeah", ",", "if", "you", "block", "me", "ill", "just", "turn", "my", "route", "##r", "on", "and", "off", "and", "ill", "get", "a", "new", "ip", "lo", "##l", ",", "and", "van", "##dal", "##ise", "everything", "all", "over", "again", ".", ".", "."], "span": ["your edit", "edit on", "on my", "my talk", "talk page", "page oh", "oh yeah", "yeah,", ", if", "if you", "you block", "block me", "me ill", "ill just", "just turn", "turn my", "my route", "router", "##r on", "on and", "and off", "off and", "and ill", "ill get", "get a", "a new", "new ip", "ip lo", "lol", "##l,", ", and", "and van", "vandal", "##dalise", "##ise everything", "everything all", "all over", "over again", "again.", "..", ".."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Give me one reason to listen to a moron like you.", "tokenize_content": ["give", "me", "one", "reason", "to", "listen", "to", "a", "mor", "##on", "like", "you", "."], "span": ["give me", "me one", "one reason", "reason to", "to listen", "listen to", "to a", "a mor", "moron", "##on like", "like you", "you."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]}
{"content": "supper, you hungry bitch", "tokenize_content": ["supper", ",", "you", "hungry", "bitch"], "span": ["supper,", ", you", "you hungry", "hungry bitch"], "toxic": 1, "score": [0, 0, 0, 1]}
{"content": "This Fox platform article is someone's a dream up crap.. do a little research on Ford and Mustangs before posting.", "tokenize_content": ["this", "fox", "platform", "article", "is", "someone", "'", "s", "a", "dream", "up", "crap", ".", ".", "do", "a", "little", "research", "on", "ford", "and", "mustang", "##s", "before", "posting", "."], "span": ["this fox", "fox platform", "platform article", "article is", "is someone", "someone '", "' s", "s a", "a dream", "dream up", "up crap", "crap.", "..", ". do", "do a", "a little", "little research", "research on", "on ford", "ford and", "and mustang", "mustangs", "##s before", "before posting", "posting."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\n That's nice. And your work has been \"\"constructive,\"\" you WikiNazi Watermelon prevaricative putz? 71.125.130.14  \"", "tokenize_content": ["\"", "that", "'", "s", "nice", ".", "and", "your", "work", "has", "been", "\"", "\"", "constructive", ",", "\"", "\"", "you", "wi", "##kin", "##azi", "water", "##mel", "##on", "pre", "##var", "##icative", "put", "##z", "?", "71", ".", "125", ".", "130", ".", "14", "\""], "span": ["\" that", "that '", "' s", "s nice", "nice.", ". and", "and your", "your work", "work has", "has been", "been \"", "\" \"", "\" constructive", "constructive,", ", \"", "\" \"", "\" you", "you wi", "wikin", "##kinazi", "##azi water", "watermel", "##melon", "##on pre", "prevar", "##varicative", "##icative put", "putz", "##z?", "? 71", "71.", ". 125", "125.", ". 130", "130.", ". 14", "14 \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Regardless, you are acting like a fifteen year old fanboy. Barricade is NOT in the movie. Grow up.", "tokenize_content": ["regardless", ",", "you", "are", "acting", "like", "a", "fifteen", "year", "old", "fan", "##boy", ".", "barr", "##ica", "##de", "is", "not", "in", "the", "movie", ".", "grow", "up", "."], "span": ["regardless,", ", you", "you are", "are acting", "acting like", "like a", "a fifteen", "fifteen year", "year old", "old fan", "fanboy", "##boy.", ". barr", "barrica", "##icade", "##de is", "is not", "not in", "in the", "the movie", "movie.", ". grow", "grow up", "up."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Greetings\n\nHey douche bag, wassup?", "tokenize_content": ["greeting", "##s", "hey", "do", "##uche", "bag", ",", "was", "##su", "##p", "?"], "span": ["greetings", "##s hey", "hey do", "douche", "##uche bag", "bag,", ", was", "wassu", "##sup", "##p?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\n your turn \n\nHELP I FEEL LIKE IM GOING TO KILL MYSELF...........  \u2014 Preceding unsigned comment added by 178.238.232.86   \"", "tokenize_content": ["\"", "your", "turn", "help", "i", "feel", "like", "im", "going", "to", "kill", "myself", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "\u2014", "preceding", "unsigned", "comment", "added", "by", "178", ".", "238", ".", "232", ".", "86", "\""], "span": ["\" your", "your turn", "turn help", "help i", "i feel", "feel like", "like im", "im going", "going to", "to kill", "kill myself", "myself.", "..", "..", "..", "..", "..", "..", "..", "..", "..", "..", ". \u2014", "\u2014 preceding", "preceding unsigned", "unsigned comment", "comment added", "added by", "by 178", "178.", ". 238", "238.", ". 232", "232.", ". 86", "86 \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "May 2006 (UTC)\n\nYou are ignorant and vandal! Stop it! 14:46, 25", "tokenize_content": ["may", "2006", "(", "utc", ")", "you", "are", "ignorant", "and", "van", "##dal", "!", "stop", "it", "!", "14", ":", "46", ",", "25"], "span": ["may 2006", "2006 (", "( utc", "utc )", ") you", "you are", "are ignorant", "ignorant and", "and van", "vandal", "##dal!", "! stop", "stop it", "it!", "! 14", "14 :", ": 46", "46,", ", 25"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"              Listen up, \"\"Farix\"\". Keep this crap up with saying I can't do stuff and you're gonna get it. Got it?  Bakutrix\"", "tokenize_content": ["\"", "listen", "up", ",", "\"", "\"", "far", "##ix", "\"", "\"", ".", "keep", "this", "crap", "up", "with", "saying", "i", "can", "'", "t", "do", "stuff", "and", "you", "'", "re", "gonna", "get", "it", ".", "got", "it", "?", "baku", "##trix", "\""], "span": ["\" listen", "listen up", "up,", ", \"", "\" \"", "\" far", "farix", "##ix \"", "\" \"", "\".", ". keep", "keep this", "this crap", "crap up", "up with", "with saying", "saying i", "i can", "can '", "' t", "t do", "do stuff", "stuff and", "and you", "you '", "' re", "re gonna", "gonna get", "get it", "it.", ". got", "got it", "it?", "? baku", "bakutrix", "##trix \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "You're an asshole, useless piece of shit. Get a life, motherfucker!", "tokenize_content": ["you", "'", "re", "an", "asshole", ",", "useless", "piece", "of", "shit", ".", "get", "a", "life", ",", "mother", "##fu", "##cker", "!"], "span": ["you '", "' re", "re an", "an asshole", "asshole,", ", useless", "useless piece", "piece of", "of shit", "shit.", ". get", "get a", "a life", "life,", ", mother", "motherfu", "##fucker", "##cker!"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "Why, hello, Mr.Fucking jackass cunt, remember me? I wasnt gone.Suck my fucking cock.", "tokenize_content": ["why", ",", "hello", ",", "mr", ".", "fucking", "jack", "##ass", "cu", "##nt", ",", "remember", "me", "?", "i", "wasn", "##t", "gone", ".", "suck", "my", "fucking", "cock", "."], "span": ["why,", ", hello", "hello,", ", mr", "mr.", ". fucking", "fucking jack", "jackass", "##ass cu", "cunt", "##nt,", ", remember", "remember me", "me?", "? i", "i wasn", "wasnt", "##t gone", "gone.", ". suck", "suck my", "my fucking", "fucking cock", "cock."], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]}
{"content": "I am a dubass who knows nothing about Hinduism.", "tokenize_content": ["i", "am", "a", "dub", "##ass", "who", "knows", "nothing", "about", "hinduism", "."], "span": ["i am", "am a", "a dub", "dubass", "##ass who", "who knows", "knows nothing", "nothing about", "about hinduism", "hinduism."], "toxic": 1, "score": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]}
{"content": "Our boss doesn't give a crap.  We're on facebook all day.  But seriously, it's that big of an issue, that you have to block out everyone? That seems a bit unreasonable.  Have a good day.", "tokenize_content": ["our", "boss", "doesn", "'", "t", "give", "a", "crap", ".", "we", "'", "re", "on", "facebook", "all", "day", ".", "but", "seriously", ",", "it", "'", "s", "that", "big", "of", "an", "issue", ",", "that", "you", "have", "to", "block", "out", "everyone", "?", "that", "seems", "a", "bit", "unreasonable", ".", "have", "a", "good", "day", "."], "span": ["our boss", "boss doesn", "doesn '", "' t", "t give", "give a", "a crap", "crap.", ". we", "we '", "' re", "re on", "on facebook", "facebook all", "all day", "day.", ". but", "but seriously", "seriously,", ", it", "it '", "' s", "s that", "that big", "big of", "of an", "an issue", "issue,", ", that", "that you", "you have", "have to", "to block", "block out", "out everyone", "everyone?", "? that", "that seems", "seems a", "a bit", "bit unreasonable", "unreasonable.", ". have", "have a", "a good", "good day", "day."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Barack Obama is mentally retarted. He is not fit to be president. he is the worst president so far, that we have had in our presidents.", "tokenize_content": ["barack", "obama", "is", "mentally", "re", "##tar", "##ted", ".", "he", "is", "not", "fit", "to", "be", "president", ".", "he", "is", "the", "worst", "president", "so", "far", ",", "that", "we", "have", "had", "in", "our", "presidents", "."], "span": ["barack obama", "obama is", "is mentally", "mentally re", "retar", "##tarted", "##ted.", ". he", "he is", "is not", "not fit", "fit to", "to be", "be president", "president.", ". he", "he is", "is the", "the worst", "worst president", "president so", "so far", "far,", ", that", "that we", "we have", "have had", "had in", "in our", "our presidents", "presidents."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Austrians = nazis \n\nOh come on dude, you know it's true. Are you a sympathizer to the huns?192.12.88.2", "tokenize_content": ["austrians", "=", "nazis", "oh", "come", "on", "dude", ",", "you", "know", "it", "'", "s", "true", ".", "are", "you", "a", "sy", "##mp", "##athi", "##zer", "to", "the", "hu", "##ns", "?", "192", ".", "12", ".", "88", ".", "2"], "span": ["austrians =", "= nazis", "nazis oh", "oh come", "come on", "on dude", "dude,", ", you", "you know", "know it", "it '", "' s", "s true", "true.", ". are", "are you", "you a", "a sy", "symp", "##mpathi", "##athizer", "##zer to", "to the", "the hu", "huns", "##ns?", "? 192", "192.", ". 12", "12.", ". 88", "88.", ". 2"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "(UTC)\nThis disgusting coal burner got what she deserved. I hope this whole incident discourages other white prostitutes from consorting with apes. 96.48.13.234  00:03, 30 August 2010", "tokenize_content": ["(", "utc", ")", "this", "disgusting", "coal", "burn", "##er", "got", "what", "she", "deserved", ".", "i", "hope", "this", "whole", "incident", "discourage", "##s", "other", "white", "prostitutes", "from", "consort", "##ing", "with", "apes", ".", "96", ".", "48", ".", "13", ".", "234", "00", ":", "03", ",", "30", "august", "2010"], "span": ["( utc", "utc )", ") this", "this disgusting", "disgusting coal", "coal burn", "burner", "##er got", "got what", "what she", "she deserved", "deserved.", ". i", "i hope", "hope this", "this whole", "whole incident", "incident discourage", "discourages", "##s other", "other white", "white prostitutes", "prostitutes from", "from consort", "consorting", "##ing with", "with apes", "apes.", ". 96", "96.", ". 48", "48.", ". 13", "13.", ". 234", "234 00", "00 :", ": 03", "03,", ", 30", "30 august", "august 2010"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "What shit u talk to me, communist rat?", "tokenize_content": ["what", "shit", "u", "talk", "to", "me", ",", "communist", "rat", "?"], "span": ["what shit", "shit u", "u talk", "talk to", "to me", "me,", ", communist", "communist rat", "rat?"], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 1, 0]}
{"content": "Special note, for a special someone \n\nFuck you, eat shit.", "tokenize_content": ["special", "note", ",", "for", "a", "special", "someone", "fuck", "you", ",", "eat", "shit", "."], "span": ["special note", "note,", ", for", "for a", "a special", "special someone", "someone fuck", "fuck you", "you,", ", eat", "eat shit", "shit."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1]}
{"content": "Serves you right \n\nHaha! You are finally blocked for 1 month! Serves you right! Bwahhahahaha sucker!", "tokenize_content": ["serves", "you", "right", "ha", "##ha", "!", "you", "are", "finally", "blocked", "for", "1", "month", "!", "serves", "you", "right", "!", "b", "##wa", "##hh", "##aha", "##ha", "##ha", "sucker", "!"], "span": ["serves you", "you right", "right ha", "haha", "##ha!", "! you", "you are", "are finally", "finally blocked", "blocked for", "for 1", "1 month", "month!", "! serves", "serves you", "you right", "right!", "! b", "bwa", "##wahh", "##hhaha", "##ahaha", "##haha", "##ha sucker", "sucker!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "This lying piece of Communist garbage should feel neither comfortable nor safe. 1.227.149.33", "tokenize_content": ["this", "lying", "piece", "of", "communist", "garbage", "should", "feel", "neither", "comfortable", "nor", "safe", ".", "1", ".", "227", ".", "149", ".", "33"], "span": ["this lying", "lying piece", "piece of", "of communist", "communist garbage", "garbage should", "should feel", "feel neither", "neither comfortable", "comfortable nor", "nor safe", "safe.", ". 1", "1.", ". 227", "227.", ". 149", "149.", ". 33"], "toxic": 1, "score": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Why the US sucks \n\nYa so the us sucs cuz bugh is dumb and they have to much army and people are to mean in new york and jesusland is to big and ya. So anyway, this was severs opinion", "tokenize_content": ["why", "the", "us", "sucks", "ya", "so", "the", "us", "su", "##cs", "cu", "##z", "bug", "##h", "is", "dumb", "and", "they", "have", "to", "much", "army", "and", "people", "are", "to", "mean", "in", "new", "york", "and", "jesus", "##land", "is", "to", "big", "and", "ya", ".", "so", "anyway", ",", "this", "was", "se", "##vers", "opinion"], "span": ["why the", "the us", "us sucks", "sucks ya", "ya so", "so the", "the us", "us su", "sucs", "##cs cu", "cuz", "##z bug", "bugh", "##h is", "is dumb", "dumb and", "and they", "they have", "have to", "to much", "much army", "army and", "and people", "people are", "are to", "to mean", "mean in", "in new", "new york", "york and", "and jesus", "jesusland", "##land is", "is to", "to big", "big and", "and ya", "ya.", ". so", "so anyway", "anyway,", ", this", "this was", "was se", "severs", "##vers opinion"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "and notice i am a dick", "tokenize_content": ["and", "notice", "i", "am", "a", "dick"], "span": ["and notice", "notice i", "i am", "am a", "a dick"], "toxic": 1, "score": [0, 0, 0, 0, 1]}
{"content": "2012 (UTC)\n\nThe fact that you're a dick probably didn't help either!!212.183.128.42  00:03, 4 November", "tokenize_content": ["2012", "(", "utc", ")", "the", "fact", "that", "you", "'", "re", "a", "dick", "probably", "didn", "'", "t", "help", "either", "!", "!", "212", ".", "183", ".", "128", ".", "42", "00", ":", "03", ",", "4", "november"], "span": ["2012 (", "( utc", "utc )", ") the", "the fact", "fact that", "that you", "you '", "' re", "re a", "a dick", "dick probably", "probably didn", "didn '", "' t", "t help", "help either", "either!", "!!", "! 212", "212.", ". 183", "183.", ". 128", "128.", ". 42", "42 00", "00 :", ": 03", "03,", ", 4", "4 november"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Guys I'm fucking bored give me something to do \n\nGuys I'm fucking bored give me something to do", "tokenize_content": ["guys", "i", "'", "m", "fucking", "bored", "give", "me", "something", "to", "do", "guys", "i", "'", "m", "fucking", "bored", "give", "me", "something", "to", "do"], "span": ["guys i", "i '", "' m", "m fucking", "fucking bored", "bored give", "give me", "me something", "something to", "to do", "do guys", "guys i", "i '", "' m", "m fucking", "fucking bored", "bored give", "give me", "me something", "something to", "to do"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]}
{"content": "My blocks \nLOL You mudsharking nigger lovers are idiots, I'm on a Dynamic IP 76.110.175.48   '''And", "tokenize_content": ["my", "blocks", "lo", "##l", "you", "mud", "##sha", "##rkin", "##g", "ni", "##gger", "lovers", "are", "idiots", ",", "i", "'", "m", "on", "a", "dynamic", "ip", "76", ".", "110", ".", "175", ".", "48", "'", "'", "'", "and"], "span": ["my blocks", "blocks lo", "lol", "##l you", "you mud", "mudsha", "##sharkin", "##rking", "##g ni", "nigger", "##gger lovers", "lovers are", "are idiots", "idiots,", ", i", "i '", "' m", "m on", "on a", "a dynamic", "dynamic ip", "ip 76", "76.", ". 110", "110.", ". 175", "175.", ". 48", "48 '", "' '", "' '", "' and"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "along that note I also like taking it so far in the ass with sixty diffrent cocks that the cum pous out of my mouth!", "tokenize_content": ["along", "that", "note", "i", "also", "like", "taking", "it", "so", "far", "in", "the", "ass", "with", "sixty", "di", "##ff", "##rent", "cock", "##s", "that", "the", "cum", "po", "##us", "out", "of", "my", "mouth", "!"], "span": ["along that", "that note", "note i", "i also", "also like", "like taking", "taking it", "it so", "so far", "far in", "in the", "the ass", "ass with", "with sixty", "sixty di", "diff", "##ffrent", "##rent cock", "cocks", "##s that", "that the", "the cum", "cum po", "pous", "##us out", "out of", "of my", "my mouth", "mouth!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Does it ever dawn on you that you are the reason some people hate Jews?", "tokenize_content": ["does", "it", "ever", "dawn", "on", "you", "that", "you", "are", "the", "reason", "some", "people", "hate", "jews", "?"], "span": ["does it", "it ever", "ever dawn", "dawn on", "on you", "you that", "that you", "you are", "are the", "the reason", "reason some", "some people", "people hate", "hate jews", "jews?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}
{"content": "You would understand... \n\nYou would understand if you had arse face haemorrhoids!", "tokenize_content": ["you", "would", "understand", ".", ".", ".", "you", "would", "understand", "if", "you", "had", "ars", "##e", "face", "ha", "##em", "##or", "##rh", "##oids", "!"], "span": ["you would", "would understand", "understand.", "..", "..", ". you", "you would", "would understand", "understand if", "if you", "you had", "had ars", "arse", "##e face", "face ha", "haem", "##emor", "##orrh", "##rhoids", "##oids!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Stop erasing the truth fag.'''\n== \n Headline text \n\n== \n Headline text \n ==\n ==", "tokenize_content": ["stop", "eras", "##ing", "the", "truth", "fa", "##g", ".", "'", "'", "'", "=", "=", "headline", "text", "=", "=", "headline", "text", "=", "=", "=", "="], "span": ["stop eras", "erasing", "##ing the", "the truth", "truth fa", "fag", "##g.", ". '", "' '", "' '", "' =", "= =", "= headline", "headline text", "text =", "= =", "= headline", "headline text", "text =", "= =", "= =", "= ="], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Remove \n\nNeilN needs to extract his head from his butt.\n\n me", "tokenize_content": ["remove", "neil", "##n", "needs", "to", "extract", "his", "head", "from", "his", "butt", ".", "me"], "span": ["remove neil", "neiln", "##n needs", "needs to", "to extract", "extract his", "his head", "head from", "from his", "his butt", "butt.", ". me"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}
{"content": "If you think you are clever, you make a big mistake. Go to school, little stupid pig. Wikipedia is not for you, sucker.", "tokenize_content": ["if", "you", "think", "you", "are", "clever", ",", "you", "make", "a", "big", "mistake", ".", "go", "to", "school", ",", "little", "stupid", "pig", ".", "wikipedia", "is", "not", "for", "you", ",", "sucker", "."], "span": ["if you", "you think", "think you", "you are", "are clever", "clever,", ", you", "you make", "make a", "a big", "big mistake", "mistake.", ". go", "go to", "to school", "school,", ", little", "little stupid", "stupid pig", "pig.", ". wikipedia", "wikipedia is", "is not", "not for", "for you", "you,", ", sucker", "sucker."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "FU, you stupid british tea bagger. How the hell can Calzaghe and Otteke both have defense streaks in the same division at the same time. Because there both a joke thats how", "tokenize_content": ["fu", ",", "you", "stupid", "british", "tea", "bag", "##ger", ".", "how", "the", "hell", "can", "cal", "##za", "##gh", "##e", "and", "ot", "##tek", "##e", "both", "have", "defense", "streaks", "in", "the", "same", "division", "at", "the", "same", "time", ".", "because", "there", "both", "a", "joke", "that", "##s", "how"], "span": ["fu,", ", you", "you stupid", "stupid british", "british tea", "tea bag", "bagger", "##ger.", ". how", "how the", "the hell", "hell can", "can cal", "calza", "##zagh", "##ghe", "##e and", "and ot", "ottek", "##teke", "##e both", "both have", "have defense", "defense streaks", "streaks in", "in the", "the same", "same division", "division at", "at the", "the same", "same time", "time.", ". because", "because there", "there both", "both a", "a joke", "joke that", "thats", "##s how"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "WOULDN'T BE THE FIRST TIME BITCH. FUCK YOU I'LL FIND OUT WHERE YOU LIVE, SODOMIZE YOUR WIFE AND THEN BURN YOUR HOUSE DOWN. FUCK YOU YOU FUCKING QUEER.", "tokenize_content": ["wouldn", "'", "t", "be", "the", "first", "time", "bitch", ".", "fuck", "you", "i", "'", "ll", "find", "out", "where", "you", "live", ",", "so", "##dom", "##ize", "your", "wife", "and", "then", "burn", "your", "house", "down", ".", "fuck", "you", "you", "fucking", "queer", "."], "span": ["wouldn '", "' t", "t be", "be the", "the first", "first time", "time bitch", "bitch.", ". fuck", "fuck you", "you i", "i '", "' ll", "ll find", "find out", "out where", "where you", "you live", "live,", ", so", "sodom", "##domize", "##ize your", "your wife", "wife and", "and then", "then burn", "burn your", "your house", "house down", "down.", ". fuck", "fuck you", "you you", "you fucking", "fucking queer", "queer."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0]}
{"content": "^No it wasn't. Wtf.", "tokenize_content": ["^", "no", "it", "wasn", "'", "t", ".", "w", "##tf", "."], "span": ["^ no", "no it", "it wasn", "wasn '", "' t", "t.", ". w", "wtf", "##tf."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "2010 NBA Finals and Adam Morrison \n\nYou are annoying and ruining other people's fun please stop deleting all the edits on the 2 above pages, you are nothing but a buzzkill who is pissing other people off.", "tokenize_content": ["2010", "nba", "finals", "and", "adam", "morrison", "you", "are", "annoying", "and", "ruining", "other", "people", "'", "s", "fun", "please", "stop", "del", "##eti", "##ng", "all", "the", "edit", "##s", "on", "the", "2", "above", "pages", ",", "you", "are", "nothing", "but", "a", "buzz", "##kill", "who", "is", "piss", "##ing", "other", "people", "off", "."], "span": ["2010 nba", "nba finals", "finals and", "and adam", "adam morrison", "morrison you", "you are", "are annoying", "annoying and", "and ruining", "ruining other", "other people", "people '", "' s", "s fun", "fun please", "please stop", "stop del", "deleti", "##eting", "##ng all", "all the", "the edit", "edits", "##s on", "on the", "the 2", "2 above", "above pages", "pages,", ", you", "you are", "are nothing", "nothing but", "but a", "a buzz", "buzzkill", "##kill who", "who is", "is piss", "pissing", "##ing other", "other people", "people off", "off."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\nBullshit \"\"some medical\"\" is classic weasel word crap.  I demand mediation.\"", "tokenize_content": ["\"", "bullshit", "\"", "\"", "some", "medical", "\"", "\"", "is", "classic", "weasel", "word", "crap", ".", "i", "demand", "mediation", ".", "\""], "span": ["\" bullshit", "bullshit \"", "\" \"", "\" some", "some medical", "medical \"", "\" \"", "\" is", "is classic", "classic weasel", "weasel word", "word crap", "crap.", ". i", "i demand", "demand mediation", "mediation.", ". \""], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]}
{"content": "What in the fuck......will someone please revert this O.o", "tokenize_content": ["what", "in", "the", "fuck", ".", ".", ".", ".", ".", ".", "will", "someone", "please", "rev", "##ert", "this", "o", ".", "o"], "span": ["what in", "in the", "the fuck", "fuck.", "..", "..", "..", "..", "..", ". will", "will someone", "someone please", "please rev", "revert", "##ert this", "this o", "o.", ". o"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Mmmm... yes... a pint of palestinian blood would be a fine dessert right now. -  talk/email", "tokenize_content": ["mmm", "##m", ".", ".", ".", "yes", ".", ".", ".", "a", "pin", "##t", "of", "palestinian", "blood", "would", "be", "a", "fine", "dessert", "right", "now", ".", "-", "talk", "/", "email"], "span": ["mmmm", "##m.", "..", "..", ". yes", "yes.", "..", "..", ". a", "a pin", "pint", "##t of", "of palestinian", "palestinian blood", "blood would", "would be", "be a", "a fine", "fine dessert", "dessert right", "right now", "now.", ". -", "- talk", "talk /", "/ email"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Fucking cabal of donkey raping shit eaters I hope you all get cancer.", "tokenize_content": ["fucking", "cab", "##al", "of", "donkey", "rap", "##ing", "shit", "eater", "##s", "i", "hope", "you", "all", "get", "cancer", "."], "span": ["fucking cab", "cabal", "##al of", "of donkey", "donkey rap", "raping", "##ing shit", "shit eater", "eaters", "##s i", "i hope", "hope you", "you all", "all get", "get cancer", "cancer."], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0]}
{"content": "YOU F***** WHITE PROPAGANDA CHIEFS! GO AND DIE! DOWN WITH AMERICA!", "tokenize_content": ["you", "f", "*", "*", "*", "*", "*", "white", "propaganda", "chiefs", "!", "go", "and", "die", "!", "down", "with", "america", "!"], "span": ["you f", "f *", "* *", "* *", "* *", "* *", "* white", "white propaganda", "propaganda chiefs", "chiefs!", "! go", "go and", "and die", "die!", "! down", "down with", "with america", "america!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "You are absurd. You are defending a page of narendra Modi who is considered as a mass murderer. Why do'nt you go to Gujarat in India and talk to some people before titiling my edits as 'Vandalism'", "tokenize_content": ["you", "are", "absurd", ".", "you", "are", "defending", "a", "page", "of", "na", "##ren", "##dra", "mod", "##i", "who", "is", "considered", "as", "a", "mass", "murderer", ".", "why", "do", "'", "nt", "you", "go", "to", "gujarat", "in", "india", "and", "talk", "to", "some", "people", "before", "ti", "##ti", "##ling", "my", "edit", "##s", "as", "'", "van", "##dal", "##ism", "'"], "span": ["you are", "are absurd", "absurd.", ". you", "you are", "are defending", "defending a", "a page", "page of", "of na", "naren", "##rendra", "##dra mod", "modi", "##i who", "who is", "is considered", "considered as", "as a", "a mass", "mass murderer", "murderer.", ". why", "why do", "do '", "' nt", "nt you", "you go", "go to", "to gujarat", "gujarat in", "in india", "india and", "and talk", "talk to", "to some", "some people", "people before", "before ti", "titi", "##tiling", "##ling my", "my edit", "edits", "##s as", "as '", "' van", "vandal", "##dalism", "##ism '"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Have theguts \n\nHave the guts and improve the English of this article, instead of marking it for deletion.\nBe a mature one. Have the guts now. Otherwise,  quit off from this article.", "tokenize_content": ["have", "the", "##gut", "##s", "have", "the", "guts", "and", "improve", "the", "english", "of", "this", "article", ",", "instead", "of", "marking", "it", "for", "del", "##eti", "##on", ".", "be", "a", "mature", "one", ".", "have", "the", "guts", "now", ".", "otherwise", ",", "quit", "off", "from", "this", "article", "."], "span": ["have the", "thegut", "##guts", "##s have", "have the", "the guts", "guts and", "and improve", "improve the", "the english", "english of", "of this", "this article", "article,", ", instead", "instead of", "of marking", "marking it", "it for", "for del", "deleti", "##etion", "##on.", ". be", "be a", "a mature", "mature one", "one.", ". have", "have the", "the guts", "guts now", "now.", ". otherwise", "otherwise,", ", quit", "quit off", "off from", "from this", "this article", "article."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\n Yeah \n\nYou're right, he's a complete cock. Runs and tells his boyfriend whenever anyone questions the shitty job he does of \"\"creating\"\" pages.\"", "tokenize_content": ["\"", "yeah", "you", "'", "re", "right", ",", "he", "'", "s", "a", "complete", "cock", ".", "runs", "and", "tells", "his", "boyfriend", "whenever", "anyone", "questions", "the", "shitty", "job", "he", "does", "of", "\"", "\"", "creating", "\"", "\"", "pages", ".", "\""], "span": ["\" yeah", "yeah you", "you '", "' re", "re right", "right,", ", he", "he '", "' s", "s a", "a complete", "complete cock", "cock.", ". runs", "runs and", "and tells", "tells his", "his boyfriend", "boyfriend whenever", "whenever anyone", "anyone questions", "questions the", "the shitty", "shitty job", "job he", "he does", "does of", "of \"", "\" \"", "\" creating", "creating \"", "\" \"", "\" pages", "pages.", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I was attempting to continue editing the Vampires Suck article.", "tokenize_content": ["i", "was", "attempting", "to", "continue", "editing", "the", "vampires", "suck", "article", "."], "span": ["i was", "was attempting", "attempting to", "to continue", "continue editing", "editing the", "the vampires", "vampires suck", "suck article", "article."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "eat shit get rid of goofs you queers.", "tokenize_content": ["eat", "shit", "get", "rid", "of", "goo", "##fs", "you", "queer", "##s", "."], "span": ["eat shit", "shit get", "get rid", "rid of", "of goo", "goofs", "##fs you", "you queer", "queers", "##s."], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 1, 0, 0]}
{"content": "Stop being a hypocrite Seb\n\nYou're attacking me indirectly, take your own advice and stop edit warring and stop libeling. The one not keeping your cool is you. Cite your sources libeler.", "tokenize_content": ["stop", "being", "a", "h", "##yp", "##oc", "##rite", "se", "##b", "you", "'", "re", "attacking", "me", "indirectly", ",", "take", "your", "own", "advice", "and", "stop", "edit", "warring", "and", "stop", "libel", "##ing", ".", "the", "one", "not", "keeping", "your", "cool", "is", "you", ".", "cite", "your", "sources", "libel", "##er", "."], "span": ["stop being", "being a", "a h", "hyp", "##ypoc", "##ocrite", "##rite se", "seb", "##b you", "you '", "' re", "re attacking", "attacking me", "me indirectly", "indirectly,", ", take", "take your", "your own", "own advice", "advice and", "and stop", "stop edit", "edit warring", "warring and", "and stop", "stop libel", "libeling", "##ing.", ". the", "the one", "one not", "not keeping", "keeping your", "your cool", "cool is", "is you", "you.", ". cite", "cite your", "your sources", "sources libel", "libeler", "##er."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Fuck off, you half-wit\nYou wikiwankers set the standard for delusional.", "tokenize_content": ["fuck", "off", ",", "you", "half", "-", "wit", "you", "wi", "##ki", "##wan", "##kers", "set", "the", "standard", "for", "del", "##usion", "##al", "."], "span": ["fuck off", "off,", ", you", "you half", "half -", "- wit", "wit you", "you wi", "wiki", "##kiwan", "##wankers", "##kers set", "set the", "the standard", "standard for", "for del", "delusion", "##usional", "##al."], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"Lets block ALL the Jews ==\nWell, Well \"\"RADIANT\"\" Are you planning to block ALL of the Jews and Jew loving gentiles for calling nazis NAZIS! -\n\nShame on you.\n\n== \"", "tokenize_content": ["\"", "lets", "block", "all", "the", "jews", "=", "=", "well", ",", "well", "\"", "\"", "radiant", "\"", "\"", "are", "you", "planning", "to", "block", "all", "of", "the", "jews", "and", "jew", "loving", "gen", "##tile", "##s", "for", "calling", "nazis", "nazis", "!", "-", "shame", "on", "you", ".", "=", "=", "\""], "span": ["\" lets", "lets block", "block all", "all the", "the jews", "jews =", "= =", "= well", "well,", ", well", "well \"", "\" \"", "\" radiant", "radiant \"", "\" \"", "\" are", "are you", "you planning", "planning to", "to block", "block all", "all of", "of the", "the jews", "jews and", "and jew", "jew loving", "loving gen", "gentile", "##tiles", "##s for", "for calling", "calling nazis", "nazis nazis", "nazis!", "! -", "- shame", "shame on", "on you", "you.", ". =", "= =", "= \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "co/ck - pen-i.s. international", "tokenize_content": ["co", "/", "ck", "-", "pen", "-", "i", ".", "s", ".", "international"], "span": ["co /", "/ ck", "ck -", "- pen", "pen -", "- i", "i.", ". s", "s.", ". international"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "WAS HERE. HE POWNS NOOBS ALL DAY!", "tokenize_content": ["was", "here", ".", "he", "pow", "##ns", "no", "##ob", "##s", "all", "day", "!"], "span": ["was here", "here.", ". he", "he pow", "powns", "##ns no", "noob", "##obs", "##s all", "all day", "day!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Your work will be deleted or bastardized whether it adheres to the current rules or not, either because those rules will be changed, or through the sheer incompetence of those who come here merely to foul up other editors' contributions.", "tokenize_content": ["your", "work", "will", "be", "deleted", "or", "bastard", "##ized", "whether", "it", "adhere", "##s", "to", "the", "current", "rules", "or", "not", ",", "either", "because", "those", "rules", "will", "be", "changed", ",", "or", "through", "the", "sheer", "inc", "##omp", "##ete", "##nce", "of", "those", "who", "come", "here", "merely", "to", "foul", "up", "other", "editors", "'", "contributions", "."], "span": ["your work", "work will", "will be", "be deleted", "deleted or", "or bastard", "bastardized", "##ized whether", "whether it", "it adhere", "adheres", "##s to", "to the", "the current", "current rules", "rules or", "or not", "not,", ", either", "either because", "because those", "those rules", "rules will", "will be", "be changed", "changed,", ", or", "or through", "through the", "the sheer", "sheer inc", "incomp", "##ompete", "##etence", "##nce of", "of those", "those who", "who come", "come here", "here merely", "merely to", "to foul", "foul up", "up other", "other editors", "editors '", "' contributions", "contributions."], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "You are a fucking dick \n\ngo fuck yourself", "tokenize_content": ["you", "are", "a", "fucking", "dick", "go", "fuck", "yourself"], "span": ["you are", "are a", "a fucking", "fucking dick", "dick go", "go fuck", "fuck yourself"], "toxic": 1, "score": [0, 0, 1, 1, 1, 1, 1]}
{"content": "Go for it, dipshit.  You're just another islamo/christian terroist.  Fuck off already!  get the fuck out of my coutnry!  Move to fucking Pakistian!", "tokenize_content": ["go", "for", "it", ",", "dip", "##shi", "##t", ".", "you", "'", "re", "just", "another", "islam", "##o", "/", "christian", "ter", "##roi", "##st", ".", "fuck", "off", "already", "!", "get", "the", "fuck", "out", "of", "my", "co", "##ut", "##nr", "##y", "!", "move", "to", "fucking", "pak", "##ist", "##ian", "!"], "span": ["go for", "for it", "it,", ", dip", "dipshi", "##shit", "##t.", ". you", "you '", "' re", "re just", "just another", "another islam", "islamo", "##o /", "/ christian", "christian ter", "terroi", "##roist", "##st.", ". fuck", "fuck off", "off already", "already!", "! get", "get the", "the fuck", "fuck out", "out of", "of my", "my co", "cout", "##utnr", "##nry", "##y!", "! move", "move to", "to fucking", "fucking pak", "pakist", "##istian", "##ian!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]}
{"content": "Fuck off you idiot 82.103.128.115", "tokenize_content": ["fuck", "off", "you", "idiot", "82", ".", "103", ".", "128", ".", "115"], "span": ["fuck off", "off you", "you idiot", "idiot 82", "82.", ". 103", "103.", ". 128", "128.", ". 115"], "toxic": 1, "score": [1, 0, 1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "Please...do you have to waste your time to stupid messages like this one? I can switch to IP from another country in one minute. 177.47.116.74", "tokenize_content": ["please", ".", ".", ".", "do", "you", "have", "to", "waste", "your", "time", "to", "stupid", "messages", "like", "this", "one", "?", "i", "can", "switch", "to", "ip", "from", "another", "country", "in", "one", "minute", ".", "177", ".", "47", ".", "116", ".", "74"], "span": ["please.", "..", "..", ". do", "do you", "you have", "have to", "to waste", "waste your", "your time", "time to", "to stupid", "stupid messages", "messages like", "like this", "this one", "one?", "? i", "i can", "can switch", "switch to", "to ip", "ip from", "from another", "another country", "country in", "in one", "one minute", "minute.", ". 177", "177.", ". 47", "47.", ". 116", "116.", ". 74"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Butt face idiot friends", "tokenize_content": ["butt", "face", "idiot", "friends"], "span": ["butt face", "face idiot", "idiot friends"], "toxic": 1, "score": [1, 1, 1]}
{"content": "racist ==\nyou are a western racist who edits out all adverse references to western governments and organizations.  if your actions continue, by documenting and publicly exposing your racism here and around the net, you will be made an cautionary example. \n\n==", "tokenize_content": ["racist", "=", "=", "you", "are", "a", "western", "racist", "who", "edit", "##s", "out", "all", "adverse", "references", "to", "western", "governments", "and", "organizations", ".", "if", "your", "actions", "continue", ",", "by", "documenting", "and", "publicly", "exposing", "your", "racism", "here", "and", "around", "the", "net", ",", "you", "will", "be", "made", "an", "caution", "##ary", "example", ".", "=", "="], "span": ["racist =", "= =", "= you", "you are", "are a", "a western", "western racist", "racist who", "who edit", "edits", "##s out", "out all", "all adverse", "adverse references", "references to", "to western", "western governments", "governments and", "and organizations", "organizations.", ". if", "if your", "your actions", "actions continue", "continue,", ", by", "by documenting", "documenting and", "and publicly", "publicly exposing", "exposing your", "your racism", "racism here", "here and", "and around", "around the", "the net", "net,", ", you", "you will", "will be", "be made", "made an", "an caution", "cautionary", "##ary example", "example.", ". =", "= ="], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "And your a PRICK TO EMPOWER ASSHOLES LIKE PROPOL", "tokenize_content": ["and", "your", "a", "prick", "to", "em", "##power", "asshole", "##s", "like", "prop", "##ol"], "span": ["and your", "your a", "a prick", "prick to", "to em", "empower", "##power asshole", "assholes", "##s like", "like prop", "propol"], "toxic": 1, "score": [0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0]}
{"content": "ONLY A NEONAZI QUACK WOULD INSIST ON AN ARYAN-TAINTED VIEW OF PIE AS A SINGLE LANGUAGE WITH A SINGLE PEOPLE. Romantic notion but obviously not science. 50.72.139.25", "tokenize_content": ["only", "a", "neon", "##azi", "qu", "##ack", "would", "insist", "on", "an", "aryan", "-", "tainted", "view", "of", "pie", "as", "a", "single", "language", "with", "a", "single", "people", ".", "romantic", "notion", "but", "obviously", "not", "science", ".", "50", ".", "72", ".", "139", ".", "25"], "span": ["only a", "a neon", "neonazi", "##azi qu", "quack", "##ack would", "would insist", "insist on", "on an", "an aryan", "aryan -", "- tainted", "tainted view", "view of", "of pie", "pie as", "as a", "a single", "single language", "language with", "with a", "a single", "single people", "people.", ". romantic", "romantic notion", "notion but", "but obviously", "obviously not", "not science", "science.", ". 50", "50.", ". 72", "72.", ". 139", "139.", ". 25"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Blow it out your ass, . And as for you , why are you always defending that punk ? I know that you nominated him for RfA, so you are either an ignorant fool, or his homosexual boyfriend! FUCK YOU!", "tokenize_content": ["blow", "it", "out", "your", "ass", ",", ".", "and", "as", "for", "you", ",", "why", "are", "you", "always", "defending", "that", "punk", "?", "i", "know", "that", "you", "nominated", "him", "for", "rf", "##a", ",", "so", "you", "are", "either", "an", "ignorant", "fool", ",", "or", "his", "homosexual", "boyfriend", "!", "fuck", "you", "!"], "span": ["blow it", "it out", "out your", "your ass", "ass,", ",.", ". and", "and as", "as for", "for you", "you,", ", why", "why are", "are you", "you always", "always defending", "defending that", "that punk", "punk?", "? i", "i know", "know that", "that you", "you nominated", "nominated him", "him for", "for rf", "rfa", "##a,", ", so", "so you", "you are", "are either", "either an", "an ignorant", "ignorant fool", "fool,", ", or", "or his", "his homosexual", "homosexual boyfriend", "boyfriend!", "! fuck", "fuck you", "you!"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0]}
{"content": "It is not redundant. You are redundant.", "tokenize_content": ["it", "is", "not", "redundant", ".", "you", "are", "redundant", "."], "span": ["it is", "is not", "not redundant", "redundant.", ". you", "you are", "are redundant", "redundant."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "fuck you \n\ni hate you why do you delete pages do you have a life are you gay if you make the page marring manz you hall be cool however at the moment you are gay", "tokenize_content": ["fuck", "you", "i", "hate", "you", "why", "do", "you", "del", "##ete", "pages", "do", "you", "have", "a", "life", "are", "you", "gay", "if", "you", "make", "the", "page", "mar", "##ring", "man", "##z", "you", "hall", "be", "cool", "however", "at", "the", "moment", "you", "are", "gay"], "span": ["fuck you", "you i", "i hate", "hate you", "you why", "why do", "do you", "you del", "delete", "##ete pages", "pages do", "do you", "you have", "have a", "a life", "life are", "are you", "you gay", "gay if", "if you", "you make", "make the", "the page", "page mar", "marring", "##ring man", "manz", "##z you", "you hall", "hall be", "be cool", "cool however", "however at", "at the", "the moment", "moment you", "you are", "are gay"], "toxic": 1, "score": [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "Hello, you Indian cannibal and child molester \n\nThe vandal doesn't care about D&D; articles, he vandalizes because he doesn't like being libeled and harassed", "tokenize_content": ["hello", ",", "you", "indian", "can", "##ni", "##bal", "and", "child", "mole", "##ster", "the", "van", "##dal", "doesn", "'", "t", "care", "about", "d", "&", "d", ";", "articles", ",", "he", "van", "##dal", "##izes", "because", "he", "doesn", "'", "t", "like", "being", "libel", "##ed", "and", "harassed"], "span": ["hello,", ", you", "you indian", "indian can", "canni", "##nibal", "##bal and", "and child", "child mole", "molester", "##ster the", "the van", "vandal", "##dal doesn", "doesn '", "' t", "t care", "care about", "about d", "d &", "& d", "d ;", "; articles", "articles,", ", he", "he van", "vandal", "##dalizes", "##izes because", "because he", "he doesn", "doesn '", "' t", "t like", "like being", "being libel", "libeled", "##ed and", "and harassed"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "do so sexually with me", "tokenize_content": ["do", "so", "sexually", "with", "me"], "span": ["do so", "so sexually", "sexually with", "with me"], "toxic": 1, "score": [0, 0, 0, 0]}
{"content": "Calling you a dildo is not vandalism (seriously, go look it up.  Ask an administrator if you don't believe me.)  I am humorous, you're just ignorant. FRACTIONS (t | c)", "tokenize_content": ["calling", "you", "a", "dil", "##do", "is", "not", "van", "##dal", "##ism", "(", "seriously", ",", "go", "look", "it", "up", ".", "ask", "an", "administrator", "if", "you", "don", "'", "t", "believe", "me", ".", ")", "i", "am", "humorous", ",", "you", "'", "re", "just", "ignorant", ".", "fraction", "##s", "(", "t", "|", "c", ")"], "span": ["calling you", "you a", "a dil", "dildo", "##do is", "is not", "not van", "vandal", "##dalism", "##ism (", "( seriously", "seriously,", ", go", "go look", "look it", "it up", "up.", ". ask", "ask an", "an administrator", "administrator if", "if you", "you don", "don '", "' t", "t believe", "believe me", "me.", ". )", ") i", "i am", "am humorous", "humorous,", ", you", "you '", "' re", "re just", "just ignorant", "ignorant.", ". fraction", "fractions", "##s (", "( t", "t |", "| c", "c )"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Anti American \nYou are an Anti American who hates Americans / USA. Is that not wrong? If you're trying to get a point across by using Wikipedia, anti Americanism won't help.", "tokenize_content": ["anti", "american", "you", "are", "an", "anti", "american", "who", "hates", "americans", "/", "usa", ".", "is", "that", "not", "wrong", "?", "if", "you", "'", "re", "trying", "to", "get", "a", "point", "across", "by", "using", "wikipedia", ",", "anti", "american", "##ism", "won", "'", "t", "help", "."], "span": ["anti american", "american you", "you are", "are an", "an anti", "anti american", "american who", "who hates", "hates americans", "americans /", "/ usa", "usa.", ". is", "is that", "that not", "not wrong", "wrong?", "? if", "if you", "you '", "' re", "re trying", "trying to", "to get", "get a", "a point", "point across", "across by", "by using", "using wikipedia", "wikipedia,", ", anti", "anti american", "americanism", "##ism won", "won '", "' t", "t help", "help."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\n Tan \"\"Wikipedia's workers or whatever\"\" \n\nTan go to hell or just grow some balls for once. Or get a girlfriend rather than spending your life on wikipedia\"", "tokenize_content": ["\"", "tan", "\"", "\"", "wikipedia", "'", "s", "workers", "or", "whatever", "\"", "\"", "tan", "go", "to", "hell", "or", "just", "grow", "some", "balls", "for", "once", ".", "or", "get", "a", "girlfriend", "rather", "than", "spending", "your", "life", "on", "wikipedia", "\""], "span": ["\" tan", "tan \"", "\" \"", "\" wikipedia", "wikipedia '", "' s", "s workers", "workers or", "or whatever", "whatever \"", "\" \"", "\" tan", "tan go", "go to", "to hell", "hell or", "or just", "just grow", "grow some", "some balls", "balls for", "for once", "once.", ". or", "or get", "get a", "a girlfriend", "girlfriend rather", "rather than", "than spending", "spending your", "your life", "life on", "on wikipedia", "wikipedia \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Fattyjwoods \n\nFattyjwoods is a douche\n\nI can't believe he would like a gay team like the Yankees, well I guess you got to be one to like one.\n\np.s. \n\nFUCK GEORGE W. BUSH!", "tokenize_content": ["fatty", "##j", "##woods", "fatty", "##j", "##woods", "is", "a", "do", "##uche", "i", "can", "'", "t", "believe", "he", "would", "like", "a", "gay", "team", "like", "the", "yankees", ",", "well", "i", "guess", "you", "got", "to", "be", "one", "to", "like", "one", ".", "p", ".", "s", ".", "fuck", "george", "w", ".", "bush", "!"], "span": ["fattyj", "##jwoods", "##woods fatty", "fattyj", "##jwoods", "##woods is", "is a", "a do", "douche", "##uche i", "i can", "can '", "' t", "t believe", "believe he", "he would", "would like", "like a", "a gay", "gay team", "team like", "like the", "the yankees", "yankees,", ", well", "well i", "i guess", "guess you", "you got", "got to", "to be", "be one", "one to", "to like", "like one", "one.", ". p", "p.", ". s", "s.", ". fuck", "fuck george", "george w", "w.", ". bush", "bush!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "Wait, you are female and black..! That's disconcerting...", "tokenize_content": ["wait", ",", "you", "are", "female", "and", "black", ".", ".", "!", "that", "'", "s", "disco", "##nce", "##rting", ".", ".", "."], "span": ["wait,", ", you", "you are", "are female", "female and", "and black", "black.", "..", ".!", "! that", "that '", "' s", "s disco", "disconce", "##ncerting", "##rting.", "..", ".."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Wtf. I haven't even edited anything within the past day, after the others told me to stop!220.245.146.235", "tokenize_content": ["w", "##tf", ".", "i", "haven", "'", "t", "even", "edited", "anything", "within", "the", "past", "day", ",", "after", "the", "others", "told", "me", "to", "stop", "!", "220", ".", "245", ".", "146", ".", "235"], "span": ["wtf", "##tf.", ". i", "i haven", "haven '", "' t", "t even", "even edited", "edited anything", "anything within", "within the", "the past", "past day", "day,", ", after", "after the", "the others", "others told", "told me", "me to", "to stop", "stop!", "! 220", "220.", ". 245", "245.", ". 146", "146.", ". 235"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Haha I've posted all your failed attempts on www.sourmath.com. I own that website, especially for fools like you.", "tokenize_content": ["ha", "##ha", "i", "'", "ve", "posted", "all", "your", "failed", "attempts", "on", "www", ".", "sour", "##mat", "##h", ".", "com", ".", "i", "own", "that", "website", ",", "especially", "for", "fools", "like", "you", "."], "span": ["haha", "##ha i", "i '", "' ve", "ve posted", "posted all", "all your", "your failed", "failed attempts", "attempts on", "on www", "www.", ". sour", "sourmat", "##math", "##h.", ". com", "com.", ". i", "i own", "own that", "that website", "website,", ", especially", "especially for", "for fools", "fools like", "like you", "you."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "please , fuck jobas with me", "tokenize_content": ["please", ",", "fuck", "job", "##as", "with", "me"], "span": ["please,", ", fuck", "fuck job", "jobas", "##as with", "with me"], "toxic": 1, "score": [0, 1, 1, 0, 0, 0]}
{"content": "Yeah its me \n\nYou're telling me not to write offensive stuff, but you'be gotten blocked yourself? ROFL, hypocrite practice what you preach!", "tokenize_content": ["yeah", "its", "me", "you", "'", "re", "telling", "me", "not", "to", "write", "offensive", "stuff", ",", "but", "you", "'", "be", "gotten", "blocked", "yourself", "?", "ro", "##fl", ",", "h", "##yp", "##oc", "##rite", "practice", "what", "you", "preach", "!"], "span": ["yeah its", "its me", "me you", "you '", "' re", "re telling", "telling me", "me not", "not to", "to write", "write offensive", "offensive stuff", "stuff,", ", but", "but you", "you '", "' be", "be gotten", "gotten blocked", "blocked yourself", "yourself?", "? ro", "rofl", "##fl,", ", h", "hyp", "##ypoc", "##ocrite", "##rite practice", "practice what", "what you", "you preach", "preach!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "never touch my edits again you douche bag", "tokenize_content": ["never", "touch", "my", "edit", "##s", "again", "you", "do", "##uche", "bag"], "span": ["never touch", "touch my", "my edit", "edits", "##s again", "again you", "you do", "douche", "##uche bag"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "and your little faggot boy Propol, pray, pray little wonk that I don't find your little ass and kill you", "tokenize_content": ["and", "your", "little", "fa", "##gg", "##ot", "boy", "prop", "##ol", ",", "pray", ",", "pray", "little", "won", "##k", "that", "i", "don", "'", "t", "find", "your", "little", "ass", "and", "kill", "you"], "span": ["and your", "your little", "little fa", "fagg", "##ggot", "##ot boy", "boy prop", "propol", "##ol,", ", pray", "pray,", ", pray", "pray little", "little won", "wonk", "##k that", "that i", "i don", "don '", "' t", "t find", "find your", "your little", "little ass", "ass and", "and kill", "kill you"], "toxic": 1, "score": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]}
{"content": "\"\nIt wasn't enough, no, because they were deported and not executed.  \"\"My human brothers\"\"?  Ha ha ha.  How many wedgies did you get in high school?!  Fucking Frenchies.  What losers.   \"", "tokenize_content": ["\"", "it", "wasn", "'", "t", "enough", ",", "no", ",", "because", "they", "were", "deported", "and", "not", "executed", ".", "\"", "\"", "my", "human", "brothers", "\"", "\"", "?", "ha", "ha", "ha", ".", "how", "many", "wed", "##gies", "did", "you", "get", "in", "high", "school", "?", "!", "fucking", "french", "##ies", ".", "what", "losers", ".", "\""], "span": ["\" it", "it wasn", "wasn '", "' t", "t enough", "enough,", ", no", "no,", ", because", "because they", "they were", "were deported", "deported and", "and not", "not executed", "executed.", ". \"", "\" \"", "\" my", "my human", "human brothers", "brothers \"", "\" \"", "\"?", "? ha", "ha ha", "ha ha", "ha.", ". how", "how many", "many wed", "wedgies", "##gies did", "did you", "you get", "get in", "in high", "high school", "school?", "?!", "! fucking", "fucking french", "frenchies", "##ies.", ". what", "what losers", "losers.", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0]}
{"content": "im sorry but you need to just leave wikipedia alone john cd coz i curse u dat u die in 10 mins", "tokenize_content": ["im", "sorry", "but", "you", "need", "to", "just", "leave", "wikipedia", "alone", "john", "cd", "co", "##z", "i", "curse", "u", "dat", "u", "die", "in", "10", "min", "##s"], "span": ["im sorry", "sorry but", "but you", "you need", "need to", "to just", "just leave", "leave wikipedia", "wikipedia alone", "alone john", "john cd", "cd co", "coz", "##z i", "i curse", "curse u", "u dat", "dat u", "u die", "die in", "in 10", "10 min", "mins"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]}
{"content": "== fuck you \nI hope you die motherfucker", "tokenize_content": ["=", "=", "fuck", "you", "i", "hope", "you", "die", "mother", "##fu", "##cker"], "span": ["= =", "= fuck", "fuck you", "you i", "i hope", "hope you", "you die", "die mother", "motherfu", "##fucker"], "toxic": 1, "score": [0, 1, 1, 0, 0, 0, 1, 0, 0, 1]}
{"content": "I'm citing your mother.", "tokenize_content": ["i", "'", "m", "citing", "your", "mother", "."], "span": ["i '", "' m", "m citing", "citing your", "your mother", "mother."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0]}
{"content": "Calling a dickhead a dickhead is not a personal attack. Sorry, but if he fucks with my edits again, I will call him a dickhead again!", "tokenize_content": ["calling", "a", "dick", "##head", "a", "dick", "##head", "is", "not", "a", "personal", "attack", ".", "sorry", ",", "but", "if", "he", "fuck", "##s", "with", "my", "edit", "##s", "again", ",", "i", "will", "call", "him", "a", "dick", "##head", "again", "!"], "span": ["calling a", "a dick", "dickhead", "##head a", "a dick", "dickhead", "##head is", "is not", "not a", "a personal", "personal attack", "attack.", ". sorry", "sorry,", ", but", "but if", "if he", "he fuck", "fucks", "##s with", "with my", "my edit", "edits", "##s again", "again,", ", i", "i will", "will call", "call him", "him a", "a dick", "dickhead", "##head again", "again!"], "toxic": 1, "score": [0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "\\\n\nI agree!! I think that she is probably a forty year old star trek nerd man who lives in his mom's basement playing nintendo!", "tokenize_content": ["\\", "i", "agree", "!", "!", "i", "think", "that", "she", "is", "probably", "a", "forty", "year", "old", "star", "trek", "ne", "##rd", "man", "who", "lives", "in", "his", "mom", "'", "s", "basement", "playing", "nintendo", "!"], "span": ["\\ i", "i agree", "agree!", "!!", "! i", "i think", "think that", "that she", "she is", "is probably", "probably a", "a forty", "forty year", "year old", "old star", "star trek", "trek ne", "nerd", "##rd man", "man who", "who lives", "lives in", "in his", "his mom", "mom '", "' s", "s basement", "basement playing", "playing nintendo", "nintendo!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "u wanna suck me off do it thats useful", "tokenize_content": ["u", "wanna", "suck", "me", "off", "do", "it", "that", "##s", "useful"], "span": ["u wanna", "wanna suck", "suck me", "me off", "off do", "do it", "it that", "thats", "##s useful"], "toxic": 1, "score": [0, 1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "America is so much richer with these niggers around. What would we ever do without them? 96.48.13.234", "tokenize_content": ["america", "is", "so", "much", "richer", "with", "these", "ni", "##gger", "##s", "around", ".", "what", "would", "we", "ever", "do", "without", "them", "?", "96", ".", "48", ".", "13", ".", "234"], "span": ["america is", "is so", "so much", "much richer", "richer with", "with these", "these ni", "nigger", "##ggers", "##s around", "around.", ". what", "what would", "would we", "we ever", "ever do", "do without", "without them", "them?", "? 96", "96.", ". 48", "48.", ". 13", "13.", ". 234"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Hey bitch! guess what \n\nKoschecks fighting at ufc 82... you know waht that means...so give your adress so i could make u suck my cock", "tokenize_content": ["hey", "bitch", "!", "guess", "what", "ko", "##sche", "##cks", "fighting", "at", "ufc", "82", ".", ".", ".", "you", "know", "wah", "##t", "that", "means", ".", ".", ".", "so", "give", "your", "ad", "##ress", "so", "i", "could", "make", "u", "suck", "my", "cock"], "span": ["hey bitch", "bitch!", "! guess", "guess what", "what ko", "kosche", "##schecks", "##cks fighting", "fighting at", "at ufc", "ufc 82", "82.", "..", "..", ". you", "you know", "know wah", "waht", "##t that", "that means", "means.", "..", "..", ". so", "so give", "give your", "your ad", "adress", "##ress so", "so i", "i could", "could make", "make u", "u suck", "suck my", "my cock"], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]}
{"content": "IS A FASCIST BULLY CONSTANTLY ATTEMPTING TO FORCE HIS WILL ON OTHERS\n\nFUCKING RACIST FAGGOT", "tokenize_content": ["is", "a", "fascist", "bully", "constantly", "attempting", "to", "force", "his", "will", "on", "others", "fucking", "racist", "fa", "##gg", "##ot"], "span": ["is a", "a fascist", "fascist bully", "bully constantly", "constantly attempting", "attempting to", "to force", "force his", "his will", "will on", "on others", "others fucking", "fucking racist", "racist fa", "fagg", "##ggot"], "toxic": 1, "score": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0]}
{"content": "because I am a huge asshole", "tokenize_content": ["because", "i", "am", "a", "huge", "asshole"], "span": ["because i", "i am", "am a", "a huge", "huge asshole"], "toxic": 1, "score": [0, 0, 0, 0, 1]}
{"content": ". J Delanoys house is going to be fire bombed!!", "tokenize_content": [".", "j", "del", "##ano", "##ys", "house", "is", "going", "to", "be", "fire", "bombed", "!", "!"], "span": [". j", "j del", "delano", "##anoys", "##ys house", "house is", "is going", "going to", "to be", "be fire", "fire bombed", "bombed!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "i will ki \n\nll you and wear your skin like a robe!", "tokenize_content": ["i", "will", "ki", "ll", "you", "and", "wear", "your", "skin", "like", "a", "robe", "!"], "span": ["i will", "will ki", "ki ll", "ll you", "you and", "and wear", "wear your", "your skin", "skin like", "like a", "a robe", "robe!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Chuckle Chuckle \n\nI think that I am going to sue you for being mean to me. I'll get my llawer, and you can get yours! lets see who wins in that fight. Ha!\n\nLove Ya - xxxx", "tokenize_content": ["chuckle", "chuckle", "i", "think", "that", "i", "am", "going", "to", "sue", "you", "for", "being", "mean", "to", "me", ".", "i", "'", "ll", "get", "my", "ll", "##aw", "##er", ",", "and", "you", "can", "get", "yours", "!", "lets", "see", "who", "wins", "in", "that", "fight", ".", "ha", "!", "love", "ya", "-", "xx", "##xx"], "span": ["chuckle chuckle", "chuckle i", "i think", "think that", "that i", "i am", "am going", "going to", "to sue", "sue you", "you for", "for being", "being mean", "mean to", "to me", "me.", ". i", "i '", "' ll", "ll get", "get my", "my ll", "llaw", "##awer", "##er,", ", and", "and you", "you can", "can get", "get yours", "yours!", "! lets", "lets see", "see who", "who wins", "wins in", "in that", "that fight", "fight.", ". ha", "ha!", "! love", "love ya", "ya -", "- xx", "xxxx"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "No one here has alleged you're a wimp.  It's quite obvious you are attempting to behave like a thug.", "tokenize_content": ["no", "one", "here", "has", "alleged", "you", "'", "re", "a", "wi", "##mp", ".", "it", "'", "s", "quite", "obvious", "you", "are", "attempting", "to", "behave", "like", "a", "thug", "."], "span": ["no one", "one here", "here has", "has alleged", "alleged you", "you '", "' re", "re a", "a wi", "wimp", "##mp.", ". it", "it '", "' s", "s quite", "quite obvious", "obvious you", "you are", "are attempting", "attempting to", "to behave", "behave like", "like a", "a thug", "thug."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "why are you a stubborn prissy little girl \n\nYou keep undoing that thing", "tokenize_content": ["why", "are", "you", "a", "stubborn", "pri", "##ss", "##y", "little", "girl", "you", "keep", "undo", "##ing", "that", "thing"], "span": ["why are", "are you", "you a", "a stubborn", "stubborn pri", "priss", "##ssy", "##y little", "little girl", "girl you", "you keep", "keep undo", "undoing", "##ing that", "that thing"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "the guy was such a big demon for Sikh..", "tokenize_content": ["the", "guy", "was", "such", "a", "big", "demon", "for", "sikh", ".", "."], "span": ["the guy", "guy was", "was such", "such a", "a big", "big demon", "demon for", "for sikh", "sikh.", ".."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "No \n\nSuck my cock, asshole, I will never stop.", "tokenize_content": ["no", "suck", "my", "cock", ",", "asshole", ",", "i", "will", "never", "stop", "."], "span": ["no suck", "suck my", "my cock", "cock,", ", asshole", "asshole,", ", i", "i will", "will never", "never stop", "stop."], "toxic": 1, "score": [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]}
{"content": "WHY THE FUCK DO U EDIT MY CONTRIB. TO WIKI ABOUT THE IRANIAN ARMY? THEY MUST DIE U KNOW!! STUPID TERRORISTS...THEY'RE LIVING ON ISRAELI SOIL CALLED ASIA-AFRICA WHICH SHOULD BE FOR ISRAELIS ONLY AND MUSLIM FREE", "tokenize_content": ["why", "the", "fuck", "do", "u", "edit", "my", "con", "##tri", "##b", ".", "to", "wi", "##ki", "about", "the", "iranian", "army", "?", "they", "must", "die", "u", "know", "!", "!", "stupid", "terrorists", ".", ".", ".", "they", "'", "re", "living", "on", "israeli", "soil", "called", "asia", "-", "africa", "which", "should", "be", "for", "israelis", "only", "and", "muslim", "free"], "span": ["why the", "the fuck", "fuck do", "do u", "u edit", "edit my", "my con", "contri", "##trib", "##b.", ". to", "to wi", "wiki", "##ki about", "about the", "the iranian", "iranian army", "army?", "? they", "they must", "must die", "die u", "u know", "know!", "!!", "! stupid", "stupid terrorists", "terrorists.", "..", "..", ". they", "they '", "' re", "re living", "living on", "on israeli", "israeli soil", "soil called", "called asia", "asia -", "- africa", "africa which", "which should", "should be", "be for", "for israelis", "israelis only", "only and", "and muslim", "muslim free"], "toxic": 1, "score": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "User:LessHeard VanU ==\nWhat is your problem? Why did you block me without a warning? I believe Administrative Abuse is prohibited. I don't even know you. Go get some mental help.\n\n==", "tokenize_content": ["user", ":", "less", "##heard", "van", "##u", "=", "=", "what", "is", "your", "problem", "?", "why", "did", "you", "block", "me", "without", "a", "warning", "?", "i", "believe", "administrative", "abuse", "is", "prohibited", ".", "i", "don", "'", "t", "even", "know", "you", ".", "go", "get", "some", "mental", "help", ".", "=", "="], "span": ["user :", ": less", "lessheard", "##heard van", "vanu", "##u =", "= =", "= what", "what is", "is your", "your problem", "problem?", "? why", "why did", "did you", "you block", "block me", "me without", "without a", "a warning", "warning?", "? i", "i believe", "believe administrative", "administrative abuse", "abuse is", "is prohibited", "prohibited.", ". i", "i don", "don '", "' t", "t even", "even know", "know you", "you.", ". go", "go get", "get some", "some mental", "mental help", "help.", ". =", "= ="], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "STOP CALLING ME THAT NAME YOU PATHETIC EXUSE FOR A TRICERATOPS, WHY IN AFRICA OF RHINOCEROSES DO YOU THINK BRR IS ME. User:Puncharoo Read my page first", "tokenize_content": ["stop", "calling", "me", "that", "name", "you", "pathetic", "ex", "##use", "for", "a", "tri", "##cera", "##tops", ",", "why", "in", "africa", "of", "rhino", "##cer", "##oses", "do", "you", "think", "br", "##r", "is", "me", ".", "user", ":", "punch", "##aro", "##o", "read", "my", "page", "first"], "span": ["stop calling", "calling me", "me that", "that name", "name you", "you pathetic", "pathetic ex", "exuse", "##use for", "for a", "a tri", "tricera", "##ceratops", "##tops,", ", why", "why in", "in africa", "africa of", "of rhino", "rhinocer", "##ceroses", "##oses do", "do you", "you think", "think br", "brr", "##r is", "is me", "me.", ". user", "user :", ": punch", "puncharo", "##aroo", "##o read", "read my", "my page", "page first"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Piss off you old timer - go fuck yourself you evil asshole.", "tokenize_content": ["piss", "off", "you", "old", "timer", "-", "go", "fuck", "yourself", "you", "evil", "asshole", "."], "span": ["piss off", "off you", "you old", "old timer", "timer -", "- go", "go fuck", "fuck yourself", "yourself you", "you evil", "evil asshole", "asshole."], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1]}
{"content": "Im not doing this GODDAMN!", "tokenize_content": ["im", "not", "doing", "this", "goddamn", "!"], "span": ["im not", "not doing", "doing this", "this goddamn", "goddamn!"], "toxic": 1, "score": [0, 0, 0, 1, 1]}
{"content": "Colossal Penis                                                                                                          Superscript textSuperscript textSuperscript textSuperscript textStrike-through text#REDIRECT [[#REDIRECT Insert text\n\n82.40.14.172  ]]Penis", "tokenize_content": ["colossal", "penis", "super", "##script", "texts", "##up", "##ers", "##cript", "texts", "##up", "##ers", "##cript", "texts", "##up", "##ers", "##cript", "texts", "##tri", "##ke", "-", "through", "text", "#", "red", "##ire", "##ct", "[", "[", "#", "red", "##ire", "##ct", "insert", "text", "82", ".", "40", ".", "14", ".", "172", "]", "]", "penis"], "span": ["colossal penis", "penis super", "superscript", "##script texts", "textsup", "##upers", "##erscript", "##cript texts", "textsup", "##upers", "##erscript", "##cript texts", "textsup", "##upers", "##erscript", "##cript texts", "textstri", "##trike", "##ke -", "- through", "through text", "text #", "# red", "redire", "##irect", "##ct [", "[ [", "[ #", "# red", "redire", "##irect", "##ct insert", "insert text", "text 82", "82.", ". 40", "40.", ". 14", "14.", ". 172", "172 ]", "] ]", "] penis"], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "Cool.  Do I give a fuck?  Enjoy the rest of your life being an anal-retentive moderator on Wikipedia buddy.", "tokenize_content": ["cool", ".", "do", "i", "give", "a", "fuck", "?", "enjoy", "the", "rest", "of", "your", "life", "being", "an", "anal", "-", "re", "##ten", "##tive", "moderator", "on", "wikipedia", "buddy", "."], "span": ["cool.", ". do", "do i", "i give", "give a", "a fuck", "fuck?", "? enjoy", "enjoy the", "the rest", "rest of", "of your", "your life", "life being", "being an", "an anal", "anal -", "- re", "reten", "##tentive", "##tive moderator", "moderator on", "on wikipedia", "wikipedia buddy", "buddy."], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "o why dont u get off my mothafuckin dick son, u think i dont kno my shit nigga?", "tokenize_content": ["o", "why", "don", "##t", "u", "get", "off", "my", "moth", "##af", "##uck", "##in", "dick", "son", ",", "u", "think", "i", "don", "##t", "kn", "##o", "my", "shit", "ni", "##gga", "?"], "span": ["o why", "why don", "dont", "##t u", "u get", "get off", "off my", "my moth", "mothaf", "##afuck", "##uckin", "##in dick", "dick son", "son,", ", u", "u think", "think i", "i don", "dont", "##t kn", "kno", "##o my", "my shit", "shit ni", "nigga", "##gga?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]}
{"content": "Crap, this article sucks.  I tried reading it, but it was just one long paragraph, most likely stolen from somewhere.  Not good.", "tokenize_content": ["crap", ",", "this", "article", "sucks", ".", "i", "tried", "reading", "it", ",", "but", "it", "was", "just", "one", "long", "paragraph", ",", "most", "likely", "stolen", "from", "somewhere", ".", "not", "good", "."], "span": ["crap,", ", this", "this article", "article sucks", "sucks.", ". i", "i tried", "tried reading", "reading it", "it,", ", but", "but it", "it was", "was just", "just one", "one long", "long paragraph", "paragraph,", ", most", "most likely", "likely stolen", "stolen from", "from somewhere", "somewhere.", ". not", "not good", "good."], "toxic": 1, "score": [1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Huh? \n\nDon't threaten me asshole.  What content did I blank or remove?  I added content.", "tokenize_content": ["huh", "?", "don", "'", "t", "threaten", "me", "asshole", ".", "what", "content", "did", "i", "blank", "or", "remove", "?", "i", "added", "content", "."], "span": ["huh?", "? don", "don '", "' t", "t threaten", "threaten me", "me asshole", "asshole.", ". what", "what content", "content did", "did i", "i blank", "blank or", "or remove", "remove?", "? i", "i added", "added content", "content."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "read what I say and understand my meaning - if you continue to harass me, it is your ass that is grass - I've violated no policies - you have. LEAVE ME BE.", "tokenize_content": ["read", "what", "i", "say", "and", "understand", "my", "meaning", "-", "if", "you", "continue", "to", "hara", "##ss", "me", ",", "it", "is", "your", "ass", "that", "is", "grass", "-", "i", "'", "ve", "violated", "no", "policies", "-", "you", "have", ".", "leave", "me", "be", "."], "span": ["read what", "what i", "i say", "say and", "and understand", "understand my", "my meaning", "meaning -", "- if", "if you", "you continue", "continue to", "to hara", "harass", "##ss me", "me,", ", it", "it is", "is your", "your ass", "ass that", "that is", "is grass", "grass -", "- i", "i '", "' ve", "ve violated", "violated no", "no policies", "policies -", "- you", "you have", "have.", ". leave", "leave me", "me be", "be."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\nI just got a telegram in the mail...it says......\"\"GWERNOL IS GAY!!!\"\"\n\nSwear to fuck your mom if you swear to tape it.\"", "tokenize_content": ["\"", "i", "just", "got", "a", "telegram", "in", "the", "mail", ".", ".", ".", "it", "says", ".", ".", ".", ".", ".", ".", "\"", "\"", "g", "##wer", "##no", "##l", "is", "gay", "!", "!", "!", "\"", "\"", "swear", "to", "fuck", "your", "mom", "if", "you", "swear", "to", "tape", "it", ".", "\""], "span": ["\" i", "i just", "just got", "got a", "a telegram", "telegram in", "in the", "the mail", "mail.", "..", "..", ". it", "it says", "says.", "..", "..", "..", "..", "..", ". \"", "\" \"", "\" g", "gwer", "##werno", "##nol", "##l is", "is gay", "gay!", "!!", "!!", "! \"", "\" \"", "\" swear", "swear to", "to fuck", "fuck your", "your mom", "mom if", "if you", "you swear", "swear to", "to tape", "tape it", "it.", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Martin Conway sucks cock in the Men's toilet at the ANU \n\nhahahahahhahahahahahahahhahahahaha what a filthy homo", "tokenize_content": ["martin", "conway", "sucks", "cock", "in", "the", "men", "'", "s", "toilet", "at", "the", "an", "##u", "ha", "##ha", "##ha", "##ha", "##hh", "##aha", "##ha", "##ha", "##ha", "##ha", "##ha", "##hh", "##aha", "##ha", "##ha", "##ha", "what", "a", "filthy", "homo"], "span": ["martin conway", "conway sucks", "sucks cock", "cock in", "in the", "the men", "men '", "' s", "s toilet", "toilet at", "at the", "the an", "anu", "##u ha", "haha", "##haha", "##haha", "##hahh", "##hhaha", "##ahaha", "##haha", "##haha", "##haha", "##haha", "##hahh", "##hhaha", "##ahaha", "##haha", "##haha", "##ha what", "what a", "a filthy", "filthy homo"], "toxic": 1, "score": [0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "YO MAMA YOU ARE ALL NERD DO DWELLERS", "tokenize_content": ["yo", "mama", "you", "are", "all", "ne", "##rd", "do", "dwellers"], "span": ["yo mama", "mama you", "you are", "are all", "all ne", "nerd", "##rd do", "do dwellers"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "YOU PEOPLE ARE IDIOTS! YOU BASE YOUR INFORMATION ON OPINION RATHER THAN FACT. DUMBASSES!", "tokenize_content": ["you", "people", "are", "idiots", "!", "you", "base", "your", "information", "on", "opinion", "rather", "than", "fact", ".", "dumb", "##asse", "##s", "!"], "span": ["you people", "people are", "are idiots", "idiots!", "! you", "you base", "base your", "your information", "information on", "on opinion", "opinion rather", "rather than", "than fact", "fact.", ". dumb", "dumbasse", "##asses", "##s!"], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]}
{"content": "hello a mexican bounty hunter wants your scalp - he will pay 500 pesos for it - he hates indios", "tokenize_content": ["hello", "a", "mexican", "bounty", "hunter", "wants", "your", "scalp", "-", "he", "will", "pay", "500", "pe", "##sos", "for", "it", "-", "he", "hates", "ind", "##ios"], "span": ["hello a", "a mexican", "mexican bounty", "bounty hunter", "hunter wants", "wants your", "your scalp", "scalp -", "- he", "he will", "will pay", "pay 500", "500 pe", "pesos", "##sos for", "for it", "it -", "- he", "he hates", "hates ind", "indios"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Nuke Sweden! Go probe urself with an anal probe. F*ckhead.", "tokenize_content": ["nu", "##ke", "sweden", "!", "go", "probe", "ur", "##sel", "##f", "with", "an", "anal", "probe", ".", "f", "*", "ck", "##head", "."], "span": ["nuke", "##ke sweden", "sweden!", "! go", "go probe", "probe ur", "ursel", "##self", "##f with", "with an", "an anal", "anal probe", "probe.", ". f", "f *", "* ck", "ckhead", "##head."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0]}
{"content": "You defend the indefensible, Wiki is crap, end of.", "tokenize_content": ["you", "defend", "the", "ind", "##efe", "##ns", "##ible", ",", "wi", "##ki", "is", "crap", ",", "end", "of", "."], "span": ["you defend", "defend the", "the ind", "indefe", "##efens", "##nsible", "##ible,", ", wi", "wiki", "##ki is", "is crap", "crap,", ", end", "end of", "of."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]}
{"content": "Where the fuck is the printer toner you stupid motherfuckers?  205.157.110.11", "tokenize_content": ["where", "the", "fuck", "is", "the", "printer", "tone", "##r", "you", "stupid", "mother", "##fu", "##cker", "##s", "?", "205", ".", "157", ".", "110", ".", "11"], "span": ["where the", "the fuck", "fuck is", "is the", "the printer", "printer tone", "toner", "##r you", "you stupid", "stupid mother", "motherfu", "##fucker", "##ckers", "##s?", "? 205", "205.", ". 157", "157.", ". 110", "110.", ". 11"], "toxic": 1, "score": [0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Either wikipedia is letting anyone become an administrator, or they want to make things as dull and stupid as possible for intelligent people.", "tokenize_content": ["either", "wikipedia", "is", "letting", "anyone", "become", "an", "administrator", ",", "or", "they", "want", "to", "make", "things", "as", "dull", "and", "stupid", "as", "possible", "for", "intelligent", "people", "."], "span": ["either wikipedia", "wikipedia is", "is letting", "letting anyone", "anyone become", "become an", "an administrator", "administrator,", ", or", "or they", "they want", "want to", "to make", "make things", "things as", "as dull", "dull and", "and stupid", "stupid as", "as possible", "possible for", "for intelligent", "intelligent people", "people."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]}
{"content": "Ed Cole\n\nFuck you and ed cole...Harry Sweoger, New YOrk Jew....", "tokenize_content": ["ed", "cole", "fuck", "you", "and", "ed", "cole", ".", ".", ".", "harry", "sw", "##eo", "##ger", ",", "new", "york", "jew", ".", ".", ".", "."], "span": ["ed cole", "cole fuck", "fuck you", "you and", "and ed", "ed cole", "cole.", "..", "..", ". harry", "harry sw", "sweo", "##eoger", "##ger,", ", new", "new york", "york jew", "jew.", "..", "..", ".."], "toxic": 1, "score": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "NOW Y CAN LEADER THE CHINA PIGS, TAIWAN NOT NEEDCHIAN PIGS.", "tokenize_content": ["now", "y", "can", "leader", "the", "china", "pigs", ",", "taiwan", "not", "need", "##chia", "##n", "pigs", "."], "span": ["now y", "y can", "can leader", "leader the", "the china", "china pigs", "pigs,", ", taiwan", "taiwan not", "not need", "needchia", "##chian", "##n pigs", "pigs."], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "WARNING ABOUT RODHULLANDEMU\n\nWarning! This user is mentally retarteded!", "tokenize_content": ["warning", "about", "rod", "##hul", "##land", "##em", "##u", "warning", "!", "this", "user", "is", "mentally", "re", "##tar", "##ted", "##ed", "!"], "span": ["warning about", "about rod", "rodhul", "##hulland", "##landem", "##emu", "##u warning", "warning!", "! this", "this user", "user is", "is mentally", "mentally re", "retar", "##tarted", "##teded", "##ed!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "hey retard. \n\nYou don't get it. those two put warnings on my page for vandalising User:tommy2010/vandalise. they can putt odd things on my page, i can put weird things on theirs.", "tokenize_content": ["hey", "re", "##tar", "##d", ".", "you", "don", "'", "t", "get", "it", ".", "those", "two", "put", "warnings", "on", "my", "page", "for", "van", "##dal", "##ising", "user", ":", "tommy", "##20", "##10", "/", "van", "##dal", "##ise", ".", "they", "can", "put", "##t", "odd", "things", "on", "my", "page", ",", "i", "can", "put", "weird", "things", "on", "theirs", "."], "span": ["hey re", "retar", "##tard", "##d.", ". you", "you don", "don '", "' t", "t get", "get it", "it.", ". those", "those two", "two put", "put warnings", "warnings on", "on my", "my page", "page for", "for van", "vandal", "##dalising", "##ising user", "user :", ": tommy", "tommy20", "##2010", "##10 /", "/ van", "vandal", "##dalise", "##ise.", ". they", "they can", "can put", "putt", "##t odd", "odd things", "things on", "on my", "my page", "page,", ", i", "i can", "can put", "put weird", "weird things", "things on", "on theirs", "theirs."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "fuck you \n\n fuck you fuck wekipedia, fuck all you good for nothing dipshits who would not shit if it came out of your ass. Go fuck yourself and stay in dreamland.", "tokenize_content": ["fuck", "you", "fuck", "you", "fuck", "we", "##ki", "##ped", "##ia", ",", "fuck", "all", "you", "good", "for", "nothing", "dip", "##shi", "##ts", "who", "would", "not", "shit", "if", "it", "came", "out", "of", "your", "ass", ".", "go", "fuck", "yourself", "and", "stay", "in", "dream", "##land", "."], "span": ["fuck you", "you fuck", "fuck you", "you fuck", "fuck we", "weki", "##kiped", "##pedia", "##ia,", ", fuck", "fuck all", "all you", "you good", "good for", "for nothing", "nothing dip", "dipshi", "##shits", "##ts who", "who would", "would not", "not shit", "shit if", "if it", "it came", "came out", "out of", "of your", "your ass", "ass.", ". go", "go fuck", "fuck yourself", "yourself and", "and stay", "stay in", "in dream", "dreamland", "##land."], "toxic": 1, "score": [1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "please stop \n\nyoure retarded posts are making me laugh so hard i have the hiccups and now i cant go to sleep. \n\ncant you just be retarded somewhere else?", "tokenize_content": ["please", "stop", "your", "##e", "re", "##tar", "##ded", "posts", "are", "making", "me", "laugh", "so", "hard", "i", "have", "the", "hi", "##cc", "##ups", "and", "now", "i", "can", "##t", "go", "to", "sleep", ".", "can", "##t", "you", "just", "be", "re", "##tar", "##ded", "somewhere", "else", "?"], "span": ["please stop", "stop your", "youre", "##e re", "retar", "##tarded", "##ded posts", "posts are", "are making", "making me", "me laugh", "laugh so", "so hard", "hard i", "i have", "have the", "the hi", "hicc", "##ccups", "##ups and", "and now", "now i", "i can", "cant", "##t go", "go to", "to sleep", "sleep.", ". can", "cant", "##t you", "you just", "just be", "be re", "retar", "##tarded", "##ded somewhere", "somewhere else", "else?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "But then again who cares about Niggers", "tokenize_content": ["but", "then", "again", "who", "cares", "about", "ni", "##gger", "##s"], "span": ["but then", "then again", "again who", "who cares", "cares about", "about ni", "nigger", "##ggers"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "the cunt, ya fucking old woman.", "tokenize_content": ["the", "cu", "##nt", ",", "ya", "fucking", "old", "woman", "."], "span": ["the cu", "cunt", "##nt,", ", ya", "ya fucking", "fucking old", "old woman", "woman."], "toxic": 1, "score": [0, 1, 0, 0, 1, 1, 0, 0]}
{"content": "I would like to know how to suck a C O ( K", "tokenize_content": ["i", "would", "like", "to", "know", "how", "to", "suck", "a", "c", "o", "(", "k"], "span": ["i would", "would like", "like to", "to know", "know how", "how to", "to suck", "suck a", "a c", "c o", "o (", "( k"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "Sleazebag \n\nJimbo, you are a sleazebag. Please go away.", "tokenize_content": ["sl", "##ea", "##ze", "##bag", "jim", "##bo", ",", "you", "are", "a", "sl", "##ea", "##ze", "##bag", ".", "please", "go", "away", "."], "span": ["slea", "##eaze", "##zebag", "##bag jim", "jimbo", "##bo,", ", you", "you are", "are a", "a sl", "slea", "##eaze", "##zebag", "##bag.", ". please", "please go", "go away", "away."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\n Hi ) \n\n  Asshole Detected Award Major Suckage detected in your personality   \"", "tokenize_content": ["\"", "hi", ")", "asshole", "detected", "award", "major", "suck", "##age", "detected", "in", "your", "personality", "\""], "span": ["\" hi", "hi )", ") asshole", "asshole detected", "detected award", "award major", "major suck", "suckage", "##age detected", "detected in", "in your", "your personality", "personality \""], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]}
{"content": "remove your head from your butt \n\nNeilN needs to remove its head from its bottom and get off its high hotse.\n\n Joe", "tokenize_content": ["remove", "your", "head", "from", "your", "butt", "neil", "##n", "needs", "to", "remove", "its", "head", "from", "its", "bottom", "and", "get", "off", "its", "high", "hot", "##se", ".", "joe"], "span": ["remove your", "your head", "head from", "from your", "your butt", "butt neil", "neiln", "##n needs", "needs to", "to remove", "remove its", "its head", "head from", "from its", "its bottom", "bottom and", "and get", "get off", "off its", "its high", "high hot", "hotse", "##se.", ". joe"], "toxic": 1, "score": [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\nKeep your thieving aussie hands of my nomination DHMO )   \u00a0Chat\u00a0  \"", "tokenize_content": ["\"", "keep", "your", "th", "##ieving", "aus", "##sie", "hands", "of", "my", "nomination", "dh", "##mo", ")", "chat", "\""], "span": ["\" keep", "keep your", "your th", "thieving", "##ieving aus", "aussie", "##sie hands", "hands of", "of my", "my nomination", "nomination dh", "dhmo", "##mo )", ") chat", "chat \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "FU.CK OFF \nits my userpage you tard\nhfydrhhtt tttt tttt ttft ttttt ttt gfftttttthdh dhtdrrth\n ff fffff ffffff ff fffffff", "tokenize_content": ["fu", ".", "ck", "off", "its", "my", "user", "##page", "you", "tar", "##d", "h", "##fy", "##dr", "##hh", "##tt", "tt", "##tt", "tt", "##tt", "tt", "##ft", "tt", "##tt", "##t", "tt", "##t", "g", "##ff", "##tt", "##tt", "##tt", "##hd", "##h", "dh", "##t", "##dr", "##rth", "ff", "ff", "##ff", "##f", "ff", "##ff", "##ff", "ff", "ff", "##ff", "##ff", "##f"], "span": ["fu.", ". ck", "ck off", "off its", "its my", "my user", "userpage", "##page you", "you tar", "tard", "##d h", "hfy", "##fydr", "##drhh", "##hhtt", "##tt tt", "tttt", "##tt tt", "tttt", "##tt tt", "ttft", "##ft tt", "tttt", "##ttt", "##t tt", "ttt", "##t g", "gff", "##fftt", "##tttt", "##tttt", "##tthd", "##hdh", "##h dh", "dht", "##tdr", "##drrth", "##rth ff", "ff ff", "ffff", "##fff", "##f ff", "ffff", "##ffff", "##ff ff", "ff ff", "ffff", "##ffff", "##fff"], "toxic": 1, "score": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "this article is a disgrace to all of this monster's victims. you will rot in hell for all of this, if you aren't punished by the victim's families first", "tokenize_content": ["this", "article", "is", "a", "disgrace", "to", "all", "of", "this", "monster", "'", "s", "victims", ".", "you", "will", "rot", "in", "hell", "for", "all", "of", "this", ",", "if", "you", "aren", "'", "t", "punished", "by", "the", "victim", "'", "s", "families", "first"], "span": ["this article", "article is", "is a", "a disgrace", "disgrace to", "to all", "all of", "of this", "this monster", "monster '", "' s", "s victims", "victims.", ". you", "you will", "will rot", "rot in", "in hell", "hell for", "for all", "all of", "of this", "this,", ", if", "if you", "you aren", "aren '", "' t", "t punished", "punished by", "by the", "the victim", "victim '", "' s", "s families", "families first"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "== Hey fuck you you cocksucker \n\nI was talking to Daymee you fucking retard.", "tokenize_content": ["=", "=", "hey", "fuck", "you", "you", "cock", "##su", "##cker", "i", "was", "talking", "to", "day", "##me", "##e", "you", "fucking", "re", "##tar", "##d", "."], "span": ["= =", "= hey", "hey fuck", "fuck you", "you you", "you cock", "cocksu", "##sucker", "##cker i", "i was", "was talking", "talking to", "to day", "dayme", "##mee", "##e you", "you fucking", "fucking re", "retar", "##tard", "##d."], "toxic": 1, "score": [0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]}
{"content": "KEEP WRITING TO YOUR FRIEND JPGORDON...WHO CARES, SILLY SLOVENIAN...WHO CARES OF YOU AND YOUR RAT PACK...", "tokenize_content": ["keep", "writing", "to", "your", "friend", "jp", "##gor", "##don", ".", ".", ".", "who", "cares", ",", "silly", "slovenian", ".", ".", ".", "who", "cares", "of", "you", "and", "your", "rat", "pack", ".", ".", "."], "span": ["keep writing", "writing to", "to your", "your friend", "friend jp", "jpgor", "##gordon", "##don.", "..", "..", ". who", "who cares", "cares,", ", silly", "silly slovenian", "slovenian.", "..", "..", ". who", "who cares", "cares of", "of you", "you and", "and your", "your rat", "rat pack", "pack.", "..", ".."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]}
{"content": "Note: If you want me to offer you sexual services e-mail me and I will send you my account number into which you can deposit money in exchange for the aforementioned services. E-mail for updated tariffs.", "tokenize_content": ["note", ":", "if", "you", "want", "me", "to", "offer", "you", "sexual", "services", "e", "-", "mail", "me", "and", "i", "will", "send", "you", "my", "account", "number", "into", "which", "you", "can", "deposit", "money", "in", "exchange", "for", "the", "aforementioned", "services", ".", "e", "-", "mail", "for", "updated", "tariffs", "."], "span": ["note :", ": if", "if you", "you want", "want me", "me to", "to offer", "offer you", "you sexual", "sexual services", "services e", "e -", "- mail", "mail me", "me and", "and i", "i will", "will send", "send you", "you my", "my account", "account number", "number into", "into which", "which you", "you can", "can deposit", "deposit money", "money in", "in exchange", "exchange for", "for the", "the aforementioned", "aforementioned services", "services.", ". e", "e -", "- mail", "mail for", "for updated", "updated tariffs", "tariffs."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "the stupid one, not me", "tokenize_content": ["the", "stupid", "one", ",", "not", "me"], "span": ["the stupid", "stupid one", "one,", ", not", "not me"], "toxic": 1, "score": [1, 1, 0, 0, 0]}
{"content": "You are 22 years older than your husband! You are an old cougar!  \n\nYou are an old cougar! You are an old cougar!", "tokenize_content": ["you", "are", "22", "years", "older", "than", "your", "husband", "!", "you", "are", "an", "old", "co", "##uga", "##r", "!", "you", "are", "an", "old", "co", "##uga", "##r", "!", "you", "are", "an", "old", "co", "##uga", "##r", "!"], "span": ["you are", "are 22", "22 years", "years older", "older than", "than your", "your husband", "husband!", "! you", "you are", "are an", "an old", "old co", "couga", "##ugar", "##r!", "! you", "you are", "are an", "an old", "old co", "couga", "##ugar", "##r!", "! you", "you are", "are an", "an old", "old co", "couga", "##ugar", "##r!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "how big is ur cock \n\ni wanna suck u off )", "tokenize_content": ["how", "big", "is", "ur", "cock", "i", "wanna", "suck", "u", "off", ")"], "span": ["how big", "big is", "is ur", "ur cock", "cock i", "i wanna", "wanna suck", "suck u", "u off", "off )"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 1, 1, 0, 0]}
{"content": "why should people have to read crap posted by idiots like you?", "tokenize_content": ["why", "should", "people", "have", "to", "read", "crap", "posted", "by", "idiots", "like", "you", "?"], "span": ["why should", "should people", "people have", "have to", "to read", "read crap", "crap posted", "posted by", "by idiots", "idiots like", "like you", "you?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0]}
{"content": "Hey dick \nYou don't know what is copyright so shutup and get out of here, don't write stupid bullshit on my talk page. Dhivehi language is Dhivehi language not your bullshit nonsese.", "tokenize_content": ["hey", "dick", "you", "don", "'", "t", "know", "what", "is", "copyright", "so", "shut", "##up", "and", "get", "out", "of", "here", ",", "don", "'", "t", "write", "stupid", "bullshit", "on", "my", "talk", "page", ".", "dh", "##ive", "##hi", "language", "is", "dh", "##ive", "##hi", "language", "not", "your", "bullshit", "non", "##ses", "##e", "."], "span": ["hey dick", "dick you", "you don", "don '", "' t", "t know", "know what", "what is", "is copyright", "copyright so", "so shut", "shutup", "##up and", "and get", "get out", "out of", "of here", "here,", ", don", "don '", "' t", "t write", "write stupid", "stupid bullshit", "bullshit on", "on my", "my talk", "talk page", "page.", ". dh", "dhive", "##ivehi", "##hi language", "language is", "is dh", "dhive", "##ivehi", "##hi language", "language not", "not your", "your bullshit", "bullshit non", "nonses", "##sese", "##e."], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]}
{"content": "I am not the only one who finds the article too ridiculous and trivia to be included.", "tokenize_content": ["i", "am", "not", "the", "only", "one", "who", "finds", "the", "article", "too", "ridiculous", "and", "tri", "##via", "to", "be", "included", "."], "span": ["i am", "am not", "not the", "the only", "only one", "one who", "who finds", "finds the", "the article", "article too", "too ridiculous", "ridiculous and", "and tri", "trivia", "##via to", "to be", "be included", "included."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "wtf \n\nfuck this shit why the fuck wuld sum pussy liccking site be fucking offline? FUCK! 192.43.227.18", "tokenize_content": ["w", "##tf", "fuck", "this", "shit", "why", "the", "fuck", "wu", "##ld", "sum", "pussy", "li", "##cc", "##king", "site", "be", "fucking", "off", "##line", "?", "fuck", "!", "192", ".", "43", ".", "227", ".", "18"], "span": ["wtf", "##tf fuck", "fuck this", "this shit", "shit why", "why the", "the fuck", "fuck wu", "wuld", "##ld sum", "sum pussy", "pussy li", "licc", "##ccking", "##king site", "site be", "be fucking", "fucking off", "offline", "##line?", "? fuck", "fuck!", "! 192", "192.", ". 43", "43.", ". 227", "227.", ". 18"], "toxic": 1, "score": [0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "HE vandalized MINE using a sockpuppet accusation template.  *I* merely returned the favor.  Now blow it out your eye wall!", "tokenize_content": ["he", "van", "##dal", "##ized", "mine", "using", "a", "sock", "##pu", "##ppet", "accusation", "template", ".", "*", "i", "*", "merely", "returned", "the", "favor", ".", "now", "blow", "it", "out", "your", "eye", "wall", "!"], "span": ["he van", "vandal", "##dalized", "##ized mine", "mine using", "using a", "a sock", "sockpu", "##puppet", "##ppet accusation", "accusation template", "template.", ". *", "* i", "i *", "* merely", "merely returned", "returned the", "the favor", "favor.", ". now", "now blow", "blow it", "it out", "out your", "your eye", "eye wall", "wall!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Stay out of it it's none of your business", "tokenize_content": ["stay", "out", "of", "it", "it", "'", "s", "none", "of", "your", "business"], "span": ["stay out", "out of", "of it", "it it", "it '", "' s", "s none", "none of", "of your", "your business"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "You sir are an imbecile, and a pervert.", "tokenize_content": ["you", "sir", "are", "an", "im", "##be", "##ci", "##le", ",", "and", "a", "per", "##vert", "."], "span": ["you sir", "sir are", "are an", "an im", "imbe", "##beci", "##cile", "##le,", ", and", "and a", "a per", "pervert", "##vert."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "you suck, just kidding", "tokenize_content": ["you", "suck", ",", "just", "kidding"], "span": ["you suck", "suck,", ", just", "just kidding"], "toxic": 1, "score": [1, 1, 0, 0]}
{"content": "Who the fuck would add prank edits that are small and inaccurate?", "tokenize_content": ["who", "the", "fuck", "would", "add", "prank", "edit", "##s", "that", "are", "small", "and", "inaccurate", "?"], "span": ["who the", "the fuck", "fuck would", "would add", "add prank", "prank edit", "edits", "##s that", "that are", "are small", "small and", "and inaccurate", "inaccurate?"], "toxic": 1, "score": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Trouted \n\nYou have been trouted for: being a homo cunt", "tokenize_content": ["trout", "##ed", "you", "have", "been", "trout", "##ed", "for", ":", "being", "a", "homo", "cu", "##nt"], "span": ["trouted", "##ed you", "you have", "have been", "been trout", "trouted", "##ed for", "for :", ": being", "being a", "a homo", "homo cu", "cunt"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "Grow up, you immature little brat.  This edit warring seems to be the only thing you do around here.", "tokenize_content": ["grow", "up", ",", "you", "immature", "little", "brat", ".", "this", "edit", "warring", "seems", "to", "be", "the", "only", "thing", "you", "do", "around", "here", "."], "span": ["grow up", "up,", ", you", "you immature", "immature little", "little brat", "brat.", ". this", "this edit", "edit warring", "warring seems", "seems to", "to be", "be the", "the only", "only thing", "thing you", "you do", "do around", "around here", "here."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\nYou're a moron that likes to throw the word \"\"logogram\"\" around.\"", "tokenize_content": ["\"", "you", "'", "re", "a", "mor", "##on", "that", "likes", "to", "throw", "the", "word", "\"", "\"", "logo", "##gram", "\"", "\"", "around", ".", "\""], "span": ["\" you", "you '", "' re", "re a", "a mor", "moron", "##on that", "that likes", "likes to", "to throw", "throw the", "the word", "word \"", "\" \"", "\" logo", "logogram", "##gram \"", "\" \"", "\" around", "around.", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\nYou playing with NOT your yard so I'm playing with yours. \"\"NOP is Antisemitic\"\" so Ukraine is Poland. Thats it.\n\n  \"", "tokenize_content": ["\"", "you", "playing", "with", "not", "your", "yard", "so", "i", "'", "m", "playing", "with", "yours", ".", "\"", "\"", "no", "##p", "is", "anti", "##se", "##mit", "##ic", "\"", "\"", "so", "ukraine", "is", "poland", ".", "that", "##s", "it", ".", "\""], "span": ["\" you", "you playing", "playing with", "with not", "not your", "your yard", "yard so", "so i", "i '", "' m", "m playing", "playing with", "with yours", "yours.", ". \"", "\" \"", "\" no", "nop", "##p is", "is anti", "antise", "##semit", "##mitic", "##ic \"", "\" \"", "\" so", "so ukraine", "ukraine is", "is poland", "poland.", ". that", "thats", "##s it", "it.", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Kill all niggers. \n\nI have hard, that others have said this.. should this be included? That racists sometimes say these.", "tokenize_content": ["kill", "all", "ni", "##gger", "##s", ".", "i", "have", "hard", ",", "that", "others", "have", "said", "this", ".", ".", "should", "this", "be", "included", "?", "that", "racist", "##s", "sometimes", "say", "these", "."], "span": ["kill all", "all ni", "nigger", "##ggers", "##s.", ". i", "i have", "have hard", "hard,", ", that", "that others", "others have", "have said", "said this", "this.", "..", ". should", "should this", "this be", "be included", "included?", "? that", "that racist", "racists", "##s sometimes", "sometimes say", "say these", "these."], "toxic": 1, "score": [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Who's ur Uncle, Dick?", "tokenize_content": ["who", "'", "s", "ur", "uncle", ",", "dick", "?"], "span": ["who '", "' s", "s ur", "ur uncle", "uncle,", ", dick", "dick?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1]}
{"content": "Member of the gaming community are you? Stupid wikipedia loser", "tokenize_content": ["member", "of", "the", "gaming", "community", "are", "you", "?", "stupid", "wikipedia", "loser"], "span": ["member of", "of the", "the gaming", "gaming community", "community are", "are you", "you?", "? stupid", "stupid wikipedia", "wikipedia loser"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 1, 1]}
{"content": "God damn Get some sense!  I think the senior members are making huge mistakes putting you little children in charge!", "tokenize_content": ["god", "damn", "get", "some", "sense", "!", "i", "think", "the", "senior", "members", "are", "making", "huge", "mistakes", "putting", "you", "little", "children", "in", "charge", "!"], "span": ["god damn", "damn get", "get some", "some sense", "sense!", "! i", "i think", "think the", "the senior", "senior members", "members are", "are making", "making huge", "huge mistakes", "mistakes putting", "putting you", "you little", "little children", "children in", "in charge", "charge!"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "=why are you being so rude? i only want to help you motherfuckers. fuck! retards! you're such retards! i hope you all die! seriously, die!!!", "tokenize_content": ["=", "why", "are", "you", "being", "so", "rude", "?", "i", "only", "want", "to", "help", "you", "mother", "##fu", "##cker", "##s", ".", "fuck", "!", "re", "##tar", "##ds", "!", "you", "'", "re", "such", "re", "##tar", "##ds", "!", "i", "hope", "you", "all", "die", "!", "seriously", ",", "die", "!", "!", "!"], "span": ["= why", "why are", "are you", "you being", "being so", "so rude", "rude?", "? i", "i only", "only want", "want to", "to help", "help you", "you mother", "motherfu", "##fucker", "##ckers", "##s.", ". fuck", "fuck!", "! re", "retar", "##tards", "##ds!", "! you", "you '", "' re", "re such", "such re", "retar", "##tards", "##ds!", "! i", "i hope", "hope you", "you all", "all die", "die!", "! seriously", "seriously,", ", die", "die!", "!!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]}
{"content": "Hey moron, I could easily log out and make edits with another username, and oh 72 hours I'm scared. Moron.", "tokenize_content": ["hey", "mor", "##on", ",", "i", "could", "easily", "log", "out", "and", "make", "edit", "##s", "with", "another", "user", "##name", ",", "and", "oh", "72", "hours", "i", "'", "m", "scared", ".", "mor", "##on", "."], "span": ["hey mor", "moron", "##on,", ", i", "i could", "could easily", "easily log", "log out", "out and", "and make", "make edit", "edits", "##s with", "with another", "another user", "username", "##name,", ", and", "and oh", "oh 72", "72 hours", "hours i", "i '", "' m", "m scared", "scared.", ". mor", "moron", "##on."], "toxic": 1, "score": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}
{"content": "You racist hillbille pig!  You don't like what others have to say so you delete their posts and block us while you continue to rant and rave your racist sermon.  Shame on you!", "tokenize_content": ["you", "racist", "hill", "##bill", "##e", "pig", "!", "you", "don", "'", "t", "like", "what", "others", "have", "to", "say", "so", "you", "del", "##ete", "their", "posts", "and", "block", "us", "while", "you", "continue", "to", "ran", "##t", "and", "rave", "your", "racist", "sermon", ".", "shame", "on", "you", "!"], "span": ["you racist", "racist hill", "hillbill", "##bille", "##e pig", "pig!", "! you", "you don", "don '", "' t", "t like", "like what", "what others", "others have", "have to", "to say", "say so", "so you", "you del", "delete", "##ete their", "their posts", "posts and", "and block", "block us", "us while", "while you", "you continue", "continue to", "to ran", "rant", "##t and", "and rave", "rave your", "your racist", "racist sermon", "sermon.", ". shame", "shame on", "on you", "you!"], "toxic": 1, "score": [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]}
{"content": "\"The definition of genre warrior is YOU. I am not \"\"warring\"\" shit. I am adding sources for genres already existing. You are pushing your own opinion as fact. And I will destroy you if you continue to thwart me. \"", "tokenize_content": ["\"", "the", "definition", "of", "genre", "warrior", "is", "you", ".", "i", "am", "not", "\"", "\"", "warring", "\"", "\"", "shit", ".", "i", "am", "adding", "sources", "for", "genres", "already", "existing", ".", "you", "are", "pushing", "your", "own", "opinion", "as", "fact", ".", "and", "i", "will", "destroy", "you", "if", "you", "continue", "to", "th", "##wart", "me", ".", "\""], "span": ["\" the", "the definition", "definition of", "of genre", "genre warrior", "warrior is", "is you", "you.", ". i", "i am", "am not", "not \"", "\" \"", "\" warring", "warring \"", "\" \"", "\" shit", "shit.", ". i", "i am", "am adding", "adding sources", "sources for", "for genres", "genres already", "already existing", "existing.", ". you", "you are", "are pushing", "pushing your", "your own", "own opinion", "opinion as", "as fact", "fact.", ". and", "and i", "i will", "will destroy", "destroy you", "you if", "if you", "you continue", "continue to", "to th", "thwart", "##wart me", "me.", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Watch out for this guy below, he's so bossy and he continues to cyberbully be. What a total dumbfuck.", "tokenize_content": ["watch", "out", "for", "this", "guy", "below", ",", "he", "'", "s", "so", "boss", "##y", "and", "he", "continues", "to", "cyber", "##bu", "##lly", "be", ".", "what", "a", "total", "dumb", "##fu", "##ck", "."], "span": ["watch out", "out for", "for this", "this guy", "guy below", "below,", ", he", "he '", "' s", "s so", "so boss", "bossy", "##y and", "and he", "he continues", "continues to", "to cyber", "cyberbu", "##bully", "##lly be", "be.", ". what", "what a", "a total", "total dumb", "dumbfu", "##fuck", "##ck."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1]}
{"content": "\"\n\n\"\"Tamil\"\" thuggery... way to be racist wikipedia.\"", "tokenize_content": ["\"", "\"", "\"", "tamil", "\"", "\"", "thug", "##ger", "##y", ".", ".", ".", "way", "to", "be", "racist", "wikipedia", ".", "\""], "span": ["\" \"", "\" \"", "\" tamil", "tamil \"", "\" \"", "\" thug", "thugger", "##gery", "##y.", "..", "..", ". way", "way to", "to be", "be racist", "racist wikipedia", "wikipedia.", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "ou leftist Wikipedia scum are an insignificant fringe group that will soon be exterminated.", "tokenize_content": ["ou", "leftist", "wikipedia", "sc", "##um", "are", "an", "insignificant", "fringe", "group", "that", "will", "soon", "be", "ex", "##ter", "##minated", "."], "span": ["ou leftist", "leftist wikipedia", "wikipedia sc", "scum", "##um are", "are an", "an insignificant", "insignificant fringe", "fringe group", "group that", "that will", "will soon", "soon be", "be ex", "exter", "##terminated", "##minated."], "toxic": 1, "score": [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I never fucking make the fucking article in the first place what the fuck?", "tokenize_content": ["i", "never", "fucking", "make", "the", "fucking", "article", "in", "the", "first", "place", "what", "the", "fuck", "?"], "span": ["i never", "never fucking", "fucking make", "make the", "the fucking", "fucking article", "article in", "in the", "the first", "first place", "place what", "what the", "the fuck", "fuck?"], "toxic": 1, "score": [0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "Terrible English \n\nThis article has the worst English in history.", "tokenize_content": ["terrible", "english", "this", "article", "has", "the", "worst", "english", "in", "history", "."], "span": ["terrible english", "english this", "this article", "article has", "has the", "the worst", "worst english", "english in", "in history", "history."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "lol wtf i aint vandalising\nseriously i tried not to hurt yo feelins tht time", "tokenize_content": ["lo", "##l", "w", "##tf", "i", "ain", "##t", "van", "##dal", "##ising", "seriously", "i", "tried", "not", "to", "hurt", "yo", "feel", "##ins", "th", "##t", "time"], "span": ["lol", "##l w", "wtf", "##tf i", "i ain", "aint", "##t van", "vandal", "##dalising", "##ising seriously", "seriously i", "i tried", "tried not", "not to", "to hurt", "hurt yo", "yo feel", "feelins", "##ins th", "tht", "##t time"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Piss off you slant eyed-gook", "tokenize_content": ["piss", "off", "you", "slant", "eyed", "-", "goo", "##k"], "span": ["piss off", "off you", "you slant", "slant eyed", "eyed -", "- goo", "gook"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0]}
{"content": "Nazis \n\nEvil blonde hair blue eyes tryin to celebrate their history, fkn crush them all, drive blonde hair blue eyes midget dick snow apes to extinction!!!58.107.179.146", "tokenize_content": ["nazis", "evil", "blonde", "hair", "blue", "eyes", "try", "##in", "to", "celebrate", "their", "history", ",", "fk", "##n", "crush", "them", "all", ",", "drive", "blonde", "hair", "blue", "eyes", "mid", "##get", "dick", "snow", "apes", "to", "extinction", "!", "!", "!", "58", ".", "107", ".", "179", ".", "146"], "span": ["nazis evil", "evil blonde", "blonde hair", "hair blue", "blue eyes", "eyes try", "tryin", "##in to", "to celebrate", "celebrate their", "their history", "history,", ", fk", "fkn", "##n crush", "crush them", "them all", "all,", ", drive", "drive blonde", "blonde hair", "hair blue", "blue eyes", "eyes mid", "midget", "##get dick", "dick snow", "snow apes", "apes to", "to extinction", "extinction!", "!!", "!!", "! 58", "58.", ". 107", "107.", ". 179", "179.", ". 146"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Fuck off!!! \n\nGo and buy some Andrex and wipe your rats ass/face (delete as appropriate). Fuck you!!!", "tokenize_content": ["fuck", "off", "!", "!", "!", "go", "and", "buy", "some", "andre", "##x", "and", "wipe", "your", "rats", "ass", "/", "face", "(", "del", "##ete", "as", "appropriate", ")", ".", "fuck", "you", "!", "!", "!"], "span": ["fuck off", "off!", "!!", "!!", "! go", "go and", "and buy", "buy some", "some andre", "andrex", "##x and", "and wipe", "wipe your", "your rats", "rats ass", "ass /", "/ face", "face (", "( del", "delete", "##ete as", "as appropriate", "appropriate )", ").", ". fuck", "fuck you", "you!", "!!", "!!"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]}
{"content": "please \n\nplease don't be a cunt", "tokenize_content": ["please", "please", "don", "'", "t", "be", "a", "cu", "##nt"], "span": ["please please", "please don", "don '", "' t", "t be", "be a", "a cu", "cunt"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "Bottomley \n\nIt's not an attack page you dickfag! It's a bunch of student who appreciate their A-level chemistry teacher, stop being a cunt and let us put this fucking page up...", "tokenize_content": ["bottom", "##ley", "it", "'", "s", "not", "an", "attack", "page", "you", "dick", "##fa", "##g", "!", "it", "'", "s", "a", "bunch", "of", "student", "who", "appreciate", "their", "a", "-", "level", "chemistry", "teacher", ",", "stop", "being", "a", "cu", "##nt", "and", "let", "us", "put", "this", "fucking", "page", "up", ".", ".", "."], "span": ["bottomley", "##ley it", "it '", "' s", "s not", "not an", "an attack", "attack page", "page you", "you dick", "dickfa", "##fag", "##g!", "! it", "it '", "' s", "s a", "a bunch", "bunch of", "of student", "student who", "who appreciate", "appreciate their", "their a", "a -", "- level", "level chemistry", "chemistry teacher", "teacher,", ", stop", "stop being", "being a", "a cu", "cunt", "##nt and", "and let", "let us", "us put", "put this", "this fucking", "fucking page", "page up", "up.", "..", ".."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "so wut u got asaulted boo hoo u probly luved gettin fuked in the ass by 2 hott gays", "tokenize_content": ["so", "wu", "##t", "u", "got", "asa", "##ult", "##ed", "boo", "ho", "##o", "u", "pro", "##bly", "lu", "##ved", "get", "##tin", "fu", "##ked", "in", "the", "ass", "by", "2", "hot", "##t", "gay", "##s"], "span": ["so wu", "wut", "##t u", "u got", "got asa", "asault", "##ulted", "##ed boo", "boo ho", "hoo", "##o u", "u pro", "probly", "##bly lu", "luved", "##ved get", "gettin", "##tin fu", "fuked", "##ked in", "in the", "the ass", "ass by", "by 2", "2 hot", "hott", "##t gay", "gays"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0]}
{"content": "please no profanity when u talk to me I am a very religious person, by the way my friend said fuck you", "tokenize_content": ["please", "no", "prof", "##ani", "##ty", "when", "u", "talk", "to", "me", "i", "am", "a", "very", "religious", "person", ",", "by", "the", "way", "my", "friend", "said", "fuck", "you"], "span": ["please no", "no prof", "profani", "##anity", "##ty when", "when u", "u talk", "talk to", "to me", "me i", "i am", "am a", "a very", "very religious", "religious person", "person,", ", by", "by the", "the way", "way my", "my friend", "friend said", "said fuck", "fuck you"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "Wikipedia should be named Wikifagia because they all suck balls.", "tokenize_content": ["wikipedia", "should", "be", "named", "wi", "##ki", "##fa", "##gia", "because", "they", "all", "suck", "balls", "."], "span": ["wikipedia should", "should be", "be named", "named wi", "wiki", "##kifa", "##fagia", "##gia because", "because they", "they all", "all suck", "suck balls", "balls."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]}
{"content": "Go to hell \n\nas i said my school has well over 100 pc's so you can block it you  muther fucking gay wankers who's moms lick nuts.", "tokenize_content": ["go", "to", "hell", "as", "i", "said", "my", "school", "has", "well", "over", "100", "pc", "'", "s", "so", "you", "can", "block", "it", "you", "mu", "##ther", "fucking", "gay", "wan", "##kers", "who", "'", "s", "mom", "##s", "lick", "nuts", "."], "span": ["go to", "to hell", "hell as", "as i", "i said", "said my", "my school", "school has", "has well", "well over", "over 100", "100 pc", "pc '", "' s", "s so", "so you", "you can", "can block", "block it", "it you", "you mu", "muther", "##ther fucking", "fucking gay", "gay wan", "wankers", "##kers who", "who '", "' s", "s mom", "moms", "##s lick", "lick nuts", "nuts."], "toxic": 1, "score": [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\n Shut up vs. fuck off \n\nSo, you're telling me being told to shut up isn't a personal attack?  \"\"Fuck\"\" is just a word like any other.   \"", "tokenize_content": ["\"", "shut", "up", "vs", ".", "fuck", "off", "so", ",", "you", "'", "re", "telling", "me", "being", "told", "to", "shut", "up", "isn", "'", "t", "a", "personal", "attack", "?", "\"", "\"", "fuck", "\"", "\"", "is", "just", "a", "word", "like", "any", "other", ".", "\""], "span": ["\" shut", "shut up", "up vs", "vs.", ". fuck", "fuck off", "off so", "so,", ", you", "you '", "' re", "re telling", "telling me", "me being", "being told", "told to", "to shut", "shut up", "up isn", "isn '", "' t", "t a", "a personal", "personal attack", "attack?", "? \"", "\" \"", "\" fuck", "fuck \"", "\" \"", "\" is", "is just", "just a", "a word", "word like", "like any", "any other", "other.", ". \""], "toxic": 1, "score": [0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "And you removed it! You numbskull! I don't care what you say anymore, this is my life! Go ahead with your own life, leave me alone! \u2014", "tokenize_content": ["and", "you", "removed", "it", "!", "you", "numb", "##sk", "##ull", "!", "i", "don", "'", "t", "care", "what", "you", "say", "anymore", ",", "this", "is", "my", "life", "!", "go", "ahead", "with", "your", "own", "life", ",", "leave", "me", "alone", "!", "\u2014"], "span": ["and you", "you removed", "removed it", "it!", "! you", "you numb", "numbsk", "##skull", "##ull!", "! i", "i don", "don '", "' t", "t care", "care what", "what you", "you say", "say anymore", "anymore,", ", this", "this is", "is my", "my life", "life!", "! go", "go ahead", "ahead with", "with your", "your own", "own life", "life,", ", leave", "leave me", "me alone", "alone!", "! \u2014"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Go fuck yourself and block me you cunt.", "tokenize_content": ["go", "fuck", "yourself", "and", "block", "me", "you", "cu", "##nt", "."], "span": ["go fuck", "fuck yourself", "yourself and", "and block", "block me", "me you", "you cu", "cunt", "##nt."], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 1, 0]}
{"content": "Shut the fuck up you tight-assed shithole!", "tokenize_content": ["shut", "the", "fuck", "up", "you", "tight", "-", "ass", "##ed", "shit", "##hole", "!"], "span": ["shut the", "the fuck", "fuck up", "up you", "you tight", "tight -", "- ass", "assed", "##ed shit", "shithole", "##hole!"], "toxic": 1, "score": [0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0]}
{"content": "i don't give a shit!==\n\nyou people are a bunch of dictators. eat shit.\n\n==", "tokenize_content": ["i", "don", "'", "t", "give", "a", "shit", "!", "=", "=", "you", "people", "are", "a", "bunch", "of", "dictator", "##s", ".", "eat", "shit", ".", "=", "="], "span": ["i don", "don '", "' t", "t give", "give a", "a shit", "shit!", "! =", "= =", "= you", "you people", "people are", "are a", "a bunch", "bunch of", "of dictator", "dictators", "##s.", ". eat", "eat shit", "shit.", ". =", "= ="], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "Why are you a bitch \n\nI put a constructive post and you changed it your a bitch", "tokenize_content": ["why", "are", "you", "a", "bitch", "i", "put", "a", "constructive", "post", "and", "you", "changed", "it", "your", "a", "bitch"], "span": ["why are", "are you", "you a", "a bitch", "bitch i", "i put", "put a", "a constructive", "constructive post", "post and", "and you", "you changed", "changed it", "it your", "your a", "a bitch"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "wow, that's funny because you are the biggest ahole I've encountered on here.  Stop harassing me.", "tokenize_content": ["wow", ",", "that", "'", "s", "funny", "because", "you", "are", "the", "biggest", "ah", "##ole", "i", "'", "ve", "encountered", "on", "here", ".", "stop", "hara", "##ssing", "me", "."], "span": ["wow,", ", that", "that '", "' s", "s funny", "funny because", "because you", "you are", "are the", "the biggest", "biggest ah", "ahole", "##ole i", "i '", "' ve", "ve encountered", "encountered on", "on here", "here.", ". stop", "stop hara", "harassing", "##ssing me", "me."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}
{"content": "YOU PROVE MY POINT \n\nIF YOU BLOCK ME, YOU WOULD ONLY MAKE ME RIGHT. ALL I EVER ASKED WAS FOR YOU TO LEAVE ME ALONE, SO GO AWAY OR BLOCK ME SHIT BAG, IM TIRED OF THIS DISCUSSION ALREADY.", "tokenize_content": ["you", "prove", "my", "point", "if", "you", "block", "me", ",", "you", "would", "only", "make", "me", "right", ".", "all", "i", "ever", "asked", "was", "for", "you", "to", "leave", "me", "alone", ",", "so", "go", "away", "or", "block", "me", "shit", "bag", ",", "im", "tired", "of", "this", "discussion", "already", "."], "span": ["you prove", "prove my", "my point", "point if", "if you", "you block", "block me", "me,", ", you", "you would", "would only", "only make", "make me", "me right", "right.", ". all", "all i", "i ever", "ever asked", "asked was", "was for", "for you", "you to", "to leave", "leave me", "me alone", "alone,", ", so", "so go", "go away", "away or", "or block", "block me", "me shit", "shit bag", "bag,", ", im", "im tired", "tired of", "of this", "this discussion", "discussion already", "already."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Oh, shut up and fuck off, you asshole.  I'll be blocked, for sure, but you'll look stupid for chasing me.  I'll just make another account.", "tokenize_content": ["oh", ",", "shut", "up", "and", "fuck", "off", ",", "you", "asshole", ".", "i", "'", "ll", "be", "blocked", ",", "for", "sure", ",", "but", "you", "'", "ll", "look", "stupid", "for", "chasing", "me", ".", "i", "'", "ll", "just", "make", "another", "account", "."], "span": ["oh,", ", shut", "shut up", "up and", "and fuck", "fuck off", "off,", ", you", "you asshole", "asshole.", ". i", "i '", "' ll", "ll be", "be blocked", "blocked,", ", for", "for sure", "sure,", ", but", "but you", "you '", "' ll", "ll look", "look stupid", "stupid for", "for chasing", "chasing me", "me.", ". i", "i '", "' ll", "ll just", "just make", "make another", "another account", "account."], "toxic": 1, "score": [0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "IM THE FRIEND! \nme and osirisV are planning on buying a country! DOWN WITH THE USA!!! captain-poison", "tokenize_content": ["im", "the", "friend", "!", "me", "and", "os", "##iri", "##s", "##v", "are", "planning", "on", "buying", "a", "country", "!", "down", "with", "the", "usa", "!", "!", "!", "captain", "-", "poison"], "span": ["im the", "the friend", "friend!", "! me", "me and", "and os", "osiri", "##iris", "##sv", "##v are", "are planning", "planning on", "on buying", "buying a", "a country", "country!", "! down", "down with", "with the", "the usa", "usa!", "!!", "!!", "! captain", "captain -", "- poison"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Fuck off please. Isn't my fault he is a leech on society with no job, friends, or scholastic ambition. Is it really vandalism if it's the truth I think not.\n\nkthnxbai", "tokenize_content": ["fuck", "off", "please", ".", "isn", "'", "t", "my", "fault", "he", "is", "a", "lee", "##ch", "on", "society", "with", "no", "job", ",", "friends", ",", "or", "scholastic", "ambition", ".", "is", "it", "really", "van", "##dal", "##ism", "if", "it", "'", "s", "the", "truth", "i", "think", "not", ".", "k", "##th", "##nx", "##bai"], "span": ["fuck off", "off please", "please.", ". isn", "isn '", "' t", "t my", "my fault", "fault he", "he is", "is a", "a lee", "leech", "##ch on", "on society", "society with", "with no", "no job", "job,", ", friends", "friends,", ", or", "or scholastic", "scholastic ambition", "ambition.", ". is", "is it", "it really", "really van", "vandal", "##dalism", "##ism if", "if it", "it '", "' s", "s the", "the truth", "truth i", "i think", "think not", "not.", ". k", "kth", "##thnx", "##nxbai"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "You cant block me you fucking retard. BRB nigger", "tokenize_content": ["you", "can", "##t", "block", "me", "you", "fucking", "re", "##tar", "##d", ".", "br", "##b", "ni", "##gger"], "span": ["you can", "cant", "##t block", "block me", "me you", "you fucking", "fucking re", "retar", "##tard", "##d.", ". br", "brb", "##b ni", "nigger"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1]}
{"content": "KInkaid Stinks \n\nKinkaid is a school that not only captures and uses the student as slaves, but also turns thier blood into energy", "tokenize_content": ["kin", "##kai", "##d", "stink", "##s", "kin", "##kai", "##d", "is", "a", "school", "that", "not", "only", "captures", "and", "uses", "the", "student", "as", "slaves", ",", "but", "also", "turns", "th", "##ier", "blood", "into", "energy"], "span": ["kinkai", "##kaid", "##d stink", "stinks", "##s kin", "kinkai", "##kaid", "##d is", "is a", "a school", "school that", "that not", "not only", "only captures", "captures and", "and uses", "uses the", "the student", "student as", "as slaves", "slaves,", ", but", "but also", "also turns", "turns th", "thier", "##ier blood", "blood into", "into energy"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"Fuck You==\nhey fuck you, who the fuck checks \"\"Phnom Nam Lyr Wildlife Sanctuary\"\" for vandalism. Get a fucking life you turd bag\n\n==\"", "tokenize_content": ["\"", "fuck", "you", "=", "=", "hey", "fuck", "you", ",", "who", "the", "fuck", "checks", "\"", "\"", "ph", "##no", "##m", "nam", "l", "##yr", "wildlife", "sanctuary", "\"", "\"", "for", "van", "##dal", "##ism", ".", "get", "a", "fucking", "life", "you", "tu", "##rd", "bag", "=", "=", "\""], "span": ["\" fuck", "fuck you", "you =", "= =", "= hey", "hey fuck", "fuck you", "you,", ", who", "who the", "the fuck", "fuck checks", "checks \"", "\" \"", "\" ph", "phno", "##nom", "##m nam", "nam l", "lyr", "##yr wildlife", "wildlife sanctuary", "sanctuary \"", "\" \"", "\" for", "for van", "vandal", "##dalism", "##ism.", ". get", "get a", "a fucking", "fucking life", "life you", "you tu", "turd", "##rd bag", "bag =", "= =", "= \""], "toxic": 1, "score": [1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "-also nederland is (relatively) a socialist country. we dont have the red on top our flag for no reason. but we sure as fuck arent communistic. and i fail to see any suffering our socialism has caused", "tokenize_content": ["-", "also", "ned", "##erland", "is", "(", "relatively", ")", "a", "socialist", "country", ".", "we", "don", "##t", "have", "the", "red", "on", "top", "our", "flag", "for", "no", "reason", ".", "but", "we", "sure", "as", "fuck", "aren", "##t", "communist", "##ic", ".", "and", "i", "fail", "to", "see", "any", "suffering", "our", "socialism", "has", "caused"], "span": ["- also", "also ned", "nederland", "##erland is", "is (", "( relatively", "relatively )", ") a", "a socialist", "socialist country", "country.", ". we", "we don", "dont", "##t have", "have the", "the red", "red on", "on top", "top our", "our flag", "flag for", "for no", "no reason", "reason.", ". but", "but we", "we sure", "sure as", "as fuck", "fuck aren", "arent", "##t communist", "communistic", "##ic.", ". and", "and i", "i fail", "fail to", "to see", "see any", "any suffering", "suffering our", "our socialism", "socialism has", "has caused"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "nigga wit attitude. \n\nyour such a cunt.", "tokenize_content": ["ni", "##gga", "wit", "attitude", ".", "your", "such", "a", "cu", "##nt", "."], "span": ["nigga", "##gga wit", "wit attitude", "attitude.", ". your", "your such", "such a", "a cu", "cunt", "##nt."], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0, 0, 1, 0]}
{"content": "\"Haha fuck you i can edit this page! no more \"\"midarme cant do this and mdiarme cant do that\"\" cause here i am bitch! wait what am I doing?\"", "tokenize_content": ["\"", "ha", "##ha", "fuck", "you", "i", "can", "edit", "this", "page", "!", "no", "more", "\"", "\"", "mid", "##arm", "##e", "can", "##t", "do", "this", "and", "md", "##ia", "##rm", "##e", "can", "##t", "do", "that", "\"", "\"", "cause", "here", "i", "am", "bitch", "!", "wait", "what", "am", "i", "doing", "?", "\""], "span": ["\" ha", "haha", "##ha fuck", "fuck you", "you i", "i can", "can edit", "edit this", "this page", "page!", "! no", "no more", "more \"", "\" \"", "\" mid", "midarm", "##arme", "##e can", "cant", "##t do", "do this", "this and", "and md", "mdia", "##iarm", "##rme", "##e can", "cant", "##t do", "do that", "that \"", "\" \"", "\" cause", "cause here", "here i", "i am", "am bitch", "bitch!", "! wait", "wait what", "what am", "am i", "i doing", "doing?", "? \""], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\n Why \n\nWhy are you so stupid? ARKJEDI10  \"", "tokenize_content": ["\"", "why", "why", "are", "you", "so", "stupid", "?", "ark", "##je", "##di", "##10", "\""], "span": ["\" why", "why why", "why are", "are you", "you so", "so stupid", "stupid?", "? ark", "arkje", "##jedi", "##di10", "##10 \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]}
{"content": "You are on a power trip. Why dont you go around deleting unsourced stuff from all the Bradford players pages?", "tokenize_content": ["you", "are", "on", "a", "power", "trip", ".", "why", "don", "##t", "you", "go", "around", "del", "##eti", "##ng", "un", "##so", "##ur", "##ced", "stuff", "from", "all", "the", "bradford", "players", "pages", "?"], "span": ["you are", "are on", "on a", "a power", "power trip", "trip.", ". why", "why don", "dont", "##t you", "you go", "go around", "around del", "deleti", "##eting", "##ng un", "unso", "##sour", "##urced", "##ced stuff", "stuff from", "from all", "all the", "the bradford", "bradford players", "players pages", "pages?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Block \n\nEach real man puts balls on your stupid jewish solidarity. 213.87.137.64", "tokenize_content": ["block", "each", "real", "man", "puts", "balls", "on", "your", "stupid", "jewish", "solidarity", ".", "213", ".", "87", ".", "137", ".", "64"], "span": ["block each", "each real", "real man", "man puts", "puts balls", "balls on", "on your", "your stupid", "stupid jewish", "jewish solidarity", "solidarity.", ". 213", "213.", ". 87", "87.", ". 137", "137.", ". 64"], "toxic": 1, "score": [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Hello, you disgusting transsexual. \n\nYou are a grotesque blight upon the earth. Please kill yourself.", "tokenize_content": ["hello", ",", "you", "disgusting", "trans", "##se", "##x", "##ual", ".", "you", "are", "a", "grotesque", "b", "##light", "upon", "the", "earth", ".", "please", "kill", "yourself", "."], "span": ["hello,", ", you", "you disgusting", "disgusting trans", "transse", "##sex", "##xual", "##ual.", ". you", "you are", "are a", "a grotesque", "grotesque b", "blight", "##light upon", "upon the", "the earth", "earth.", ". please", "please kill", "kill yourself", "yourself."], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "\"\nRemoval of sentence\nI reverted to remove a sentence which in part contained \"\"However this is a load of nonsense.\"\"Dakota ~  \u00b0 \"", "tokenize_content": ["\"", "removal", "of", "sentence", "i", "reverted", "to", "remove", "a", "sentence", "which", "in", "part", "contained", "\"", "\"", "however", "this", "is", "a", "load", "of", "nonsense", ".", "\"", "\"", "dakota", "~", "\u00b0", "\""], "span": ["\" removal", "removal of", "of sentence", "sentence i", "i reverted", "reverted to", "to remove", "remove a", "a sentence", "sentence which", "which in", "in part", "part contained", "contained \"", "\" \"", "\" however", "however this", "this is", "is a", "a load", "load of", "of nonsense", "nonsense.", ". \"", "\" \"", "\" dakota", "dakota ~", "~ \u00b0", "\u00b0 \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "How can you say I am illiterate, ignorant or incompetent... I am not American...92.238.252.159", "tokenize_content": ["how", "can", "you", "say", "i", "am", "ill", "##iter", "##ate", ",", "ignorant", "or", "inc", "##omp", "##ete", "##nt", ".", ".", ".", "i", "am", "not", "american", ".", ".", ".", "92", ".", "238", ".", "252", ".", "159"], "span": ["how can", "can you", "you say", "say i", "i am", "am ill", "illiter", "##iterate", "##ate,", ", ignorant", "ignorant or", "or inc", "incomp", "##ompete", "##etent", "##nt.", "..", "..", ". i", "i am", "am not", "not american", "american.", "..", "..", ". 92", "92.", ". 238", "238.", ". 252", "252.", ". 159"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Your intelligence, insight, and manners are quite poor. And YOU'RE the vandal, obviously. Don't waste my time, loser.", "tokenize_content": ["your", "intelligence", ",", "insight", ",", "and", "manners", "are", "quite", "poor", ".", "and", "you", "'", "re", "the", "van", "##dal", ",", "obviously", ".", "don", "'", "t", "waste", "my", "time", ",", "loser", "."], "span": ["your intelligence", "intelligence,", ", insight", "insight,", ", and", "and manners", "manners are", "are quite", "quite poor", "poor.", ". and", "and you", "you '", "' re", "re the", "the van", "vandal", "##dal,", ", obviously", "obviously.", ". don", "don '", "' t", "t waste", "waste my", "my time", "time,", ", loser", "loser."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "THE OFFICIAL DEATH CERTIFICATE\nBY RUSSIAN GOVERNMENT SAYS DEC 21 1879 AND YOUR OTHER LANGUAGE WIKIPEDIAS SAY SAME, GROW UP, WILL YOU!", "tokenize_content": ["the", "official", "death", "certificate", "by", "russian", "government", "says", "dec", "21", "1879", "and", "your", "other", "language", "wikipedia", "##s", "say", "same", ",", "grow", "up", ",", "will", "you", "!"], "span": ["the official", "official death", "death certificate", "certificate by", "by russian", "russian government", "government says", "says dec", "dec 21", "21 1879", "1879 and", "and your", "your other", "other language", "language wikipedia", "wikipedias", "##s say", "say same", "same,", ", grow", "grow up", "up,", ", will", "will you", "you!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Scrap the map. The 5-pic collage looks better. Real pictures sum up the war better then some plain ass map animation.", "tokenize_content": ["scrap", "the", "map", ".", "the", "5", "-", "pic", "col", "##lage", "looks", "better", ".", "real", "pictures", "sum", "up", "the", "war", "better", "then", "some", "plain", "ass", "map", "animation", "."], "span": ["scrap the", "the map", "map.", ". the", "the 5", "5 -", "- pic", "pic col", "collage", "##lage looks", "looks better", "better.", ". real", "real pictures", "pictures sum", "sum up", "up the", "the war", "war better", "better then", "then some", "some plain", "plain ass", "ass map", "map animation", "animation."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "Hey, discofucker, stay out of this.", "tokenize_content": ["hey", ",", "disco", "##fu", "##cker", ",", "stay", "out", "of", "this", "."], "span": ["hey,", ", disco", "discofu", "##fucker", "##cker,", ", stay", "stay out", "out of", "of this", "this."], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0]}
{"content": "Douchebag is a washed up has been who is mostly a crackhead bitch.", "tokenize_content": ["do", "##uche", "##bag", "is", "a", "washed", "up", "has", "been", "who", "is", "mostly", "a", "crack", "##head", "bitch", "."], "span": ["douche", "##uchebag", "##bag is", "is a", "a washed", "washed up", "up has", "has been", "been who", "who is", "is mostly", "mostly a", "a crack", "crackhead", "##head bitch", "bitch."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]}
{"content": "What... \n\nWhat are you doing? Don't fuck me. I fuck to Ryulong, not you.", "tokenize_content": ["what", ".", ".", ".", "what", "are", "you", "doing", "?", "don", "'", "t", "fuck", "me", ".", "i", "fuck", "to", "ryu", "##long", ",", "not", "you", "."], "span": ["what.", "..", "..", ". what", "what are", "are you", "you doing", "doing?", "? don", "don '", "' t", "t fuck", "fuck me", "me.", ". i", "i fuck", "fuck to", "to ryu", "ryulong", "##long,", ", not", "not you", "you."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]}
{"content": "Your DO know that Hispanics are part of Europeoid race, don't you? Aparently you don't. Damn racist! Your beloved John Wayne", "tokenize_content": ["your", "do", "know", "that", "hispanic", "##s", "are", "part", "of", "europe", "##oid", "race", ",", "don", "'", "t", "you", "?", "ap", "##are", "##ntly", "you", "don", "'", "t", ".", "damn", "racist", "!", "your", "beloved", "john", "wayne"], "span": ["your do", "do know", "know that", "that hispanic", "hispanics", "##s are", "are part", "part of", "of europe", "europeoid", "##oid race", "race,", ", don", "don '", "' t", "t you", "you?", "? ap", "apare", "##arently", "##ntly you", "you don", "don '", "' t", "t.", ". damn", "damn racist", "racist!", "! your", "your beloved", "beloved john", "john wayne"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "Then you're both blind and retarded.", "tokenize_content": ["then", "you", "'", "re", "both", "blind", "and", "re", "##tar", "##ded", "."], "span": ["then you", "you '", "' re", "re both", "both blind", "blind and", "and re", "retar", "##tarded", "##ded."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I LIKE TO ATTACK F*ING ALIENS WHEN THEY ARE SLEEPING< WHEN THEY ARE NOT AWAKE IN THE MIDDLE OF THE F*ING NIfht", "tokenize_content": ["i", "like", "to", "attack", "f", "*", "ing", "aliens", "when", "they", "are", "sleeping", "<", "when", "they", "are", "not", "awake", "in", "the", "middle", "of", "the", "f", "*", "ing", "ni", "##f", "##ht"], "span": ["i like", "like to", "to attack", "attack f", "f *", "* ing", "ing aliens", "aliens when", "when they", "they are", "are sleeping", "sleeping <", "< when", "when they", "they are", "are not", "not awake", "awake in", "in the", "the middle", "middle of", "of the", "the f", "f *", "* ing", "ing ni", "nif", "##fht"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "fuck you george \n\nakhtak sharmota", "tokenize_content": ["fuck", "you", "george", "ak", "##hta", "##k", "sha", "##rm", "##ota"], "span": ["fuck you", "you george", "george ak", "akhta", "##htak", "##k sha", "sharm", "##rmota"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "you are a loser you dumbum", "tokenize_content": ["you", "are", "a", "loser", "you", "dumb", "##um"], "span": ["you are", "are a", "a loser", "loser you", "you dumb", "dumbum"], "toxic": 1, "score": [0, 0, 1, 1, 1, 0]}
{"content": "I am a total tool who reverts shit for fun )", "tokenize_content": ["i", "am", "a", "total", "tool", "who", "rev", "##ert", "##s", "shit", "for", "fun", ")"], "span": ["i am", "am a", "a total", "total tool", "tool who", "who rev", "revert", "##erts", "##s shit", "shit for", "for fun", "fun )"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]}
{"content": "Fuck off \n\nsee my page for more of my comments on your work", "tokenize_content": ["fuck", "off", "see", "my", "page", "for", "more", "of", "my", "comments", "on", "your", "work"], "span": ["fuck off", "off see", "see my", "my page", "page for", "for more", "more of", "of my", "my comments", "comments on", "on your", "your work"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Sidenote: Xizer is not a racist. Calling this guy a nigger was just funny though. lol", "tokenize_content": ["side", "##note", ":", "xi", "##zer", "is", "not", "a", "racist", ".", "calling", "this", "guy", "a", "ni", "##gger", "was", "just", "funny", "though", ".", "lo", "##l"], "span": ["sidenote", "##note :", ": xi", "xizer", "##zer is", "is not", "not a", "a racist", "racist.", ". calling", "calling this", "this guy", "guy a", "a ni", "nigger", "##gger was", "was just", "just funny", "funny though", "though.", ". lo", "lol"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I am going to shove a burning torch up your ass. \n\nThen I will force you to sit on an open propane tank.", "tokenize_content": ["i", "am", "going", "to", "shove", "a", "burning", "torch", "up", "your", "ass", ".", "then", "i", "will", "force", "you", "to", "sit", "on", "an", "open", "prop", "##ane", "tank", "."], "span": ["i am", "am going", "going to", "to shove", "shove a", "a burning", "burning torch", "torch up", "up your", "your ass", "ass.", ". then", "then i", "i will", "will force", "force you", "you to", "to sit", "sit on", "on an", "an open", "open prop", "propane", "##ane tank", "tank."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "you are gay gay gay gay gay gay", "tokenize_content": ["you", "are", "gay", "gay", "gay", "gay", "gay", "gay"], "span": ["you are", "are gay", "gay gay", "gay gay", "gay gay", "gay gay", "gay gay"], "toxic": 1, "score": [0, 1, 1, 1, 1, 1, 1]}
{"content": "off topic, who here agreees the 2000's suck? \n\nThink about it, crappy president, huge debt, crappy music, wars, tragic events, yeah the 2000's suck -Dragong4", "tokenize_content": ["off", "topic", ",", "who", "here", "agree", "##es", "the", "2000", "'", "s", "suck", "?", "think", "about", "it", ",", "crap", "##py", "president", ",", "huge", "debt", ",", "crap", "##py", "music", ",", "wars", ",", "tragic", "events", ",", "yeah", "the", "2000", "'", "s", "suck", "-", "dragon", "##g", "##4"], "span": ["off topic", "topic,", ", who", "who here", "here agree", "agreees", "##es the", "the 2000", "2000 '", "' s", "s suck", "suck?", "? think", "think about", "about it", "it,", ", crap", "crappy", "##py president", "president,", ", huge", "huge debt", "debt,", ", crap", "crappy", "##py music", "music,", ", wars", "wars,", ", tragic", "tragic events", "events,", ", yeah", "yeah the", "the 2000", "2000 '", "' s", "s suck", "suck -", "- dragon", "dragong", "##g4"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]}
{"content": "Yakety Yak \n\nHere's a glove slap:", "tokenize_content": ["ya", "##ke", "##ty", "ya", "##k", "here", "'", "s", "a", "glove", "slap", ":"], "span": ["yake", "##kety", "##ty ya", "yak", "##k here", "here '", "' s", "s a", "a glove", "glove slap", "slap :"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Here is my badge of honor bitches )", "tokenize_content": ["here", "is", "my", "badge", "of", "honor", "bitch", "##es", ")"], "span": ["here is", "is my", "my badge", "badge of", "of honor", "honor bitch", "bitches", "##es )"], "toxic": 1, "score": [0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "Fuck this bot \n\nFuck you cluebot you suck quit reverting my shit man! Faggot! 70.234.221.234", "tokenize_content": ["fuck", "this", "bot", "fuck", "you", "clue", "##bot", "you", "suck", "quit", "rev", "##ert", "##ing", "my", "shit", "man", "!", "fa", "##gg", "##ot", "!", "70", ".", "234", ".", "221", ".", "234"], "span": ["fuck this", "this bot", "bot fuck", "fuck you", "you clue", "cluebot", "##bot you", "you suck", "suck quit", "quit rev", "revert", "##erting", "##ing my", "my shit", "shit man", "man!", "! fa", "fagg", "##ggot", "##ot!", "! 70", "70.", ". 234", "234.", ". 221", "221.", ". 234"], "toxic": 1, "score": [1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Then the inaccurate bitch is going to win, because this doesn't end til I am forced to bow or am banned.", "tokenize_content": ["then", "the", "inaccurate", "bitch", "is", "going", "to", "win", ",", "because", "this", "doesn", "'", "t", "end", "til", "i", "am", "forced", "to", "bow", "or", "am", "banned", "."], "span": ["then the", "the inaccurate", "inaccurate bitch", "bitch is", "is going", "going to", "to win", "win,", ", because", "because this", "this doesn", "doesn '", "' t", "t end", "end til", "til i", "i am", "am forced", "forced to", "to bow", "bow or", "or am", "am banned", "banned."], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "This guy is a Bitch and needs to SUCK a DICK!", "tokenize_content": ["this", "guy", "is", "a", "bitch", "and", "needs", "to", "suck", "a", "dick", "!"], "span": ["this guy", "guy is", "is a", "a bitch", "bitch and", "and needs", "needs to", "to suck", "suck a", "a dick", "dick!"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1]}
{"content": "About Chris C. \n\nHe ate A LOT of peanuts. He also smelled like gym socks. He can do the chicken dance better than a chiken.", "tokenize_content": ["about", "chris", "c", ".", "he", "ate", "a", "lot", "of", "peanuts", ".", "he", "also", "smelled", "like", "gym", "socks", ".", "he", "can", "do", "the", "chicken", "dance", "better", "than", "a", "chi", "##ken", "."], "span": ["about chris", "chris c", "c.", ". he", "he ate", "ate a", "a lot", "lot of", "of peanuts", "peanuts.", ". he", "he also", "also smelled", "smelled like", "like gym", "gym socks", "socks.", ". he", "he can", "can do", "do the", "the chicken", "chicken dance", "dance better", "better than", "than a", "a chi", "chiken", "##ken."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "THIS IS FAR LEFTWING UAF CRANK who deletes/discriminates against bnp supporters:", "tokenize_content": ["this", "is", "far", "left", "##wing", "ua", "##f", "crank", "who", "del", "##ete", "##s", "/", "disc", "##rim", "##inates", "against", "bn", "##p", "supporters", ":"], "span": ["this is", "is far", "far left", "leftwing", "##wing ua", "uaf", "##f crank", "crank who", "who del", "delete", "##etes", "##s /", "/ disc", "discrim", "##riminates", "##inates against", "against bn", "bnp", "##p supporters", "supporters :"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\nFuck you, you can't block shit Don Quixote.  How did I post this after being \"\"blocked\"\"?  And why are letting people delete user pages?   \"", "tokenize_content": ["\"", "fuck", "you", ",", "you", "can", "'", "t", "block", "shit", "don", "qui", "##x", "##ote", ".", "how", "did", "i", "post", "this", "after", "being", "\"", "\"", "blocked", "\"", "\"", "?", "and", "why", "are", "letting", "people", "del", "##ete", "user", "pages", "?", "\""], "span": ["\" fuck", "fuck you", "you,", ", you", "you can", "can '", "' t", "t block", "block shit", "shit don", "don qui", "quix", "##xote", "##ote.", ". how", "how did", "did i", "i post", "post this", "this after", "after being", "being \"", "\" \"", "\" blocked", "blocked \"", "\" \"", "\"?", "? and", "and why", "why are", "are letting", "letting people", "people del", "delete", "##ete user", "user pages", "pages?", "? \""], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Haha, well just wait till I'm unblocked, cause once I am this useless shit is going off.", "tokenize_content": ["ha", "##ha", ",", "well", "just", "wait", "till", "i", "'", "m", "un", "##block", "##ed", ",", "cause", "once", "i", "am", "this", "useless", "shit", "is", "going", "off", "."], "span": ["haha", "##ha,", ", well", "well just", "just wait", "wait till", "till i", "i '", "' m", "m un", "unblock", "##blocked", "##ed,", ", cause", "cause once", "once i", "i am", "am this", "this useless", "useless shit", "shit is", "is going", "going off", "off."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]}
{"content": "That was a mistake the stupid asses at Funimation made, Bardock was never a scientist.", "tokenize_content": ["that", "was", "a", "mistake", "the", "stupid", "ass", "##es", "at", "fun", "##ima", "##tion", "made", ",", "bard", "##ock", "was", "never", "a", "scientist", "."], "span": ["that was", "was a", "a mistake", "mistake the", "the stupid", "stupid ass", "asses", "##es at", "at fun", "funima", "##imation", "##tion made", "made,", ", bard", "bardock", "##ock was", "was never", "never a", "a scientist", "scientist."], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I'ma smack ya upside da head wit a shovel.  \n\nI'm takin ya down, boi.", "tokenize_content": ["i", "'", "ma", "smack", "ya", "upside", "da", "head", "wit", "a", "shovel", ".", "i", "'", "m", "tak", "##in", "ya", "down", ",", "bo", "##i", "."], "span": ["i '", "' ma", "ma smack", "smack ya", "ya upside", "upside da", "da head", "head wit", "wit a", "a shovel", "shovel.", ". i", "i '", "' m", "m tak", "takin", "##in ya", "ya down", "down,", ", bo", "boi", "##i."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "retard \n\nare you mentally retarded user:ugugugugugugug is my own account you absolute jibbering fool", "tokenize_content": ["re", "##tar", "##d", "are", "you", "mentally", "re", "##tar", "##ded", "user", ":", "u", "##gu", "##gu", "##gu", "##gu", "##gu", "##gu", "##g", "is", "my", "own", "account", "you", "absolute", "ji", "##bber", "##ing", "fool"], "span": ["retar", "##tard", "##d are", "are you", "you mentally", "mentally re", "retar", "##tarded", "##ded user", "user :", ": u", "ugu", "##gugu", "##gugu", "##gugu", "##gugu", "##gugu", "##gug", "##g is", "is my", "my own", "own account", "account you", "you absolute", "absolute ji", "jibber", "##bbering", "##ing fool"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "you stupid whore \n\nwill never get it will you?\ndoesnt fit in your tiny wakpedia wimp err admin brain\n\nfuck you asshole", "tokenize_content": ["you", "stupid", "whore", "will", "never", "get", "it", "will", "you", "?", "doesn", "##t", "fit", "in", "your", "tiny", "wa", "##k", "##ped", "##ia", "wi", "##mp", "er", "##r", "ad", "##min", "brain", "fuck", "you", "asshole"], "span": ["you stupid", "stupid whore", "whore will", "will never", "never get", "get it", "it will", "will you", "you?", "? doesn", "doesnt", "##t fit", "fit in", "in your", "your tiny", "tiny wa", "wak", "##kped", "##pedia", "##ia wi", "wimp", "##mp er", "err", "##r ad", "admin", "##min brain", "brain fuck", "fuck you", "you asshole"], "toxic": 1, "score": [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]}
{"content": "Hey fuck you Hal Turner sent a death threat to me in teh mail yesterday. He's a RACIST Don't let him use this is a launch pad for thi NAZI ANTICS!", "tokenize_content": ["hey", "fuck", "you", "hal", "turner", "sent", "a", "death", "threat", "to", "me", "in", "te", "##h", "mail", "yesterday", ".", "he", "'", "s", "a", "racist", "don", "'", "t", "let", "him", "use", "this", "is", "a", "launch", "pad", "for", "th", "##i", "nazi", "antics", "!"], "span": ["hey fuck", "fuck you", "you hal", "hal turner", "turner sent", "sent a", "a death", "death threat", "threat to", "to me", "me in", "in te", "teh", "##h mail", "mail yesterday", "yesterday.", ". he", "he '", "' s", "s a", "a racist", "racist don", "don '", "' t", "t let", "let him", "him use", "use this", "this is", "is a", "a launch", "launch pad", "pad for", "for th", "thi", "##i nazi", "nazi antics", "antics!"], "toxic": 1, "score": [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Anal sex \n\nI am gay and actively engage in anal sex most nights. it doesnt hurt so whats wrong with it?", "tokenize_content": ["anal", "sex", "i", "am", "gay", "and", "actively", "engage", "in", "anal", "sex", "most", "nights", ".", "it", "doesn", "##t", "hurt", "so", "what", "##s", "wrong", "with", "it", "?"], "span": ["anal sex", "sex i", "i am", "am gay", "gay and", "and actively", "actively engage", "engage in", "in anal", "anal sex", "sex most", "most nights", "nights.", ". it", "it doesn", "doesnt", "##t hurt", "hurt so", "so what", "whats", "##s wrong", "wrong with", "with it", "it?"], "toxic": 1, "score": [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "you suck \n\nbecause you are a stupid bitch!.", "tokenize_content": ["you", "suck", "because", "you", "are", "a", "stupid", "bitch", "!", "."], "span": ["you suck", "suck because", "because you", "you are", "are a", "a stupid", "stupid bitch", "bitch!", "!."], "toxic": 1, "score": [1, 1, 0, 0, 0, 1, 1, 1, 0]}
{"content": "QQ Those are Timmy crynig eyes haha.", "tokenize_content": ["q", "##q", "those", "are", "timmy", "cry", "##nig", "eyes", "ha", "##ha", "."], "span": ["qq", "##q those", "those are", "are timmy", "timmy cry", "crynig", "##nig eyes", "eyes ha", "haha", "##ha."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\":I'll just beat its ass again.  I'm at a high enough level.  - THE VOICES \n\n\"", "tokenize_content": ["\"", ":", "i", "'", "ll", "just", "beat", "its", "ass", "again", ".", "i", "'", "m", "at", "a", "high", "enough", "level", ".", "-", "the", "voices", "\""], "span": ["\" :", ": i", "i '", "' ll", "ll just", "just beat", "beat its", "its ass", "ass again", "again.", ". i", "i '", "' m", "m at", "at a", "a high", "high enough", "enough level", "level.", ". -", "- the", "the voices", "voices \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Wow, what a blatant racist you are.  Have you considered therapy?", "tokenize_content": ["wow", ",", "what", "a", "b", "##lat", "##ant", "racist", "you", "are", ".", "have", "you", "considered", "therapy", "?"], "span": ["wow,", ", what", "what a", "a b", "blat", "##latant", "##ant racist", "racist you", "you are", "are.", ". have", "have you", "you considered", "considered therapy", "therapy?"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "HOW DARE YOU EDIT MY SHIT AGAIN ARGGGGGHHHHHHHHHHH!!!!!!!!! jokes lol", "tokenize_content": ["how", "dare", "you", "edit", "my", "shit", "again", "ar", "##gg", "##gg", "##gh", "##hh", "##hh", "##hh", "##hh", "##hh", "!", "!", "!", "!", "!", "!", "!", "!", "!", "jokes", "lo", "##l"], "span": ["how dare", "dare you", "you edit", "edit my", "my shit", "shit again", "again ar", "argg", "##gggg", "##gggh", "##ghhh", "##hhhh", "##hhhh", "##hhhh", "##hhhh", "##hh!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "!!", "! jokes", "jokes lo", "lol"], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "RV \n\nYOU HAVE RVED MY EDIT.  RV IT BACK, OR I WILL DESTROY YOU.", "tokenize_content": ["rv", "you", "have", "rv", "##ed", "my", "edit", ".", "rv", "it", "back", ",", "or", "i", "will", "destroy", "you", "."], "span": ["rv you", "you have", "have rv", "rved", "##ed my", "my edit", "edit.", ". rv", "rv it", "it back", "back,", ", or", "or i", "i will", "will destroy", "destroy you", "you."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]}
{"content": "Its Not inapproprite, its constructive editing, if you wait for 1 f**king day, someone will contribute", "tokenize_content": ["its", "not", "ina", "##pp", "##rop", "##rite", ",", "its", "constructive", "editing", ",", "if", "you", "wait", "for", "1", "f", "*", "*", "king", "day", ",", "someone", "will", "contribute"], "span": ["its not", "not ina", "inapp", "##pprop", "##roprite", "##rite,", ", its", "its constructive", "constructive editing", "editing,", ", if", "if you", "you wait", "wait for", "for 1", "1 f", "f *", "* *", "* king", "king day", "day,", ", someone", "someone will", "will contribute"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "What Could Someone LIke You Possibly Know About Anything? \n\nGo play with your girlfriends ditz.", "tokenize_content": ["what", "could", "someone", "like", "you", "possibly", "know", "about", "anything", "?", "go", "play", "with", "your", "girlfriends", "di", "##tz", "."], "span": ["what could", "could someone", "someone like", "like you", "you possibly", "possibly know", "know about", "about anything", "anything?", "? go", "go play", "play with", "with your", "your girlfriends", "girlfriends di", "ditz", "##tz."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I have a huge penis and I like to fuck icelantic girls in the ass.", "tokenize_content": ["i", "have", "a", "huge", "penis", "and", "i", "like", "to", "fuck", "ice", "##lan", "##tic", "girls", "in", "the", "ass", "."], "span": ["i have", "have a", "a huge", "huge penis", "penis and", "and i", "i like", "like to", "to fuck", "fuck ice", "icelan", "##lantic", "##tic girls", "girls in", "in the", "the ass", "ass."], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1]}
{"content": "J DELANOY IS A MOTHERFUCKER \n\nnuff' said", "tokenize_content": ["j", "del", "##ano", "##y", "is", "a", "mother", "##fu", "##cker", "nu", "##ff", "'", "said"], "span": ["j del", "delano", "##anoy", "##y is", "is a", "a mother", "motherfu", "##fucker", "##cker nu", "nuff", "##ff '", "' said"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]}
{"content": "\"Nobody's could be called homophobic, even employing words such as \"\"sodomite\"\", \"\"faggot\"\" or \"\"sexual deviant\"\".\"", "tokenize_content": ["\"", "nobody", "'", "s", "could", "be", "called", "homo", "##phobic", ",", "even", "employing", "words", "such", "as", "\"", "\"", "so", "##dom", "##ite", "\"", "\"", ",", "\"", "\"", "fa", "##gg", "##ot", "\"", "\"", "or", "\"", "\"", "sexual", "devi", "##ant", "\"", "\"", ".", "\""], "span": ["\" nobody", "nobody '", "' s", "s could", "could be", "be called", "called homo", "homophobic", "##phobic,", ", even", "even employing", "employing words", "words such", "such as", "as \"", "\" \"", "\" so", "sodom", "##domite", "##ite \"", "\" \"", "\",", ", \"", "\" \"", "\" fa", "fagg", "##ggot", "##ot \"", "\" \"", "\" or", "or \"", "\" \"", "\" sexual", "sexual devi", "deviant", "##ant \"", "\" \"", "\".", ". \""], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Stay away \n\nPlease do not write on my user talk page any more. I find your pederast life style very upsetting and disgusting. Writing on my talk page about it causes me to vomit.", "tokenize_content": ["stay", "away", "please", "do", "not", "write", "on", "my", "user", "talk", "page", "any", "more", ".", "i", "find", "your", "pe", "##der", "##ast", "life", "style", "very", "upset", "##ting", "and", "disgusting", ".", "writing", "on", "my", "talk", "page", "about", "it", "causes", "me", "to", "vomit", "."], "span": ["stay away", "away please", "please do", "do not", "not write", "write on", "on my", "my user", "user talk", "talk page", "page any", "any more", "more.", ". i", "i find", "find your", "your pe", "peder", "##derast", "##ast life", "life style", "style very", "very upset", "upsetting", "##ting and", "and disgusting", "disgusting.", ". writing", "writing on", "on my", "my talk", "talk page", "page about", "about it", "it causes", "causes me", "me to", "to vomit", "vomit."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Welcome, Korean assh*le's page.\nWhy don't you enjoy licking Korean assh*le!", "tokenize_content": ["welcome", ",", "korean", "ass", "##h", "*", "le", "'", "s", "page", ".", "why", "don", "'", "t", "you", "enjoy", "licking", "korean", "ass", "##h", "*", "le", "!"], "span": ["welcome,", ", korean", "korean ass", "assh", "##h *", "* le", "le '", "' s", "s page", "page.", ". why", "why don", "don '", "' t", "t you", "you enjoy", "enjoy licking", "licking korean", "korean ass", "assh", "##h *", "* le", "le!"], "toxic": 1, "score": [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]}
{"content": "Hello Jackass:\n\nI have not forgotten about you  68.251.36.124", "tokenize_content": ["hello", "jack", "##ass", ":", "i", "have", "not", "forgotten", "about", "you", "68", ".", "251", ".", "36", ".", "124"], "span": ["hello jack", "jackass", "##ass :", ": i", "i have", "have not", "not forgotten", "forgotten about", "about you", "you 68", "68.", ". 251", "251.", ". 36", "36.", ". 124"], "toxic": 1, "score": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "If you want to stop being called a honcho, then stop acting like a honcho and start dealing with people like human beings.", "tokenize_content": ["if", "you", "want", "to", "stop", "being", "called", "a", "hon", "##cho", ",", "then", "stop", "acting", "like", "a", "hon", "##cho", "and", "start", "dealing", "with", "people", "like", "human", "beings", "."], "span": ["if you", "you want", "want to", "to stop", "stop being", "being called", "called a", "a hon", "honcho", "##cho,", ", then", "then stop", "stop acting", "acting like", "like a", "a hon", "honcho", "##cho and", "and start", "start dealing", "dealing with", "with people", "people like", "like human", "human beings", "beings."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "It was already deleted so there is no need to discuss now!! Go To Hell", "tokenize_content": ["it", "was", "already", "deleted", "so", "there", "is", "no", "need", "to", "discuss", "now", "!", "!", "go", "to", "hell"], "span": ["it was", "was already", "already deleted", "deleted so", "so there", "there is", "is no", "no need", "need to", "to discuss", "discuss now", "now!", "!!", "! go", "go to", "to hell"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}
{"content": "\"\n\"\"Bullshit is not appropriate for Wikipedia\"\". LOL.  \"", "tokenize_content": ["\"", "\"", "\"", "bullshit", "is", "not", "appropriate", "for", "wikipedia", "\"", "\"", ".", "lo", "##l", ".", "\""], "span": ["\" \"", "\" \"", "\" bullshit", "bullshit is", "is not", "not appropriate", "appropriate for", "for wikipedia", "wikipedia \"", "\" \"", "\".", ". lo", "lol", "##l.", ". \""], "toxic": 1, "score": [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "i'm so sorry bitches. i didn't mean to FUCK UP YOUR RETARD BEEHIVE", "tokenize_content": ["i", "'", "m", "so", "sorry", "bitch", "##es", ".", "i", "didn", "'", "t", "mean", "to", "fuck", "up", "your", "re", "##tar", "##d", "bee", "##hi", "##ve"], "span": ["i '", "' m", "m so", "so sorry", "sorry bitch", "bitches", "##es.", ". i", "i didn", "didn '", "' t", "t mean", "mean to", "to fuck", "fuck up", "up your", "your re", "retar", "##tard", "##d bee", "beehi", "##hive"], "toxic": 1, "score": [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Do i care? ill just make annother account. Stupid wikipedia.", "tokenize_content": ["do", "i", "care", "?", "ill", "just", "make", "ann", "##oth", "##er", "account", ".", "stupid", "wikipedia", "."], "span": ["do i", "i care", "care?", "? ill", "ill just", "just make", "make ann", "annoth", "##other", "##er account", "account.", ". stupid", "stupid wikipedia", "wikipedia."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0]}
{"content": "No, it was RE-ADD.. not read with two d's.. you STUPID FUCKING CUNT!!!!", "tokenize_content": ["no", ",", "it", "was", "re", "-", "add", ".", ".", "not", "read", "with", "two", "d", "'", "s", ".", ".", "you", "stupid", "fucking", "cu", "##nt", "!", "!", "!", "!"], "span": ["no,", ", it", "it was", "was re", "re -", "- add", "add.", "..", ". not", "not read", "read with", "with two", "two d", "d '", "' s", "s.", "..", ". you", "you stupid", "stupid fucking", "fucking cu", "cunt", "##nt!", "!!", "!!", "!!"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]}
{"content": "Dreadstar, LittleMountain5 and some jerk on the internet are jokes", "tokenize_content": ["dread", "##star", ",", "little", "##mount", "##ain", "##5", "and", "some", "jerk", "on", "the", "internet", "are", "jokes"], "span": ["dreadstar", "##star,", ", little", "littlemount", "##mountain", "##ain5", "##5 and", "and some", "some jerk", "jerk on", "on the", "the internet", "internet are", "are jokes"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]}
{"content": "I'M REALLY FUCKING SCARED 86.131.154.229", "tokenize_content": ["i", "'", "m", "really", "fucking", "scared", "86", ".", "131", ".", "154", ".", "229"], "span": ["i '", "' m", "m really", "really fucking", "fucking scared", "scared 86", "86.", ". 131", "131.", ". 154", "154.", ". 229"], "toxic": 1, "score": [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Don't talk to me troll.", "tokenize_content": ["don", "'", "t", "talk", "to", "me", "troll", "."], "span": ["don '", "' t", "t talk", "talk to", "to me", "me troll", "troll."], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 1]}
{"content": "message to attackers\nLeave him alone. what has he done to you? you ips who attack this user give honest IP editors a bad name. this shit needs to stop now. 199.101.61.190", "tokenize_content": ["message", "to", "attackers", "leave", "him", "alone", ".", "what", "has", "he", "done", "to", "you", "?", "you", "ip", "##s", "who", "attack", "this", "user", "give", "honest", "ip", "editors", "a", "bad", "name", ".", "this", "shit", "needs", "to", "stop", "now", ".", "199", ".", "101", ".", "61", ".", "190"], "span": ["message to", "to attackers", "attackers leave", "leave him", "him alone", "alone.", ". what", "what has", "has he", "he done", "done to", "to you", "you?", "? you", "you ip", "ips", "##s who", "who attack", "attack this", "this user", "user give", "give honest", "honest ip", "ip editors", "editors a", "a bad", "bad name", "name.", ". this", "this shit", "shit needs", "needs to", "to stop", "stop now", "now.", ". 199", "199.", ". 101", "101.", ". 61", "61.", ". 190"], "toxic": 1, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "FUCK ALL YOU NUT LICKING MOTHERFUCKING FAGOT COCK SUCKING WHORES!  YOU ALL SUCK SHAPIROS COCK AND LICK HIS MOTHERS CUNT!", "tokenize_content": ["fuck", "all", "you", "nut", "licking", "mother", "##fu", "##cking", "fa", "##go", "##t", "cock", "sucking", "whore", "##s", "!", "you", "all", "suck", "shapiro", "##s", "cock", "and", "lick", "his", "mothers", "cu", "##nt", "!"], "span": ["fuck all", "all you", "you nut", "nut licking", "licking mother", "motherfu", "##fucking", "##cking fa", "fago", "##got", "##t cock", "cock sucking", "sucking whore", "whores", "##s!", "! you", "you all", "all suck", "suck shapiro", "shapiros", "##s cock", "cock and", "and lick", "lick his", "his mothers", "mothers cu", "cunt", "##nt!"], "toxic": 1, "score": [1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0]}
{"content": "No please. I did it myself and corrected the factual error on this page.", "tokenize_content": ["no", "please", ".", "i", "did", "it", "myself", "and", "corrected", "the", "factual", "error", "on", "this", "page", "."], "span": ["no please", "please.", ". i", "i did", "did it", "it myself", "myself and", "and corrected", "corrected the", "the factual", "factual error", "error on", "on this", "this page", "page."], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\nThis is an interim measure. If the consensus changes it can be undone. BH \"", "tokenize_content": ["\"", "this", "is", "an", "interim", "measure", ".", "if", "the", "consensus", "changes", "it", "can", "be", "undone", ".", "b", "##h", "\""], "span": ["\" this", "this is", "is an", "an interim", "interim measure", "measure.", ". if", "if the", "the consensus", "consensus changes", "changes it", "it can", "can be", "be undone", "undone.", ". b", "bh", "##h \""], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "West Africa Editing \n\nHI Briansmithson your article is good but i reccomend u have at least 6 paragraphs after like 8 it starts to get boring so try my idea thank you", "tokenize_content": ["west", "africa", "editing", "hi", "brian", "##smith", "##son", "your", "article", "is", "good", "but", "i", "rec", "##com", "##end", "u", "have", "at", "least", "6", "paragraph", "##s", "after", "like", "8", "it", "starts", "to", "get", "boring", "so", "try", "my", "idea", "thank", "you"], "span": ["west africa", "africa editing", "editing hi", "hi brian", "briansmith", "##smithson", "##son your", "your article", "article is", "is good", "good but", "but i", "i rec", "reccom", "##comend", "##end u", "u have", "have at", "at least", "least 6", "6 paragraph", "paragraphs", "##s after", "after like", "like 8", "8 it", "it starts", "starts to", "to get", "get boring", "boring so", "so try", "try my", "my idea", "idea thank", "thank you"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Queen (band) \n\nYou are not alone in wanting to expand the genre section for Queen, neither are you alone in finding your efforts quickly reverted. It's a tough page to improve or expand. 75.4.202.97", "tokenize_content": ["queen", "(", "band", ")", "you", "are", "not", "alone", "in", "wanting", "to", "expand", "the", "genre", "section", "for", "queen", ",", "neither", "are", "you", "alone", "in", "finding", "your", "efforts", "quickly", "reverted", ".", "it", "'", "s", "a", "tough", "page", "to", "improve", "or", "expand", ".", "75", ".", "4", ".", "202", ".", "97"], "span": ["queen (", "( band", "band )", ") you", "you are", "are not", "not alone", "alone in", "in wanting", "wanting to", "to expand", "expand the", "the genre", "genre section", "section for", "for queen", "queen,", ", neither", "neither are", "are you", "you alone", "alone in", "in finding", "finding your", "your efforts", "efforts quickly", "quickly reverted", "reverted.", ". it", "it '", "' s", "s a", "a tough", "tough page", "page to", "to improve", "improve or", "or expand", "expand.", ". 75", "75.", ". 4", "4.", ". 202", "202.", ". 97"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Draft DYK hook:\n\n ... that Islamic Gibraltar (Moorish Castle pictured) was called the City of Victory and lasted for over 725 years, far longer than Spanish or British Gibraltar?", "tokenize_content": ["draft", "d", "##yk", "hook", ":", ".", ".", ".", "that", "islamic", "gibraltar", "(", "moor", "##ish", "castle", "pictured", ")", "was", "called", "the", "city", "of", "victory", "and", "lasted", "for", "over", "72", "##5", "years", ",", "far", "longer", "than", "spanish", "or", "british", "gibraltar", "?"], "span": ["draft d", "dyk", "##yk hook", "hook :", ":.", "..", "..", ". that", "that islamic", "islamic gibraltar", "gibraltar (", "( moor", "moorish", "##ish castle", "castle pictured", "pictured )", ") was", "was called", "called the", "the city", "city of", "of victory", "victory and", "and lasted", "lasted for", "for over", "over 72", "725", "##5 years", "years,", ", far", "far longer", "longer than", "than spanish", "spanish or", "or british", "british gibraltar", "gibraltar?"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "SH, thanks for the clarification.  I definitely agree with you.  What you are describing should be forbidden.", "tokenize_content": ["sh", ",", "thanks", "for", "the", "cl", "##ari", "##fication", ".", "i", "definitely", "agree", "with", "you", ".", "what", "you", "are", "describing", "should", "be", "forbidden", "."], "span": ["sh,", ", thanks", "thanks for", "for the", "the cl", "clari", "##arification", "##fication.", ". i", "i definitely", "definitely agree", "agree with", "with you", "you.", ". what", "what you", "you are", "are describing", "describing should", "should be", "be forbidden", "forbidden."], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Nobody's making anything up. The fact is that there are 8 million adults of working age who do not do any kind of work at all. (92.12.20.168  )", "tokenize_content": ["nobody", "'", "s", "making", "anything", "up", ".", "the", "fact", "is", "that", "there", "are", "8", "million", "adults", "of", "working", "age", "who", "do", "not", "do", "any", "kind", "of", "work", "at", "all", ".", "(", "92", ".", "12", ".", "20", ".", "168", ")"], "span": ["nobody '", "' s", "s making", "making anything", "anything up", "up.", ". the", "the fact", "fact is", "is that", "that there", "there are", "are 8", "8 million", "million adults", "adults of", "of working", "working age", "age who", "who do", "do not", "not do", "do any", "any kind", "kind of", "of work", "work at", "at all", "all.", ". (", "( 92", "92.", ". 12", "12.", ". 20", "20.", ". 168", "168 )"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\": \"\"I got wood for sheep\"\" is how that phrase goes.  \n\n\"", "tokenize_content": ["\"", ":", "\"", "\"", "i", "got", "wood", "for", "sheep", "\"", "\"", "is", "how", "that", "phrase", "goes", ".", "\""], "span": ["\" :", ": \"", "\" \"", "\" i", "i got", "got wood", "wood for", "for sheep", "sheep \"", "\" \"", "\" is", "is how", "how that", "that phrase", "phrase goes", "goes.", ". \""], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Yes I was having trouble with the translation. Thanks for the correcting.", "tokenize_content": ["yes", "i", "was", "having", "trouble", "with", "the", "translation", ".", "thanks", "for", "the", "correct", "##ing", "."], "span": ["yes i", "i was", "was having", "having trouble", "trouble with", "with the", "the translation", "translation.", ". thanks", "thanks for", "for the", "the correct", "correcting", "##ing."], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Floghera is a type of flute but looks like a bagpipe, Toumpeleki is a drum also and some other Idiophone Instruments like: Trigonon zilia and simadro\nTAB", "tokenize_content": ["fl", "##og", "##her", "##a", "is", "a", "type", "of", "flute", "but", "looks", "like", "a", "bag", "##pipe", ",", "to", "##ump", "##ele", "##ki", "is", "a", "drum", "also", "and", "some", "other", "id", "##io", "##phone", "instruments", "like", ":", "tri", "##gon", "##on", "z", "##ilia", "and", "sima", "##dro", "tab"], "span": ["flog", "##ogher", "##hera", "##a is", "is a", "a type", "type of", "of flute", "flute but", "but looks", "looks like", "like a", "a bag", "bagpipe", "##pipe,", ", to", "toump", "##umpele", "##eleki", "##ki is", "is a", "a drum", "drum also", "also and", "and some", "some other", "other id", "idio", "##iophone", "##phone instruments", "instruments like", "like :", ": tri", "trigon", "##gonon", "##on z", "zilia", "##ilia and", "and sima", "simadro", "##dro tab"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "White men marches on \n\nWhy have you deleted this article? I know it's a racist song but it quite famous song sang for white supramecist groups. I think that the song is enough important to be on wikipedia.\n\nThanks,", "tokenize_content": ["white", "men", "marches", "on", "why", "have", "you", "deleted", "this", "article", "?", "i", "know", "it", "'", "s", "a", "racist", "song", "but", "it", "quite", "famous", "song", "sang", "for", "white", "su", "##pr", "##ame", "##cis", "##t", "groups", ".", "i", "think", "that", "the", "song", "is", "enough", "important", "to", "be", "on", "wikipedia", ".", "thanks", ","], "span": ["white men", "men marches", "marches on", "on why", "why have", "have you", "you deleted", "deleted this", "this article", "article?", "? i", "i know", "know it", "it '", "' s", "s a", "a racist", "racist song", "song but", "but it", "it quite", "quite famous", "famous song", "song sang", "sang for", "for white", "white su", "supr", "##prame", "##amecis", "##cist", "##t groups", "groups.", ". i", "i think", "think that", "that the", "the song", "song is", "is enough", "enough important", "important to", "to be", "be on", "on wikipedia", "wikipedia.", ". thanks", "thanks,"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Well don`t you think you ought to have a source which actually calls him a right-wing extremist? and not use one which has supposition that he may have been involved with the far right?", "tokenize_content": ["well", "don", "`", "t", "you", "think", "you", "ought", "to", "have", "a", "source", "which", "actually", "calls", "him", "a", "right", "-", "wing", "ex", "##tre", "##mist", "?", "and", "not", "use", "one", "which", "has", "su", "##pp", "##osition", "that", "he", "may", "have", "been", "involved", "with", "the", "far", "right", "?"], "span": ["well don", "don `", "` t", "t you", "you think", "think you", "you ought", "ought to", "to have", "have a", "a source", "source which", "which actually", "actually calls", "calls him", "him a", "a right", "right -", "- wing", "wing ex", "extre", "##tremist", "##mist?", "? and", "and not", "not use", "use one", "one which", "which has", "has su", "supp", "##pposition", "##osition that", "that he", "he may", "may have", "have been", "been involved", "involved with", "with the", "the far", "far right", "right?"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "New image \n\nHow about File:Tiktaalik_by_Obsidian_Soul_modified.png", "tokenize_content": ["new", "image", "how", "about", "file", ":", "ti", "##kt", "##aa", "##lik", "_", "by", "_", "obsidian", "_", "soul", "_", "modified", ".", "p", "##ng"], "span": ["new image", "image how", "how about", "about file", "file :", ": ti", "tikt", "##ktaa", "##aalik", "##lik _", "_ by", "by _", "_ obsidian", "obsidian _", "_ soul", "soul _", "_ modified", "modified.", ". p", "png"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I have merged it with Separatist movements of India and added some stuff on the Durand Line.86.29.135.66", "tokenize_content": ["i", "have", "merged", "it", "with", "sep", "##arat", "##ist", "movements", "of", "india", "and", "added", "some", "stuff", "on", "the", "duran", "##d", "line", ".", "86", ".", "29", ".", "135", ".", "66"], "span": ["i have", "have merged", "merged it", "it with", "with sep", "separat", "##aratist", "##ist movements", "movements of", "of india", "india and", "and added", "added some", "some stuff", "stuff on", "on the", "the duran", "durand", "##d line", "line.", ". 86", "86.", ". 29", "29.", ". 135", "135.", ". 66"], "toxic": 0, "score": [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\nThank you, I appreciate it. \u20aa\u2014  (T\u00b7C) \u263d\u25ef\u263e\"", "tokenize_content": ["\"", "thank", "you", ",", "i", "appreciate", "it", ".", "[UNK]", "\u2014", "(", "t", "\u00b7", "c", ")", "[UNK]", "\""], "span": ["\" thank", "thank you", "you,", ", i", "i appreciate", "appreciate it", "it.", ".", "\u2014", "\u2014 (", "( t", "t \u00b7", "\u00b7 c", "c )", ")", "\""], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Oy vey \n\nJIDF detected", "tokenize_content": ["o", "##y", "ve", "##y", "ji", "##df", "detected"], "span": ["oy", "##y ve", "vey", "##y ji", "jidf", "##df detected"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0]}
{"content": "em 0 1em; \npadding: .5em 1", "tokenize_content": ["em", "0", "1", "##em", ";", "pad", "##ding", ":", ".", "5", "##em", "1"], "span": ["em 0", "0 1", "1em", "##em ;", "; pad", "padding", "##ding :", ":.", ". 5", "5em", "##em 1"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "The page alternates between present and past tense. This needs to all be in present.  19:43, July 30, 2005 (UTC)", "tokenize_content": ["the", "page", "alternate", "##s", "between", "present", "and", "past", "tense", ".", "this", "needs", "to", "all", "be", "in", "present", ".", "19", ":", "43", ",", "july", "30", ",", "2005", "(", "utc", ")"], "span": ["the page", "page alternate", "alternates", "##s between", "between present", "present and", "and past", "past tense", "tense.", ". this", "this needs", "needs to", "to all", "all be", "be in", "in present", "present.", ". 19", "19 :", ": 43", "43,", ", july", "july 30", "30,", ", 2005", "2005 (", "( utc", "utc )"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Celebrities \n\nTalk about your fave celebs and even your crushes!", "tokenize_content": ["celebrities", "talk", "about", "your", "fa", "##ve", "ce", "##le", "##bs", "and", "even", "your", "crush", "##es", "!"], "span": ["celebrities talk", "talk about", "about your", "your fa", "fave", "##ve ce", "cele", "##lebs", "##bs and", "and even", "even your", "your crush", "crushes", "##es!"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Let's not turn this into an edit war. Whoever think there is a problem with my edit state here why!\n\nNo more edits on the article without corresponding talk page edits.\n 7 July 2005 22:00 (UTC)", "tokenize_content": ["let", "'", "s", "not", "turn", "this", "into", "an", "edit", "war", ".", "whoever", "think", "there", "is", "a", "problem", "with", "my", "edit", "state", "here", "why", "!", "no", "more", "edit", "##s", "on", "the", "article", "without", "corresponding", "talk", "page", "edit", "##s", ".", "7", "july", "2005", "22", ":", "00", "(", "utc", ")"], "span": ["let '", "' s", "s not", "not turn", "turn this", "this into", "into an", "an edit", "edit war", "war.", ". whoever", "whoever think", "think there", "there is", "is a", "a problem", "problem with", "with my", "my edit", "edit state", "state here", "here why", "why!", "! no", "no more", "more edit", "edits", "##s on", "on the", "the article", "article without", "without corresponding", "corresponding talk", "talk page", "page edit", "edits", "##s.", ". 7", "7 july", "july 2005", "2005 22", "22 :", ": 00", "00 (", "( utc", "utc )"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n The onus is on you to show that \"\"the guidelines\"\" require removal of that study. I don't have to make your arguments for you.   \"", "tokenize_content": ["\"", "the", "on", "##us", "is", "on", "you", "to", "show", "that", "\"", "\"", "the", "guidelines", "\"", "\"", "require", "removal", "of", "that", "study", ".", "i", "don", "'", "t", "have", "to", "make", "your", "arguments", "for", "you", ".", "\""], "span": ["\" the", "the on", "onus", "##us is", "is on", "on you", "you to", "to show", "show that", "that \"", "\" \"", "\" the", "the guidelines", "guidelines \"", "\" \"", "\" require", "require removal", "removal of", "of that", "that study", "study.", ". i", "i don", "don '", "' t", "t have", "have to", "to make", "make your", "your arguments", "arguments for", "for you", "you.", ". \""], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\n WP:FAC for lead(II) nitrate \n\nYoh, PC, I just put the lead(II) nitrate article up for FA-class. Feel free to contribute your support.  (Talk) .\"", "tokenize_content": ["\"", "w", "##p", ":", "fa", "##c", "for", "lead", "(", "ii", ")", "nitrate", "yo", "##h", ",", "pc", ",", "i", "just", "put", "the", "lead", "(", "ii", ")", "nitrate", "article", "up", "for", "fa", "-", "class", ".", "feel", "free", "to", "contribute", "your", "support", ".", "(", "talk", ")", ".", "\""], "span": ["\" w", "wp", "##p :", ": fa", "fac", "##c for", "for lead", "lead (", "( ii", "ii )", ") nitrate", "nitrate yo", "yoh", "##h,", ", pc", "pc,", ", i", "i just", "just put", "put the", "the lead", "lead (", "( ii", "ii )", ") nitrate", "nitrate article", "article up", "up for", "for fa", "fa -", "- class", "class.", ". feel", "feel free", "free to", "to contribute", "contribute your", "your support", "support.", ". (", "( talk", "talk )", ").", ". \""], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "It's in the other articles because the other articles are wrong.", "tokenize_content": ["it", "'", "s", "in", "the", "other", "articles", "because", "the", "other", "articles", "are", "wrong", "."], "span": ["it '", "' s", "s in", "in the", "the other", "other articles", "articles because", "because the", "the other", "other articles", "articles are", "are wrong", "wrong."], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "The pun regarding SPECIFICO's username and adding the rolling eyes are the bit which is incivil.", "tokenize_content": ["the", "pun", "regarding", "specific", "##o", "'", "s", "user", "##name", "and", "adding", "the", "rolling", "eyes", "are", "the", "bit", "which", "is", "inc", "##iv", "##il", "."], "span": ["the pun", "pun regarding", "regarding specific", "specifico", "##o '", "' s", "s user", "username", "##name and", "and adding", "adding the", "the rolling", "rolling eyes", "eyes are", "are the", "the bit", "bit which", "which is", "is inc", "inciv", "##ivil", "##il."], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "your right! 'waterloo sunset' is my favorite two", "tokenize_content": ["your", "right", "!", "'", "waterloo", "sunset", "'", "is", "my", "favorite", "two"], "span": ["your right", "right!", "! '", "' waterloo", "waterloo sunset", "sunset '", "' is", "is my", "my favorite", "favorite two"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "REDIRECT Talk:List of Billboard Mainstream Top 40 number-one songs of 2007", "tokenize_content": ["red", "##ire", "##ct", "talk", ":", "list", "of", "billboard", "mainstream", "top", "40", "number", "-", "one", "songs", "of", "2007"], "span": ["redire", "##irect", "##ct talk", "talk :", ": list", "list of", "of billboard", "billboard mainstream", "mainstream top", "top 40", "40 number", "number -", "- one", "one songs", "songs of", "of 2007"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "\"\n\n Please do not vandalize pages, as you did with this edit to Queens Park Community School. If you continue to do so, you will be blocked from editing.    \"", "tokenize_content": ["\"", "please", "do", "not", "van", "##dal", "##ize", "pages", ",", "as", "you", "did", "with", "this", "edit", "to", "queens", "park", "community", "school", ".", "if", "you", "continue", "to", "do", "so", ",", "you", "will", "be", "blocked", "from", "editing", ".", "\""], "span": ["\" please", "please do", "do not", "not van", "vandal", "##dalize", "##ize pages", "pages,", ", as", "as you", "you did", "did with", "with this", "this edit", "edit to", "to queens", "queens park", "park community", "community school", "school.", ". if", "if you", "you continue", "continue to", "to do", "do so", "so,", ", you", "you will", "will be", "be blocked", "blocked from", "from editing", "editing.", ". \""], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "qv. also: LOTHIAN, M (Burke's Peerage & Baronetage)", "tokenize_content": ["q", "##v", ".", "also", ":", "lot", "##hian", ",", "m", "(", "burke", "'", "s", "peerage", "&", "baronet", "##age", ")"], "span": ["qv", "##v.", ". also", "also :", ": lot", "lothian", "##hian,", ", m", "m (", "( burke", "burke '", "' s", "s peerage", "peerage &", "& baronet", "baronetage", "##age )"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Please, please, continue.  Tell me what you really think.", "tokenize_content": ["please", ",", "please", ",", "continue", ".", "tell", "me", "what", "you", "really", "think", "."], "span": ["please,", ", please", "please,", ", continue", "continue.", ". tell", "tell me", "me what", "what you", "you really", "really think", "think."], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "What has accent have to do with it? Does it matter what accent he spoke with?", "tokenize_content": ["what", "has", "accent", "have", "to", "do", "with", "it", "?", "does", "it", "matter", "what", "accent", "he", "spoke", "with", "?"], "span": ["what has", "has accent", "accent have", "have to", "to do", "do with", "with it", "it?", "? does", "does it", "it matter", "matter what", "what accent", "accent he", "he spoke", "spoke with", "with?"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "One can only imagine. ''''''\u00a0Talk", "tokenize_content": ["one", "can", "only", "imagine", ".", "'", "'", "'", "'", "'", "'", "talk"], "span": ["one can", "can only", "only imagine", "imagine.", ". '", "' '", "' '", "' '", "' '", "' '", "' talk"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I think you need to realise its not as important as you health and peace of mind, think about it. 175.110.222.144", "tokenize_content": ["i", "think", "you", "need", "to", "realise", "its", "not", "as", "important", "as", "you", "health", "and", "peace", "of", "mind", ",", "think", "about", "it", ".", "175", ".", "110", ".", "222", ".", "144"], "span": ["i think", "think you", "you need", "need to", "to realise", "realise its", "its not", "not as", "as important", "important as", "as you", "you health", "health and", "and peace", "peace of", "of mind", "mind,", ", think", "think about", "about it", "it.", ". 175", "175.", ". 110", "110.", ". 222", "222.", ". 144"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I've made the addition that I proposed above.  (talk)", "tokenize_content": ["i", "'", "ve", "made", "the", "addition", "that", "i", "proposed", "above", ".", "(", "talk", ")"], "span": ["i '", "' ve", "ve made", "made the", "the addition", "addition that", "that i", "i proposed", "proposed above", "above.", ". (", "( talk", "talk )"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Airdates\nSomeone should explain the airdates a little better, I think the NBC version was on from 1976-1978 and the syndie version was on till 1980, but this isn't explained well.", "tokenize_content": ["air", "##dates", "someone", "should", "explain", "the", "air", "##dates", "a", "little", "better", ",", "i", "think", "the", "nbc", "version", "was", "on", "from", "1976", "-", "1978", "and", "the", "syn", "##die", "version", "was", "on", "till", "1980", ",", "but", "this", "isn", "'", "t", "explained", "well", "."], "span": ["airdates", "##dates someone", "someone should", "should explain", "explain the", "the air", "airdates", "##dates a", "a little", "little better", "better,", ", i", "i think", "think the", "the nbc", "nbc version", "version was", "was on", "on from", "from 1976", "1976 -", "- 1978", "1978 and", "and the", "the syn", "syndie", "##die version", "version was", "was on", "on till", "till 1980", "1980,", ", but", "but this", "this isn", "isn '", "' t", "t explained", "explained well", "well."], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Before you read this, read below 'Up for debate'and then take the next part how it was meant to be taken: as a joke.", "tokenize_content": ["before", "you", "read", "this", ",", "read", "below", "'", "up", "for", "debate", "'", "and", "then", "take", "the", "next", "part", "how", "it", "was", "meant", "to", "be", "taken", ":", "as", "a", "joke", "."], "span": ["before you", "you read", "read this", "this,", ", read", "read below", "below '", "' up", "up for", "for debate", "debate '", "' and", "and then", "then take", "take the", "the next", "next part", "part how", "how it", "it was", "was meant", "meant to", "to be", "be taken", "taken :", ": as", "as a", "a joke", "joke."], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I have raised this matter at Wikipedia:Administrators' noticeboard/Incidents.", "tokenize_content": ["i", "have", "raised", "this", "matter", "at", "wikipedia", ":", "administrators", "'", "notice", "##board", "/", "incidents", "."], "span": ["i have", "have raised", "raised this", "this matter", "matter at", "at wikipedia", "wikipedia :", ": administrators", "administrators '", "' notice", "noticeboard", "##board /", "/ incidents", "incidents."], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Answered on my talk page (where you cross-posted this).", "tokenize_content": ["answered", "on", "my", "talk", "page", "(", "where", "you", "cross", "-", "posted", "this", ")", "."], "span": ["answered on", "on my", "my talk", "talk page", "page (", "( where", "where you", "you cross", "cross -", "- posted", "posted this", "this )", ")."], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Note, please don't post IP information here as I do not wish to expose my IP to possible attacks.  (PowWow)", "tokenize_content": ["note", ",", "please", "don", "'", "t", "post", "ip", "information", "here", "as", "i", "do", "not", "wish", "to", "expose", "my", "ip", "to", "possible", "attacks", ".", "(", "pow", "##wo", "##w", ")"], "span": ["note,", ", please", "please don", "don '", "' t", "t post", "post ip", "ip information", "information here", "here as", "as i", "i do", "do not", "not wish", "wish to", "to expose", "expose my", "my ip", "ip to", "to possible", "possible attacks", "attacks.", ". (", "( pow", "powwo", "##wow", "##w )"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I have no problem with defending my position with any Admin, you, however, may be on extremely thin ice, given your previous behavioural issues (and subsequent bans)with them.", "tokenize_content": ["i", "have", "no", "problem", "with", "defending", "my", "position", "with", "any", "ad", "##min", ",", "you", ",", "however", ",", "may", "be", "on", "extremely", "thin", "ice", ",", "given", "your", "previous", "behaviour", "##al", "issues", "(", "and", "subsequent", "ban", "##s", ")", "with", "them", "."], "span": ["i have", "have no", "no problem", "problem with", "with defending", "defending my", "my position", "position with", "with any", "any ad", "admin", "##min,", ", you", "you,", ", however", "however,", ", may", "may be", "be on", "on extremely", "extremely thin", "thin ice", "ice,", ", given", "given your", "your previous", "previous behaviour", "behavioural", "##al issues", "issues (", "( and", "and subsequent", "subsequent ban", "bans", "##s )", ") with", "with them", "them."], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Greetings, Marek69! \nThanks for the reception, mate! ;D", "tokenize_content": ["greeting", "##s", ",", "marek", "##6", "##9", "!", "thanks", "for", "the", "reception", ",", "mate", "!", ";", "d"], "span": ["greetings", "##s,", ", marek", "marek6", "##69", "##9!", "! thanks", "thanks for", "for the", "the reception", "reception,", ", mate", "mate!", "! ;", "; d"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}
{"content": "\"\n\nMoldopodo, stop accusing me of \"\"never trying to reach consensus or to prove whatsoever\"\" and stop trolling. What you do is called trolling.   \"", "tokenize_content": ["\"", "mold", "##op", "##od", "##o", ",", "stop", "accusing", "me", "of", "\"", "\"", "never", "trying", "to", "reach", "consensus", "or", "to", "prove", "whatsoever", "\"", "\"", "and", "stop", "troll", "##ing", ".", "what", "you", "do", "is", "called", "troll", "##ing", ".", "\""], "span": ["\" mold", "moldop", "##opod", "##odo", "##o,", ", stop", "stop accusing", "accusing me", "me of", "of \"", "\" \"", "\" never", "never trying", "trying to", "to reach", "reach consensus", "consensus or", "or to", "to prove", "prove whatsoever", "whatsoever \"", "\" \"", "\" and", "and stop", "stop troll", "trolling", "##ing.", ". what", "what you", "you do", "do is", "is called", "called troll", "trolling", "##ing.", ". \""], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Modern-day unions could be considered to be rackets as well. 24.141.76.19", "tokenize_content": ["modern", "-", "day", "unions", "could", "be", "considered", "to", "be", "rack", "##ets", "as", "well", ".", "24", ".", "141", ".", "76", ".", "19"], "span": ["modern -", "- day", "day unions", "unions could", "could be", "be considered", "considered to", "to be", "be rack", "rackets", "##ets as", "as well", "well.", ". 24", "24.", ". 141", "141.", ". 76", "76.", ". 19"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "What critique? The suggestion was for more sources and an example of those that are acceptable for notability purposes. No mention of those already in use.", "tokenize_content": ["what", "critique", "?", "the", "suggestion", "was", "for", "more", "sources", "and", "an", "example", "of", "those", "that", "are", "acceptable", "for", "not", "##ability", "purposes", ".", "no", "mention", "of", "those", "already", "in", "use", "."], "span": ["what critique", "critique?", "? the", "the suggestion", "suggestion was", "was for", "for more", "more sources", "sources and", "and an", "an example", "example of", "of those", "those that", "that are", "are acceptable", "acceptable for", "for not", "notability", "##ability purposes", "purposes.", ". no", "no mention", "mention of", "of those", "those already", "already in", "in use", "use."], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "I see you have been talking to yourself again. Do not make the mistake of thinking that this will provide you with a defence against wp:sock.It won't.~~", "tokenize_content": ["i", "see", "you", "have", "been", "talking", "to", "yourself", "again", ".", "do", "not", "make", "the", "mistake", "of", "thinking", "that", "this", "will", "provide", "you", "with", "a", "defence", "against", "w", "##p", ":", "sock", ".", "it", "won", "'", "t", ".", "~", "~"], "span": ["i see", "see you", "you have", "have been", "been talking", "talking to", "to yourself", "yourself again", "again.", ". do", "do not", "not make", "make the", "the mistake", "mistake of", "of thinking", "thinking that", "that this", "this will", "will provide", "provide you", "you with", "with a", "a defence", "defence against", "against w", "wp", "##p :", ": sock", "sock.", ". it", "it won", "won '", "' t", "t.", ". ~", "~ ~"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "SORRY! OVER AND OUT!", "tokenize_content": ["sorry", "!", "over", "and", "out", "!"], "span": ["sorry!", "! over", "over and", "and out", "out!"], "toxic": 0, "score": [0, 0, 0, 0, 0]}
{"content": "Edit summaries \n\nHi, could I request that you use edit summaries as much as possible? This makes it easier to see what kind of changes you have made without having to check the diff. \u00a0|\u00a0T@lk", "tokenize_content": ["edit", "sum", "##mar", "##ies", "hi", ",", "could", "i", "request", "that", "you", "use", "edit", "sum", "##mar", "##ies", "as", "much", "as", "possible", "?", "this", "makes", "it", "easier", "to", "see", "what", "kind", "of", "changes", "you", "have", "made", "without", "having", "to", "check", "the", "di", "##ff", ".", "|", "t", "@", "l", "##k"], "span": ["edit sum", "summar", "##maries", "##ies hi", "hi,", ", could", "could i", "i request", "request that", "that you", "you use", "use edit", "edit sum", "summar", "##maries", "##ies as", "as much", "much as", "as possible", "possible?", "? this", "this makes", "makes it", "it easier", "easier to", "to see", "see what", "what kind", "kind of", "of changes", "changes you", "you have", "have made", "made without", "without having", "having to", "to check", "check the", "the di", "diff", "##ff.", ". |", "| t", "t @", "@ l", "lk"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "April 2011 (UTC)\nRepaired; any measured appropriate comments Mr. Rubin (tweaking), or anyone else?  97.87.29.188  22:37, 5", "tokenize_content": ["april", "2011", "(", "utc", ")", "repaired", ";", "any", "measured", "appropriate", "comments", "mr", ".", "rubin", "(", "t", "##we", "##aking", ")", ",", "or", "anyone", "else", "?", "97", ".", "87", ".", "29", ".", "188", "22", ":", "37", ",", "5"], "span": ["april 2011", "2011 (", "( utc", "utc )", ") repaired", "repaired ;", "; any", "any measured", "measured appropriate", "appropriate comments", "comments mr", "mr.", ". rubin", "rubin (", "( t", "twe", "##weaking", "##aking )", "),", ", or", "or anyone", "anyone else", "else?", "? 97", "97.", ". 87", "87.", ". 29", "29.", ". 188", "188 22", "22 :", ": 37", "37,", ", 5"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "henry lee lucas was my dad im pretty sure i know the information better than you do.", "tokenize_content": ["henry", "lee", "lucas", "was", "my", "dad", "im", "pretty", "sure", "i", "know", "the", "information", "better", "than", "you", "do", "."], "span": ["henry lee", "lee lucas", "lucas was", "was my", "my dad", "dad im", "im pretty", "pretty sure", "sure i", "i know", "know the", "the information", "information better", "better than", "than you", "you do", "do."], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
{"content": "Thanks \nThanks for the advice. Its better to be banned by speaking the bitter truth than being abused by so cheap people. But anyway, I would keep this Qalenderanna thinking to myself. D", "tokenize_content": ["thanks", "thanks", "for", "the", "advice", ".", "its", "better", "to", "be", "banned", "by", "speaking", "the", "bitter", "truth", "than", "being", "abused", "by", "so", "cheap", "people", ".", "but", "anyway", ",", "i", "would", "keep", "this", "q", "##ale", "##nder", "##anna", "thinking", "to", "myself", ".", "d"], "span": ["thanks thanks", "thanks for", "for the", "the advice", "advice.", ". its", "its better", "better to", "to be", "be banned", "banned by", "by speaking", "speaking the", "the bitter", "bitter truth", "truth than", "than being", "being abused", "abused by", "by so", "so cheap", "cheap people", "people.", ". but", "but anyway", "anyway,", ", i", "i would", "would keep", "keep this", "this q", "qale", "##alender", "##nderanna", "##anna thinking", "thinking to", "to myself", "myself.", ". d"], "toxic": 0, "score": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
